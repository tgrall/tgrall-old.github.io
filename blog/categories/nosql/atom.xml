<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Nosql | Tug's Blog]]></title>
  <link href="http://tgrall.github.io/blog/categories/nosql/atom.xml" rel="self"/>
  <link href="http://tgrall.github.io/"/>
  <updated>2019-09-05T15:56:33+02:00</updated>
  <id>http://tgrall.github.io/</id>
  <author>
    <name><![CDATA[Tug Grall]]></name>
    <email><![CDATA[tugdual@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Multi-Nodes Redis Cluster With Docker]]></title>
    <link href="http://tgrall.github.io/blog/2019/09/05/multi-nodes-redis-cluster-with-docker/"/>
    <updated>2019-09-05T11:33:56+02:00</updated>
    <id>http://tgrall.github.io/blog/2019/09/05/multi-nodes-redis-cluster-with-docker</id>
    <content type="html"><![CDATA[<p>As part of my on-boarding/training at RedisLabs I continue to play with the product, and I have decided today to install a local 3 nodes cluster of Redis Enterprise Server (RS); and show how easy is to move from a single node/shard database to a multi nodes highly available one.</p>

<p>Once your cluster is up &amp; running, you will kill some containers to see how the system automatically fail-over to guarantee service continuity.</p>

<p>The deployment will look more or less like the schema below, (<em><a href="https://docs.redislabs.com/latest/rs/getting-started/docker/">coming from RedisLabs documentation</a></em>)</p>

<p><img class="center" src="/images/posts/multi-nodes-redis-cluster-with-docker/docker-deployment.png"></p>

<p><strong>Prerequisites:</strong></p>

<p><em>Docker Desktop (</em>I am running Docker on Mac*)</p>

<!--more-->


<h3>Installing and Running your First Redis Node</h3>

<p>As usual, installing a new product with Docker is very simple just run the following command:</p>

<pre><code class="bash">docker run -d --cap-add sys_resource \
--name  redis-node1 \
-p 8443:8443 \
-p 9443:9443 \
-p 12000:12000 \
redislabs/redis
</code></pre>

<p>Let&rsquo;s look at the parameters used here:</p>

<ul>
<li><code>-d</code>: run the container in the background</li>
<li><code>--cap-add sys_resource</code>: add Linux  <code>sys_resource</code>capabilities to set proper privileges</li>
<li><code>--name  redis-node1</code>: naming the container</li>
<li><code>-p 8443:8443</code>: to access the management web UI (HTTPS)</li>
<li><code>-p 9443:9443</code>: to access the REST API (HTTPS)</li>
<li><code>-p 12000:12000</code>: the TCP port that we will use for the database endpoint on this node</li>
<li><code>redislabs/redis</code>: use the RedisLabs image (the enterprise version of Redis)</li>
</ul>


<h4>Creating a new Cluster</h4>

<p>Once the container is started you can configure the &ldquo;cluster&rdquo;.</p>

<ol>
<li>Go top <a href="https://localhost:8443/">https://localhost:8443/</a> (accept the connect using the temporary certificate)</li>
<li>Click &ldquo;Setup&rdquo;</li>
<li>Change the Cluster Name to &ldquo;my-redis-cluster.tug-demo.com&rdquo;</li>
<li>Click &ldquo;Next&rdquo;</li>
<li>On the &ldquo;cluster authentication&rdquo; click &ldquo;Next&rdquo;  <em>(we will be using the free version)</em></li>
<li>Enter the user admin credentials and click &ldquo;Next&rdquo;.</li>
</ol>


<p>Once it is configured, connect to the console to the console using the credentials you have created.</p>

<h4>Adding a new database</h4>

<p>Now you have to create a new database.</p>

<ol>
<li>Select &ldquo;Redis Database&rdquo; and &ldquo;Single Region&rdquo;</li>
<li>Enter the name &ldquo;test-db-001&rdquo;, and &ldquo;0.5&rdquo; for the memory limit</li>
<li>Click &ldquo;Show Advanced Options&rdquo;</li>
<li>Enter 12000 in the &ldquo;Endpoint port number&rdquo; field</li>
<li>Click &ldquo;Activate&rdquo;.</li>
</ol>


<p>After  fewseconds, the database is created and available.</p>

<p>Note: we have not set anything special around clustering and replication; we will do that later.</p>

<h4>Using the Single Node Database</h4>

<p>You can now connect to the database. You can use  <code>redis-cli</code>from your host, or you can connect to the container and do it from there:</p>

<pre><code class="bash">&gt; docker  exec-it redis-node1 /bin/bash

redislabs@0a174e819a6b:/opt$ redis-cli -p 12000

127.0.0.1:12000&gt; SET foo bar
OK

127.0.0.1:12000&gt; GET foo
"bar"

127.0.0.1:12000&gt;  exit
</code></pre>

<p><strong><em>Checkpoint</em></strong></p>

<p>So far you have:</p>

<ol>
<li>Install a single node cluster of Redis Enterprise using Docker</li>
<li>Create a new cluster</li>
<li>Created a database that listens on port 12000.</li>
</ol>


<p>In the container, run the  <code>rladminstatus</code>command, to get information about your deployment.</p>

<p><img class="center" src="/images/posts/multi-nodes-redis-cluster-with-docker/rladmin-status.png"></p>

<p>In the cluster node section, you can see the address of the node, 172.17.0.2 in my case. This is the IP address of the container, that will be used to create the multi-node cluster.</p>

<p>It is time to add new nodes to the cluster and enable replication and sharding</p>

<h3>Adding new nodes</h3>

<p>To add new nodes to the cluster, you start new containers. Since the 3 containers will be running on the same host, it is necessary, to avoid conflicts, to use different mapping to the Web UI, REST API, and database endpoint ports.</p>

<p><strong>Start node 2:</strong></p>

<pre><code class="bash">docker run -d --cap-add sys_resource \
--name redis-node2 \
-p 8444:8443 \
-p 9444:9443 \
-p 12001:12000 \
redislabs/redis
</code></pre>

<p><strong>Start node 3:</strong></p>

<pre><code class="bash">docker run -d --cap-add sys_resource \
--name redis-node3 \
-p 8445:8443 \
-p 9445:9443 \
-p 12002:12000 \
redislabs/redis
</code></pre>

<p>So to configure each node you need to use the URLs:</p>

<ul>
<li>node 2: <a href="https://localhost:8444/">https://localhost:8444/</a></li>
<li>node 3: <a href="https://localhost:8445/">https://localhost:8445/</a></li>
</ul>


<p>I have just increase the port number of the Web UI (8443: node 1, 8444: node 2, 8445 node 3).</p>

<p>For these 2 new nodes, do the following steps to add them to the cluster:</p>

<ol>
<li>Click &ldquo;Setup&rdquo;</li>
<li>In  clusterconfiguration, select &ldquo;Join Cluster&rdquo;,

<ul>
<li>Enter the IP address of the first node, 172.17.0.2 in my environment</li>
<li>Enter the credentials you have used during the installation of the first node.</li>
</ul>
</li>
<li>Click &ldquo;Next&rdquo;</li>
</ol>


<p>After a few seconds, you will be redirected to the home page and see the list of nodes of your cluster.</p>

<p>Repeat the same steps for the third node.</p>

<p>Your environment should look like this after the installation and configuration of the 3 nodes.</p>

<p><img class="center" src="/images/posts/multi-nodes-redis-cluster-with-docker/cluster-view-3-nodes.png"></p>

<p>You can also reuse the  <code>rladminstatus</code>command on one of the containers and see the new configuration.</p>

<p>If you look carefully, you can see that you have only 1 shard in your cluster. Let&rsquo;s now add a new shard to the database.</p>

<p><strong>Enabling Clustering and Replication to the DB</strong></p>

<p>In the Redis Enterprise Admin Web UI, (<em>you can use any of the nodes</em>):</p>

<ol>
<li>Click on the &ldquo;databases&rdquo; tab</li>
<li>Click on &ldquo;test-db-001&rdquo; database</li>
<li>Click on the &ldquo;configuration&rdquo;</li>
<li>Go to the bottom of the page and click &ldquo;Edit&rdquo;</li>
<li>Check the &ldquo;Replication&rdquo; checkbox, to create new shard that will be a replica, to provide high availability</li>
<li>Check &ldquo;Database Clustering&rdquo; and increase the number of shards to 2. This will  <em>distribute</em>the data in your database into 2 shards, this for better scalability.
 <em>You can see that the UI indicated that you have  </em>4 shards with replication*. Yes because you have a database that you have &ldquo;divided in 2&rdquo;, and each of the portions of the database is replicated.
(Also with the free version of Redis Enterprise you are limited to 4 shards, so do not be surprised if you can not increase the number of shards to more than 4)</li>
<li>Click &ldquo;Update&rdquo; at the bottom of the page.</li>
</ol>


<p>Go back to the &ldquo;nodes&rdquo; tab, and you will see that you have now 4 shards distributed on your 3 nodes.</p>

<p><strong>Discovering the cluster topology</strong></p>

<p>Run  <code>rladminstatus</code>to inspect your cluster and see how the various components are installed:</p>

<p><img class="center" src="/images/posts/multi-nodes-redis-cluster-with-docker/rladmin-status-with-db.png"></p>

<p>For example, you can see, that in my environment:</p>

<p><em>in the &ldquo;CLUSTER NODES&rdquo; section that the &ldquo;node:1&rdquo; is the master of the cluster
</em>in the &ldquo;DATABASES&rdquo; section that replication is enabled, and the database uses a &ldquo;<a href="https://docs.redislabs.com/latest/rs/concepts/rebalancing-shard-placement/#dense-shard-placement-policy">dense placement</a>&rdquo;
<em>in the &ldquo;SHARDS&rdquo; section you can see the various shards and their placement (</em>node:1|2|3<em>), their role (</em>master|slave*) and their slots.</p>

<p>Using Redis Enterprise Enterprise Software (RS), all the clustering is managed transparently for you, and your applications. This means that you just have to connect your application to RS Cluster.</p>

<p><strong>Clustering in Action</strong></p>

<p>First of all, you have already seen a lot, just using the Web UI (and you could have done it using CLI and REST API), you have moved an existing database from a single instance to a distributed and highly available instance.</p>

<p>So now if something happens to the system, for example, if one of the masters disappears RS will automatically get another  oneelected.</p>

<p>Let me kill for example the node 3 that contains the 2 masters for my database.</p>

<pre><code class="bash">&gt; docker  killredis-node3
</code></pre>

<p>After a few seconds, you should see that the master shards are now on another node, in my case node:1.</p>

<p><img class="center" src="/images/posts/multi-nodes-redis-cluster-with-docker/rladmin-status-with-db-002.png"></p>

<p>So if an application, is using this cluster it would be almost transparent as the election of the new master is happening in the  backgroud.</p>

<p>If you restart the node 3 it will rejoin the cluster, and the replicas will be updated on node 3 with any changes that happened to the masters.</p>

<pre><code class="bash">&gt; docker start  redis-node3
</code></pre>

<p>The same automatic fail-over will happen if you kill a node with the cluster  manager,or the endpoint.</p>

<h4>Conclusion</h4>

<p>In this small article you have learned how to:</p>

<ul>
<li>deploy a 3 nodes Redis Enterprise Server (RS) on Docker (on a single host)</li>
<li>create a database, and make it highly available and distributed easily using the Admin UI</li>
<li>look at the deployment using  <code>rladminstatus</code>command.</li>
</ul>


<p>You have also seen, by killing some nodes, how the cluster fail-over will various master services (shards, endpoint, master cluster node) to another node automatically. This to ensure a continuity of service for your application.</p>

<p>In another  postI will show what is the exact behavior of client applications during the fail-over.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Redis Streams &amp; Java]]></title>
    <link href="http://tgrall.github.io/blog/2019/09/02/getting-with-redis-streams-and-java/"/>
    <updated>2019-09-02T09:24:24+02:00</updated>
    <id>http://tgrall.github.io/blog/2019/09/02/getting-with-redis-streams-and-java</id>
    <content type="html"><![CDATA[<p>As you may have seen, I have joined <a href="https://www.redislabs.com">Redis Labs</a> a month ago; one of the first task as a new hire is to learn more about Redis. So I learned, and I am still learning.</p>

<p>This is when I discovered <a href="https://redis.io/topics/streams-intro">Redis Streams</a>. I am a big fan of streaming-based applications so it is natural that I start with a small blog post explaining how to use Redis Streams and Java.</p>

<p><strong><em>What is Redis Streams?</em></strong></p>

<p>Redis Streams is a Redis Data Type, that represents a log so you can add new information/message in an append-only mode <em>(this is not 100% accurate since you can remove messages from the log)</em>. Using Redis Streams you can build &ldquo;Kafka Like&rdquo; applications, what I mean by that you can:</p>

<ul>
<li>create applications that publish and consume messages (nothing extraordinary here, you could already do that with Redi Pub/Sub)</li>
<li>consume messages that are published even when your client application (consumer) is not running. This is a big difference with Redis Pub/Sub</li>
<li>consume messages starting a specific offset, for example, read the whole history, or only new messages</li>
</ul>


<p>In addition to this, Redis Streams has the concept of <strong>Consumer Groups</strong>. Redis Streams Consumer Groups, like Apache Kafka ones, allows the client applications to consume messages in a distributed fashion (multiple clients), providing an easy way to scale and create highly available systems.</p>

<p><img class="center" src="/images/posts/getting-with-redis-streams-and-java/redis-streams-101-img-1.png"></p>

<p>Enroll in the <a href="https://university.redislabs.com/courses/course-v1:redislabs+RU202+2019_03/about">Redis University: Redis Streams</a> to learn more and get certified.</p>

<p><strong><em>Sample Application</em></strong></p>

<p>The <a href="https://github.com/tgrall/redis-streams-101-java">redis-streams-101-java GitHub Repository</a> contains sample code that shows how to</p>

<ul>
<li>post messages to a streams</li>
<li>consume messages using a consumer group</li>
</ul>


<!--more -->


<h4>Prerequisites</h4>

<ul>
<li>Redis 5.x, you have here multiple options:

<ul>
<li><a href="https://redis.io">Download</a> and install Redis Community</li>
<li>Install and Run a Docker image: <a href="https://hub.docker.com/_/redis">Community</a> or <a href="https://hub.docker.com/r/redislabs/redis">Redis Enterprise</a></li>
<li>Create a online instance on <a href="https://redislabs.com/redis-enterprise/essentials/">Redis Labs Cloud</a> (30mb for free)</li>
</ul>
</li>
<li>Java 8 or later</li>
<li>Apache Maven 3.5.x</li>
<li>Git</li>
</ul>


<h3>Java &amp; Redis Streams</h3>

<p>Redis has many Java clients developed by the community, as you can see on the <a href="https://redis.io/clients#java">Redis.io site</a>.</p>

<p>It looks, based on my short experience with Redis so far, that the most complete one around Redis Streams support is <a href="https://lettuce.io">Lettuce</a>, this is the one I will be using in the following code.</p>

<h4>1- Adding Lettuce to Your Maven Project</h4>

<p>Add the following dependency to your project file:</p>

<pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;io.lettuce&lt;/groupId&gt;
            &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
            &lt;version&gt;5.1.8.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>

<h4>2- Connecting to Redis</h4>

<p>Import the following classes</p>

<pre><code class="java">import io.lettuce.core.*;
import io.lettuce.core.api.StatefulRedisConnection;
import io.lettuce.core.api.sync.RedisCommands;
</code></pre>

<p>Then connect with:</p>

<pre><code class="java">RedisClient redisClient = RedisClient.create("redis://password@host:port"); // change to reflect your environment
StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect();
RedisCommands&lt;String, String&gt; syncCommands = connection.sync();
</code></pre>

<p>When your application is done with the connection you should disconnect with the following code:</p>

<pre><code class="java">connection.close();
redisClient.shutdown();
</code></pre>

<h4>3- Sending Message to Streams</h4>

<p>Once you have a connection you can send a message. In this example, I will let Redis generate the message ID, which is time-based, and the body will be built using a Map representing IoT data, for example, a weather data capturing Wind speed and direction in real-time.</p>

<pre><code class="java">    public static void main(String[] args) {

        RedisClient redisClient = RedisClient.create("redis://localhost:6379"); // change to reflect your environment
        StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect();
        RedisCommands&lt;String, String&gt; syncCommands = connection.sync();

        Map&lt;String, String&gt; messageBody = new HashMap&lt;&gt;();
        messageBody.put( "speed", "15" );
        messageBody.put( "direction", "270" );
        messageBody.put( "sensor_ts", String.valueOf(System.currentTimeMillis()) );

        String messageId = syncCommands.xadd(
                "weather_sensor:wind",
                messageBody);

        System.out.println( String.format("Message %s : %s posted", messageId, messageBody) );

        connection.close();
        redisClient.shutdown();

    }
</code></pre>

<p>Let me explain the code:</p>

<ul>
<li>Lines 3-5 are used to connect to Redis</li>
<li>Lines 7-10 are used to create the message body, using a Map, since Redis Streams messages are string key/values.</li>
<li>Lines 12-14 call the <code>syncCommands.xadd()</code> method using the streams key &ldquo;weather_sensor:wind&rdquo; and the message body itself

<ul>
<li>this method returns the message ID.</li>
</ul>
</li>
<li>line 16 just print the message ID and content</li>
<li>the lines 18-19 close the connection and client.</li>
</ul>


<p>The complete producer code is available <a href="https://github.com/tgrall/redis-streams-101-java/blob/master/src/main/java/com/kanibl/redis/streams/simple/RedisStreams101Producer.java">here</a>.</p>

<h4>4- Consuming Messages</h4>

<p>Redis Streams offers various way to consume/read messages using the commands: <a href="https://redis.io/commands/xrange">XRANGE</a>, <a href="https://redis.io/commands/xrevrange">XREVRANGE</a>, <a href="https://redis.io/commands/xread">XREAD</a>, <a href="https://redis.io/commands/xreadgroup">XREADGROUP</a>.</p>

<p>I want to keep the article short and close to the way you would build an application with Apache Kafka, this is why I will use the <a href="https://redis.io/commands/xreadgroup">XREADGROUP</a> command from Lettuce.</p>

<p>The Consumer Groups allow developers to create a group of clients that will cooperate to consume messages from the streams (for scale and high availability); it is also a way to associate the client to specific applications roles; for example:</p>

<ul>
<li>a consumer group called &ldquo;data warehouse&rdquo; will consume messages and send them to a data warehouse</li>
<li>another consumer group called &ldquo;aggregator&rdquo; will consume the messages and aggregate the data and send them to another sink (another stream or storage)</li>
</ul>


<p>Each of this group will act independently, and each of this group could have multiple &ldquo;consumers&rdquo; (client).</p>

<p>Let&rsquo;s see how you use this in Java.</p>

<pre><code class="java">...

        try {
            // WARNING: Streams must exist before creating the group
            //          This will not be necessary in Lettuce 5.2, see https://github.com/lettuce-io/lettuce-core/issues/898
            syncCommands.xgroupCreate( XReadArgs.StreamOffset.from("weather_sensor:wind", "0-0"), "application_1"  );
        }
        catch (RedisBusyException redisBusyException) {
            System.out.println( String.format("\t Group '%s already' exists","application_1"));
        }


        System.out.println("Waiting for new messages");

        while(true) {

            List&lt;StreamMessage&lt;String, String&gt;&gt; messages = syncCommands.xreadgroup(
                    Consumer.from("application_1", "consumer_1"),
                    XReadArgs.StreamOffset.lastConsumed("weather_sensor:wind")
            );

            if (!messages.isEmpty()) {
                System.out.println( messages );
            }


        }

...
</code></pre>

<p>This code is a subset of the <code>main()</code> method I have removed the connection management part, to add readability. Let&rsquo;s take a look to the code:</p>

<ul>
<li>line 3 to 10, using the method <code>xgroupCreate()</code>, that matches the <a href="https://redis.io/commands/xgroup">XGROUP CREATE</a> command,

<ul>
<li>is used to create a new group called <code>application_1</code>,</li>
<li>consume messages from the stream <code>weather_sensor:wind</code></li>
<li>starting at the first message in the stream, this is indicated using the message ID <code>0-0</code>. <em>Note that it is also possible to indicate to the group to start to read at a specific message ID, or only the new messages that arrive after the creating of the consumer group using <code>$</code> special ID (or the helper method <code>XReadArgs.StreamOffset.latest()</code></em>.</li>
</ul>
</li>
<li>line 15 to 27, in this example we use an infinite loop (<code>while(true)</code>) to wait for any new messages published to the streams</li>
<li>line 17 to 20, the method <code>xreadgroup()</code> returns the messages based on the group configuration

<ul>
<li>line 18 define the consumer named <code>consumer_1</code> that is associated with the group <code>application_1</code>: you can create new group do distribute the read to multiple clients</li>
<li>line 19 indicates where to start, in this case, <code>StreamOffset.lastConsumed("weather_sensor:wind")</code> the consumer will consume messages that have not been read already. With the current configuration of the group (offset <code>0-0</code>), when the consumer will start for the first time, it will read all the existing messages.</li>
<li>the <a href="https://redis.io/commands/xreadgroup">XREADGROUP</a> command by default sends an acknowledgment for each consumed message.</li>
</ul>
</li>
</ul>


<p>The complete consumer code is available <a href="https://github.com/tgrall/redis-streams-101-java/blob/master/src/main/java/com/kanibl/redis/streams/simple/RedisStreams101Consumer.java">here</a>.</p>

<h3>Build &amp; Run the Simple Java Application</h3>

<p>Now that you have a better understanding of the code, let&rsquo;s run the producer and consumer. You can run this from your IDE, or using Maven.</p>

<p>Let&rsquo;s do it using Maven CLI, for this open 2 terminals:</p>

<ul>
<li>one to produce messages</li>
<li>one to consume them</li>
</ul>


<p><em>1- Clone and Build the project</em></p>

<pre><code class="bash">&gt; git clone https://github.com/tgrall/redis-streams-101-java.git

&gt; cd redis-streams-101-java

&gt; mvn clean verify
</code></pre>

<p><em>2- Post a new message</em></p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Producer"
</code></pre>

<p><em>3- Consume messages</em></p>

<p>Open a new terminal and run the following command:</p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Consumer"
</code></pre>

<p>The consumer will start and consume the message you just posted, and wait for any new messages.</p>

<p><em>4- In the first terminal post 100 new messages</em></p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Producer" -Dexec.args="100"
</code></pre>

<p>The consumer will receive and print all the messages.</p>

<p><em>5- Kill the consumer and post more messages</em></p>

<p>Let&rsquo;s now do another test, stop the consumer using a simple <code>ctrl+C</code>.</p>

<p>Then post 5 new messages.</p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Producer" -Dexec.args="5"
</code></pre>

<p>The messages are not yet consumed by any application, but still store in Redis Streams.</p>

<p>So when you start the consumer, it will consumes these new messages.</p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Consumer"
</code></pre>

<p>This is a one of the differences between <a href="https://redis.io/topics/streams-intro">Redis Streams</a> and <a href="https://redis.io/topics/pubsub">Redis PubSub</a>. The producer application has publish many messages while the consumer application was not running. Since the consumer is ran with <code>StreamOffset.lastConsumed()</code>, when the consumer is starting, it looks to the last consumed ID, and start to read the streams from there. This method generate a XGROUPREAD command with the group</p>

<h3>Conclusion</h3>

<p>In this small project, you have learned, how to use Lettuce, a Java client for Redis to:</p>

<ul>
<li>publish messages to a stream</li>
<li>create a consumer group</li>
<li>consume messages using the consumer group.</li>
</ul>


<p>This is a very basic example, and in a next post I will show you how to work with multiple consumers, and to configure the Consumer Group and Consumers to control which messages you want to read</p>

<p>More to come!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MapR-DB JSON REST API]]></title>
    <link href="http://tgrall.github.io/blog/2018/04/23/getting-started-with-mapr-db-json-rest-api/"/>
    <updated>2018-04-23T14:37:51+02:00</updated>
    <id>http://tgrall.github.io/blog/2018/04/23/getting-started-with-mapr-db-json-rest-api</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>In this project you will learn how to use the MapR-DB JSON REST API to:</p>

<p>Create and Delete tables
Create, Read, Update and Delete documents (CRUD)
MapR Extension Package 5.0 (MEP) introduced the MapR-DB JSON REST API that allow application to use REST to interact with MapR-DB JSON.</p>

<p>You can find information about the MapR-DB JSON REST API in the documentation: <a href="https://maprdocs.mapr.com/home/MapR-DB/JSON_DB/UsingMapRDBJSONRESTAPI.html">Using the MapR-DB JSON REST API</a></p>

<!-- more -->


<h2>Prerequisites</h2>

<p>You system should have the following components:</p>

<ul>
<li>A running MapR 6.0.1 &amp; MEP 5.0 cluster with the MapR-DB REST API service installed</li>
<li><code>curl</code> or equivalent tool</li>
</ul>


<h2>Discover the MapR-DB JSON REST API</h2>

<p>The easiest way to discover it, is to use curl command (or equivalent).</p>

<p><strong>1 - Create a table</strong></p>

<pre><code>curl -X PUT \
  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp' \
  -u root:mapr \
  -k
</code></pre>

<p>In this command:</p>

<ul>
<li>the MapR-DB REST Service (MapR Data Access Gateway) is running on the mapr-node host with the default port <code>8243</code> using HTTPS</li>
<li>the HTTP verb <code>PUT</code> on <code>/api/v2/table/</code> endoint creates a new table</li>
<li>the protocol is HTTP since HTTPS is not enabled on this cluster</li>
<li>the new table will be created wit the path <code>/apps/emp</code> that is encoded to <code>%2Fapps%2Femp</code></li>
<li>the user <code>root</code> with the password <code>mapr</code> is used for authentication, using basic authentication</li>
<li>the <code>-k</code> parameter is used to indicate to turn off curlâ€™s verification of the certificate.</li>
</ul>


<p>In this example, you use the basic authentication, it is also possible to use <a href="https://jwt.io/introduction/">JSON Web Token</a>. You will learn more about this when you will write an application in Go.</p>

<p><strong>2 - Insert Documents</strong></p>

<p>Insert one document</p>

<pre><code>curl -X POST \
  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp' \
  -u root:mapr \
  -H 'Content-Type: application/json' \
  -d '{"_id":"user001","first_name":"John","last_name":"Doe", "age" : 28}' \
  -k
</code></pre>

<p>In this command:</p>

<ul>
<li>the <code>/api/v2/table/{path}</code> with the verb <code>GET</code> is used with a <code>condition</code> query parameter</li>
<li>the OJAI JSON syntax is used to express the condition: <code>{"$eq":{"last_name":"Doe"}}</code></li>
</ul>


<p><strong>3 - Update a document</strong></p>

<p>The following example will increment the age by 1 and update the last name.</p>

<pre><code>curl -X POST \
  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp%2F/document/user001' \
  -u root:mapr \
  -H 'Content-Type: application/json' \
  -d '{"$set" : {"last_name" : "New Doe"}, "$increment" : {"age":1}}' \
  -k
</code></pre>

<p>In this comamnd:</p>

<ul>
<li>the URL points to the document <code>_id</code> to update</li>
<li>the HTTP verb <code>POST</code> is used to modify the resource</li>
<li>the request body <code>-d</code> is the OJAI JSON Mutation that update the last name and increment the age.</li>
</ul>


<p>You can check that the document has been updated using the following command:</p>

<pre><code>curl -X GET \
  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp%2F/document/user001' \
  -u root:mapr \
  -k
</code></pre>

<p><strong>4 - Delete a document</strong></p>

<p>Delete the document with the <code>_id</code> user001.</p>

<pre><code>curl -X DELETE \
  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp%2F/document/user001' \
  -u root:mapr \
  -k
</code></pre>

<p>In this command:</p>

<ul>
<li>the URI <code>/api/v2/table/{path}/document/{id}</code> with the HTTP verb <code>DELETE</code> is used to delete the document</li>
</ul>


<p><strong>5 - Delete the MapR-DB JSON table</strong></p>

<p>The last step of this tutorial is to delete the table using the following command:</p>

<pre><code>curl -X DELETE \
  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp' \
  -u root:mapr \
  -k
</code></pre>

<h2>Conclusion</h2>

<p>In this tutorial you have learned how to use the MapR-DB JSON REST API to:</p>

<ul>
<li>Create a table</li>
<li>Insert and query documents</li>
<li>Update and delete documents</li>
<li>Drop table</li>
</ul>


<p>You can now use the API to create MapR-DB JSON Application using your favorite language.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MapR-DB Table Replication]]></title>
    <link href="http://tgrall.github.io/blog/2017/08/08/getting-started-with-mapr-db-table-replication/"/>
    <updated>2017-08-08T10:01:19+02:00</updated>
    <id>http://tgrall.github.io/blog/2017/08/08/getting-started-with-mapr-db-table-replication</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>MapR-DB Table Replication allows data to be replicated to another table that could be on on the same cluster or in another cluster. This is different from the automatic and intra-cluster replication that copies the data into different physical nodes for high availability and prevent data loss.</p>

<p>This tutorial focuses on the MapR-DB Table Replication that replicates data between tables on different clusters.</p>

<p>Replicating data between different clusters allows you to:</p>

<ul>
<li>provide another level of disaster recovery that protects your data and applications against global data center failure,</li>
<li>push data close to the applications and users,</li>
<li>aggregate the data from mutliple datacenters.</li>
</ul>


<p><strong>Replication Topologies</strong></p>

<p>MapR-DB Table Replication provides various topologies to adapt the replication to the business and technical requirements:</p>

<ul>
<li><em>Master-slave replication</em> : in this topology, you replicate one way from source tables to replicas. The replicas can be in a remote cluster or in the cluster where the source tables are located.</li>
<li><em>Multi-Master replication</em> : in this replication topology, there are two master-slave relationships, with each table playing both the role of a master and a slave. Client applications update both tables and each table replicates updates to the other.</li>
</ul>


<p>In this example you will learn how to setup multi-master replication.</p>

<!-- more -->


<h3>Prerequisites</h3>

<ul>
<li>2 MapR Clusters 5.x with Enterprise Edition license

<ul>
<li>in this demonstration they are called <code>cluster1</code> and <code>cluster2</code></li>
</ul>
</li>
</ul>


<h2>Setting Up Replication</h2>

<p>In the next steps you will configure your clusters to enable mutip-master replication as follow:</p>

<p><img src="http://tgrall.github.io/images/posts/maprdb-replication/replication.png" alt="Architecture" /></p>

<h3>Configuring the clusters</h3>

<p>Each node of the source cluster must communicate with the destination cluster&rsquo;s CLDB nodes. On each node of your source cluster edit the <code>mapr-clusters.conf</code> file and add the destination cluster information.</p>

<p><em>Cluster 1 Configuration</em></p>

<p>In all the nodes of <code>cluster1</code>, edit the  <code>/opt/mapr/conf/mapr-clusters.conf</code> file and add the <code>cluster2</code> configuration. The file should look like the following:</p>

<pre><code>cluster1 secure=false cluster1-node1:7222 cluster1-node2:7222 cluster1-node2:7222

cluster2 secure=false cluster2-node1:7222 cluster2-node2:7222 cluster2-node3:7222
</code></pre>

<p><em>Cluster 2 Configuration</em></p>

<p>In all the nodes of <code>cluster2</code>, edit the  <code>/opt/mapr/conf/mapr-clusters.conf</code> file and add the <code>cluster1</code> configuration. The file should look like the following:</p>

<pre><code>cluster2 secure=false cluster2-node1:7222 cluster2-node2:7222 cluster2-node3:7222

cluster1 secure=false cluster1-node1:7222 cluster1-node2:7222 cluster1-node2:7222
</code></pre>

<p>You can find information about the <code>mapr-clusters.conf</code> format in <a href="http://maprdocs.mapr.com/home/ReferenceGuide/mapr-clusters.conf.html">the documentation</a>.</p>

<p>Open a terminal window on one of the <code>cluster1</code> node using <code>mapr</code> user, and do the following:</p>

<pre><code>$ ls /mapr/cluster1/
apps   hbase  installer  opt  tmp  user  var

$ ls /mapr/cluster2/
apps   hbase  installer  opt  tmp  user  var
</code></pre>

<h3>Installing and Configuring the MapR Gateway</h3>

<p>A MapR gateway mediates one-way communication between a source MapR cluster and a destination MapR cluster. In this example you will use mult-master replication, this means that data will be replicated from <code>cluster1</code> to <code>cluster2</code> and from <code>cluster2</code> to <code>cluster1</code>.</p>

<p>The good practice is to install the MapR-Gateway to the destination cluster, so in our case let&rsquo;s install one gateway on one of the <code>cluster1</code> node, and one gateway on one of the <code>cluster2</code> node. Note that this configuration will not be highly available, and usually you will deploy more than 1 gateway by cluster.</p>

<h4>Installing the MapR-Gateway</h4>

<p>As root on one node of the <code>cluster1</code>, adapt the command to your linux environment, for example on the node <code>cluster1-node2</code></p>

<pre><code>$ yum install mapr-gateway


# Update MapR configuration
$ /opt/mapr/server/configure.sh -N cluster1 -C cluster1-node1:7222,cluster1-node2:7222,cluster1-node3:7222 -R
</code></pre>

<p>Do the same on <code>cluster2</code>, for example on the node <code>cluster2-node2</code>:</p>

<pre><code>$ yum install mapr-gateway


# Update MapR configuration
$ /opt/mapr/server/configure.sh -N cluster1 -C cluster2-node1:7222,cluster2-node2:7222,cluster2-node3:7222 -R
</code></pre>

<h4>Registering the Gateway to the Clusters</h4>

<p>Now that we have a gateway running on each cluster, you have to <strong><em>register the gateway</em></strong> in each cluster.</p>

<p>On <code>cluster1</code> run the following command to register the <code>cluster2</code> gateway as destination:</p>

<pre><code>$ maprcli cluster gateway set -dstcluster cluster2 -gateways cluster2-node2

# Check the configuration
$ maprcli cluster gateway list
</code></pre>

<p>On <code>cluster2</code> run the following command to register the <code>cluster1</code> gateway as destination:</p>

<pre><code>$ maprcli cluster gateway set -dstcluster cluster1 -gateways cluster1-node2

# Check the configuration
$ maprcli cluster gateway list
</code></pre>

<h3>Creating Table with Replication</h3>

<p>In a terminal window, as <code>mapr</code> user on <code>cluster1</code>, create a table and insert documents:</p>

<pre><code>$ maprcli table create -path /apps/user_profiles  -tabletype json
</code></pre>

<p>This create a new JSON table; it is also possible to use <code>/mapr/cluster1/apps/user_profiles</code>.</p>

<p>Let&rsquo;s now add documents using MapR-DB Shell:</p>

<pre><code>$ mapr dbshell

maprdb mapr:&gt; insert /apps/user_profiles --value '{"_id":"user001" , "first_name":"John", "last_name":"Doe"}'

maprdb mapr:&gt; find /apps/user_profiles
</code></pre>

<h4>Adding Table Replication</h4>

<p>Let&rsquo;s now enable replication between <code>user_profiles</code> on <code>cluster1</code> to a <code>user_profiles</code> table in <code>cluster2</code>.</p>

<p>In <code>cluster1</code>, on a terminal window as <code>mapr</code> run the following command:</p>

<pre><code>$ maprcli table replica autosetup -path /apps/user_profiles -replica /mapr/cluster2/apps/user_profiles -multimaster yes
</code></pre>

<p>You can get information about the replication configuration for the table using the following command:</p>

<pre><code>$ maprcli table replica list -path /apps/user_profiles -json
</code></pre>

<h4>Testing Replication</h4>

<p>Open another terminal in <code>cluster2</code> and use MapR-DB Shell to look at the replicated data:</p>

<pre><code>$ mapr dbshell

maprdb mapr:&gt; find /apps/user_profiles
{"_id":"user001","first_name":"John","last_name":"Doe"}
1 document(s) found.
</code></pre>

<p>You can also use the full path <code>/mapr/cluster2/apps/user_profiles</code></p>

<p>In <code>cluster1</code> add a new document using MapR-DB Shell:</p>

<pre><code>$ mapr dbshell

maprdb mapr:&gt; insert /apps/user_profiles --value '{"_id":"user002" , "first_name":"Simon", "last_name":"Dupont"}'

maprdb mapr:&gt; find /apps/user_profiles
</code></pre>

<p>Do a find in <code>cluster2</code> table, and you will see that the data have been replicated.</p>

<p>You can insert or delete a document in <code>cluster2</code> and do a find in <code>cluster1</code>, you will see that the new document is also replicated in the other direction.</p>

<p>Note, for this demonstration, we use 2 terminals connected to each cluster you can do some test using the Global Namespace in a single MapR-DB Shell.</p>

<h2>Conclusion</h2>

<p>In this tutorial you have learned how to setup the MapR-DB Multi-Master replication to have data automatically replicated between 2 clusters.</p>

<p>MapR-DB Table Replication provides many options, not only in term of topology (master-slave/mult-master), but also some options and commands to:</p>

<ul>
<li>replicate some columns/attributes or column family</li>
<li>configure replication in a secured cluster</li>
<li>pause replication.</li>
</ul>


<p>You can find more information about the MapR-DB Table Replication, and MapR-Gateway in the documentation:</p>

<ul>
<li><a href="http://maprdocs.mapr.com/home/MapR-DB/ReplicatingMapR-DBTables.html">Table Replication</a></li>
<li><a href="http://maprdocs.mapr.com/home/MapR-DB/ConfiguringMapRClustersForTR.html">Setting up Table Replication</a></li>
<li><a href="http://maprdocs.mapr.com/home/Gateways/MapRGateways.html">Configuring and Managing MapR Gateways</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to MongoDB Security]]></title>
    <link href="http://tgrall.github.io/blog/2015/02/04/introduction-to-mongodb-security/"/>
    <updated>2015-02-04T18:55:30+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/02/04/introduction-to-mongodb-security</id>
    <content type="html"><![CDATA[<p>Last week at the Paris MUG, I had a quick chat about security and MongoDB, and I have decided to create this post that explains how to configure out of the box security available in MongoDB.</p>

<p>You can find all information about MongoDB Security in following documentation chapter:</p>

<ul>
<li><a href="http://docs.mongodb.org/manual/security/">http://docs.mongodb.org/manual/security/</a></li>
</ul>


<p><img class="center" src="/images/posts/intro-mongodb-security/password.jpg"></p>

<p>In this post, <em>I won&rsquo;t go</em> into the detail about how to deploy your database in a secured environment (DMZ/Network/IP/Location/&hellip;)</p>

<p>I will focus on <strong>Authentication</strong> and <strong>Authorization</strong>, and provide you the steps to secure the access to your database and data.</p>

<p>I have to mention that by default, when you install and start MongoDB, security is not enabled. Just to make it easier to work with.</p>

<p>The first part of the security is the <strong>Authentication</strong>, you have multiple choices documented <a href="http://docs.mongodb.org/manual/core/authentication/">here</a>. Let&rsquo;s focus on &ldquo;MONGODB-CR&rdquo; mechanism.</p>

<p>The second part is <strong>Authorization</strong> to select what a user can do or not once he is connected to the database. The documentation about authorization is available <a href="http://docs.mongodb.org/manual/core/authorization/">here</a>.</p>

<p>Let&rsquo;s now document how-to:</p>

<ol>
<li>Create an Administrator User</li>
<li>Create Application Users</li>
</ol>


<p>For each type of users I will show how to grant specific permissions.</p>

<!-- more -->


<h2>1. Start MongoDB</h2>

<p>As I said before, by default security is not enabled when you start MongoDB; so the first think to do is to enable it using the <code>--auth</code> parameter.</p>

<pre><code>&gt; mkdir /data/db

&gt; mongod --auth

....
....
2015-02-04T06:56:37.875+0100 [conn1] note: no users configured in admin.system.users, allowing localhost access
...
</code></pre>

<p>MongoDB is starting, and until you have created a user you can connect from localhost to create some users (especially the administrator one). This is what is called the <em>localhost exception</em>.</p>

<p>Note: I am here documenting security in simple configuration, I invite you to look to the documentation when deploying a <a href="http://docs.mongodb.org/v2.2/administration/sharded-clusters/#sharded-cluster-security-considerations">Sharded cluster</a>.</p>

<p>Now that we have started MongoDB, we can create users.</p>

<h2>2. Create Admin User</h2>

<p>The first thing is to create an admin user, that can also create users, So we have to:</p>

<ol>
<li>go to the mongo shell</li>
<li>connect to the `admin&#8217; database</li>
<li>create a user and assign him the role <a href="http://docs.mongodb.org/manual/reference/built-in-roles/#userAdminAnyDatabase"><strong>userAdminAnyDatabase</strong></a></li>
</ol>


<pre><code>use admin

var user = {
    "user" : "admin",
    "pwd" : "manager",
    roles : [
        {
            "role" : "userAdminAnyDatabase",
            "db" : "admin"
        }
    ]
}

db.createUser(user);

exit
</code></pre>

<p>Now that you have created a user, in a MongoDB running with <code>--auth</code>, anonymous connections won&rsquo;t be able to do do anything with the database.</p>

<p>You can test for example to execute <code>show dbs</code> or <code>db.coll.insert({'x':0})</code> commands, you&rsquo;ll see authorization errors.</p>

<h3>Connect with the Admnistrator user</h3>

<p>Now that we have an admin user you can connect to the database with this user:</p>

<pre><code>
&gt; mongo admin -u admin -p
</code></pre>

<p>Our admin user, has the role <strong>userAdminAnyDatabase</strong>. With this role you can manage user; but this role cannot read/write data from application datatabases/collections.</p>

<p>So we need now to create a new user for our &ldquo;eCommerce&rdquo; application.</p>

<h2>3. Create Application User</h2>

<p>Now we will create a new user <em>website</em> that is responsible of the ecommerce database.</p>

<pre><code>&gt; mongo admin -u admin -p

use ecommerce

var user = {
    "user" : "website",
    "pwd" : "abc123",
    roles : [
        {
            "role" : "readWrite",
            "db" : "ecommerce"
        }
    ]
}

db.createUser(user);

exit
</code></pre>

<p>This user will be able to read/write on the <em>ecommerce</em> database</p>

<h3>Connect with the application user</h3>

<p>Using the mongo shell you can now connect and create/query data</p>

<pre><code>&gt; mongo ecommerce -u website -p

db.products.insert({ "title" : "MongoDB in Action"  });

db.products.findOne();

db.products.update({}, {"$set" : { "type" : "book" } })
</code></pre>

<p>As you can see this user has the perfect profile for your application.</p>

<p>Note, that if you try to query or modify another database with this user you will receive authorization exceptions.</p>

<h2>Create a reporting user (Read Only)</h2>

<p>You may need in your application, user that can only read data, let&rsquo;s say in all databases. For this you just need to assign the role <strong>readAnyDatabase</strong>.</p>

<pre><code>
&gt; mongo admin -u admin -p

var user = {
    "user" : "reporting",
    "pwd" : "abc123",
    roles : [
        {
            "role" : "readAnyDatabase",
            "db" : "admin"
        }
    ]
}

db.createUser(user);

exit
</code></pre>

<p>This user will be able to query all the databases and collections, including <code>show dbs</code> command.</p>

<p>Let&rsquo;s connect with the reporting user:</p>

<pre><code>&gt; mongo admin -u reporting -p

show dbs

use ecommerce

db.products.find();
</code></pre>

<p>If you try to inser/update/delete document you will receive an exception.</p>

<h2>Add new role to a user</h2>

<p>Let&rsquo;s now see how to add a new role to a user. For example I want to let the admin the power of read and write any database. For this I just need to add the role <strong>readWriteAnyDatabase</strong> to the admin user.</p>

<pre><code>&gt; mongo admin -u admin -p

db.grantRolesToUser(
    "admin",
    [{ "role" : "readWriteAnyDatabase", "db" : "admin" }]
)

db.getUser("admin");
</code></pre>

<p>Using the <code>db.grantRolesToUser</code> command I have added the role to the admin user, and using the <code>db.getUser</code> I can look at the user profile.</p>

<p>Now, admin user should be able to create new databases, collections and documents, let&rsquo;s try:</p>

<pre><code>use hr

db.employees.insert({ "name":"John Doe", "hire_date" : new Date() });

db.organization.insert({ "name" : "Development" });

db.employees.findOne();
</code></pre>

<h2>Create and use custom roles</h2>

<p>Another feature that is used a lot around security is related to the roles. In some case you want to provide multiple roles to a user, for example:</p>

<ul>
<li>all permission on database <em>ecommerce</em></li>
<li>read the collection <em>employees</em> in database <em>hr</em></li>
</ul>


<p>For this you can create a role that provide all the permissions and assign it to users. Let&rsquo;s do that using admin user.</p>

<pre><code>use admin

var role = {
    "role"  : "webSiteManagerRole",
    privileges : [
        {
            "resource": {"db" : "hr", "collection" : "employees"},
            "actions": ["find"]
        }
    ],
    "roles" : [
        {
            "role" : "readWrite",
            "db" : "ecommerce"
        }
    ]
}

db.createRole( role );

var user = {
    "user" : "master",
    "pwd" : "abc123",
    roles : [
        {
            "role" : "webSiteManagerRole",
            "db" : "admin"
        }
    ]
}

db.createUser(user);

exit
</code></pre>

<p>If you connect now with the user &ldquo;master&rdquo;, you will see that, the user:</p>

<ul>
<li>can do anything you want in the ecommerce database</li>
<li>can read the &ldquo;hr.employees&rdquo; collection, on only this</li>
<li>cannot do anything else.</li>
</ul>


<h2>Roles and Privileges</h2>

<p>As you have seen in the previous section, you can create roles, and assign privileges to these roles. This is very powerful and you can really control each action on the database.</p>

<p>I am inviting you to look in detail to the built-in roles and privileges, this will help you a lot to select the proper ones for your application:</p>

<ul>
<li><a href="http://docs.mongodb.org/manual/reference/built-in-roles/">Built-in Roles</a></li>
<li><a href="http://docs.mongodb.org/manual/reference/privilege-actions/">Privileges</a></li>
</ul>


<h2>Conclusion</h2>

<p>In this blog post I quickly explained, how to:</p>

<ul>
<li>Use MongoDB Authentication</li>
<li>Create Users</li>
<li>Assign Roles and Privileges for Users.</li>
</ul>


<p>It is interesting to know that everything that I have showed you in the shell could be done from a user interface in <a href="http://mms.mongodb.com">MMS</a></p>
]]></content>
  </entry>
  
</feed>
