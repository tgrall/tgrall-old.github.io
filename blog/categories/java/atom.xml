<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | Tug's Blog]]></title>
  <link href="http://tgrall.github.io/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://tgrall.github.io/"/>
  <updated>2020-01-02T17:13:18+01:00</updated>
  <id>http://tgrall.github.io/</id>
  <author>
    <name><![CDATA[Tug Grall]]></name>
    <email><![CDATA[tugdual@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Use SSL/TLS With Redis Enterprise]]></title>
    <link href="http://tgrall.github.io/blog/2020/01/02/how-to-use-ssl-slash-tls-with-redis-enterprise/"/>
    <updated>2020-01-02T10:47:13+01:00</updated>
    <id>http://tgrall.github.io/blog/2020/01/02/how-to-use-ssl-slash-tls-with-redis-enterprise</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/posts/how-to-use-ssl-slash-tls-with-redis-enterprise/000_header.jpeg"></p>

<p>In this article I will explain how to secure your Redis databases using SSL (Secure Sockets Layer). In production it is a good practise to use SSL to protect the data that are moving between various computers (client applications and Redis servers). Transport Level Security (TLS) guarantee that only allowed applications/computers are connected to the database, and also that data are not viewed or altered by a middle man process.</p>

<p>You can secure the connections between your client applications and Redis cluster using:</p>

<ul>
<li>One-Way SSL: the client (your application) get the certificate from the server (Redis cluster), validate it, and then all communications are encrypted</li>
<li>Two-Way SSL: (aka mutual SSL) here both the client and the server authenticate each other and validate that both ends are trusted.</li>
</ul>


<p>In this article, I will focus on the Two-Way SSL, and using Redis Enterprise.</p>

<!-- more -->


<p>Prerequisites:</p>

<ul>
<li>A Redis Enterprise 5.4.x database, <em>(my database is protected by the password <code>secretdb01</code>, and listening on port <code>12000</code>)</em></li>
<li><code>redis-cli</code> to run basis commands</li>
<li>Python, Node and Java installed if you want to test various languages.</li>
</ul>


<p><strong>Simple  Test</strong></p>

<p>Let&rsquo;s make sure that the database is available:</p>

<pre><code>redis-cli -p 12000 -a secretdb01 INFO SERVER
</code></pre>

<p>This should print the Server information.</p>

<h4>1- Get the Certificate from Redis Cluster</h4>

<p>You have access to the Redis Enterprise Cluster, you go to one of the to retrieve the certificate (that is a self generated one by default).</p>

<p>The cluster certificate is located at: <code>/etc/opt/redislabs/proxy_cert.pem</code>.</p>

<p>You have to copy it on each client machine; note that once it is done you can use this certificate to connect using &ldquo;One-Way SSL&rdquo;, but not the purpose of this article.</p>

<p>In my demonstration I am using Docker and copy the certificate using this command from my host:</p>

<pre><code>docker cp redis-node1:/etc/opt/redislabs/proxy_cert.pem ./certificates
</code></pre>

<h4>2- Generate a New Client Certificate</h4>

<p>Using the Two-Way SSL you need to have a certificate for the client that will be use by Redis database proxy to trust the client.</p>

<p>In this article I will use a self signed certificate using OpenSSL,in this example we care creating a certificate for an application named <code>app_001</code>.</p>

<p>You can create as many certificate as you want, or reuse this one for all servers/applications.</p>

<p>Open a terminal and run the following commands:</p>

<pre><code class="bash ">
openssl req \
  -nodes \
 -newkey rsa:2048 \
 -keyout client_key_app_001.pem \
 -x509 \
 -days 36500 \
 -out client_cert_app_001.pem
</code></pre>

<p>This command generate a new ckient key (<code>client_key_001.pem</code>) and certificate (<code>client_cert_001.pem</code>) with no passphrase.</p>

<h4>3- Configure the Redis Datatabse</h4>

<p>The next step is to take the certificate and add it to the database you want to protect.</p>

<p>Let&rsquo;s copy the certificate and paste it into the Redis Enterprise Web Console.</p>

<p>Copy the certificate in your clipboard:</p>

<p>Mac:
<code>bash
pbcopy &lt; client_cert_app_001.pem
</code></p>

<p>Linux:
<code>bash
 xclip -sel clip &lt; client_cert_app_001.pem
</code></p>

<p>Windows:
<code>bash
clip &lt; client_cert_app_001.pem
</code></p>

<p>Go to the Redis Enterprise Admin Web Console and enable TLS on your database:</p>

<ol>
<li>Edit the database configuration</li>
<li>Check TLS</li>
<li>Select &ldquo;Require TLS for All communications&rdquo;</li>
<li>Check &ldquo;Enforce client authentication&rdquo;</li>
<li>Paste the certificate in the text area</li>
<li>Click the Save button to save the certificate</li>
<li>Clic the Udpate button to save the configuration.</li>
</ol>


<p><img class="center" src="/images/posts/how-to-use-ssl-slash-tls-with-redis-enterprise/001-tls-configuration.png"></p>

<p>The database is now protected, and it is mandatory to use the SSL certificate to connect to it.</p>

<pre><code>redis-cli -p 12000 -a secretdb01 INFO SERVER
(error) ERR unencrypted connection is prohibited
</code></pre>

<h4>4- Connect to the Database using the Certificate</h4>

<p>In all these example, I am using a &ldquo;self-signed&rdquo; certificate, so I do not check the validity of the hostname.
You should adapt the connections/TLS information based on your certificate configuration.</p>

<h4>4.1 Using Redis-CLI</h4>

<p>To connect to a SSL protected database using <code>redis-cli</code> you have to use <a href="https://www.stunnel.org/index.html"><code>stunnel</code></a>.</p>

<p>Create a <code>stunnel.conf</code> file with the following content:</p>

<pre><code>cert = /path_to/certificates/client_cert_app_001.pem
key = /path_to/certificates/client_key_app_001.pem
cafile = /path_to/certificates/proxy_cert.pem
client = yes

[redislabs]
accept = 127.0.0.1:6380
connect = 127.0.0.1:12000
</code></pre>

<p>This will start a process that listen to port <code>6380</code> and used as a proxy to the Redis Enterprise database on port <code>12000</code>.</p>

<pre><code>redis-cli -p 6380 -a secretdb01 INFO SERVER
</code></pre>

<h5>4.2 Using Python</h5>

<p>Using Python, you have to set the SSL connection parameters:</p>

<pre><code class="python">#!/usr/local/bin/python3

import redis
import pprint

try:
  r = redis.StrictRedis(
    password='secretdb01',
    decode_responses=True,
    host='localhost',
    port=12000,
    ssl=True, 
    ssl_keyfile='./client_key_app_001.pem', 
    ssl_certfile='./client_cert_app_001.pem', 
    ssl_cert_reqs='required', 
    ssl_ca_certs='./proxy_cert.pem',
    )

  info = r.info()
  pprint.pprint(info)

except Exception as err:
  print("Error connecting to Redis: {}".format(err))
</code></pre>

<p>More information in the documentation &ldquo;<a href="https://redislabs.com/lp/python-redis/">Using Redis with Python</a>&rdquo;.</p>

<h5>4.3 Using Node.JS</h5>

<p>For <a href="http://redis.js.org/">Node Redis</a>, use the <a href="https://nodejs.org/api/tls.html">TLS</a> library to configure the client connection:</p>

<pre><code class="javascript">var redis = require("redis");
var tls = require('tls');
var fs = require('fs');

var ssl = {
    key: fs.readFileSync('../certificates/client_key_app_001.pem',encoding='ascii'),
    cert: fs.readFileSync('../certificates/client_cert_app_001.pem',encoding='ascii'),
    ca: [ fs.readFileSync('../certificates/proxy_cert.pem',encoding='ascii') ],
    checkServerIdentity: () =&gt; { return null; },
};

var client = redis.createClient(12000,'127.0.0.1', 
    {
      password : 'secretdb01',
      tls: ssl
    }
);

client.info( "SERVER", function (err, reply) {
    console.log(reply);
} );
</code></pre>

<p>More information in the documentation &ldquo;<a href="https://redislabs.com/lp/node-js-redis/">Using Redis with Node.js</a>&rdquo;.</p>

<h3>4.4 Using Java</h3>

<p>In Java, to be able to connect using SSL, you have to install all the certificates in the Java environment using the <a href="https://docs.oracle.com/en/java/javase/11/tools/keytool.html">keytool</a> utility.</p>

<p>Create a <strong>keystore</strong> file that stores the key and certificate you have created earlier:</p>

<pre><code>openssl pkcs12 -export \
  -in ./client_cert_app_001.pem \
  -inkey ./client_key_app_001.pem \
  -out client-keystore.p12 \
  -name "APP_01_P12"
</code></pre>

<p>As you can see the keystore is used to store the credentials associated with you client; it will be used later with the <code>-javax.net.ssl.keyStore</code> system property in the Java application.</p>

<p>In addition to the keys tore, you also have to create a trustore, that is used to store other credential for example in our case the redis cluster certificate.</p>

<p>Create a <strong>trustore</strong> file and add the Redis cluster certificate to it</p>

<pre><code>keytool -genkey \
  -dname "cn=CLIENT_APP_01" \
  -alias truststorekey \
  -keyalg RSA \
  -keystore ./client-truststore.p12 \
  -keypass secret
  -storepass secret
  -storetype pkcs12
</code></pre>

<pre><code>keytool -import \
  -keystore ./client-truststore.p12 \
  -file ./proxy_cert.pem \
  -alias redis-cluster-crt
</code></pre>

<p>The trustore will be used later with the <code>-javax.net.ssl.trustStore</code> system property in the Java application.</p>

<pre><code>-Djavax.net.ssl.keyStore=/Users/tgrall/projects/demos/ssl/blog/certificates/java/client-keystore.p12
-Djavax.net.ssl.keyStorePassword=secret
-Djavax.net.ssl.trustStore=/Users/tgrall/projects/demos/ssl/blog/certificates/java/client-truststore.p12
-Djavax.net.ssl.trustStorePassword=secret
</code></pre>

<p>For this example and simplicity, I will hard code these property in the Java code itself:</p>

<pre><code class="java">
import redis.clients.jedis.Jedis;
import java.net.URI;

public class SSLTest {

    public static void main(String[] args) {

        System.setProperty("javax.net.ssl.keyStore", "/path_to/certificates/client-keystore.p12");
        System.setProperty("javax.net.ssl.keyStorePassword", "secret");

        System.setProperty("javax.net.ssl.trustStore","/path_to/certificates/client-truststore.p12");
        System.setProperty("javax.net.ssl.trustStorePassword","secret");

        URI uri = URI.create("rediss://127.0.0.1:12000");

        Jedis jedis = new Jedis(uri);
        jedis.auth("secretdb01");


        System.out.println(jedis.info("SERVER"));
        jedis.close();
    }

}
</code></pre>

<ul>
<li>line 8-12, the system environment variable are set to point to the keystore and trustore (this should be externalized)</li>
<li>line 14, the Redis URL start with <code>rediss</code> with 2 s to indicate that the connection should be encrypted</li>
<li>line 17, set the database password</li>
</ul>


<p>More information in the documentation &ldquo;<a href="https://redislabs.com/lp/redis-java/">Using Redis with Java</a>&rdquo;.</p>

<h2>Conclusion</h2>

<p>In this article, you have learned how to:</p>

<ul>
<li>retrieve the Redis Server certificate</li>
<li>generate a client certificate</li>
<li>protect your database to enforce transport level security (TLS) with 2 ways authentication</li>
<li>connect to the database from <code>redis-cli</code>, Python, Node and Java</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis Rolling Upgrade on Pivotal Cloud Foundry (PCF)]]></title>
    <link href="http://tgrall.github.io/blog/2019/09/19/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/"/>
    <updated>2019-09-19T05:05:23+02:00</updated>
    <id>http://tgrall.github.io/blog/2019/09/19/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf</id>
    <content type="html"><![CDATA[<h3>Introduction</h3>

<p>In this article, I will show you how to update Redis Enterprise on PCF and see how Redis Enterprise cluster will guarantee a service continuity using out of the box failover.</p>

<p>If you need a Cloud Foundry application that calls Redis automatically you can use this <a href="https://github.com/tgrall/simple-redis-spring-demo-pcf">project simple-redis-spring-demo-pcf</a>.</p>

<p>For this article, I will upgrade <a href="https://docs.pivotal.io/partners/redis-labs-enterprise-pack/index.html">Redis Enterprise for PCF</a> from the version v5.4.2400147 to the latest version, currently v5.4.40700169.</p>

<!--more -->


<p><strong>Prerequisites</strong></p>

<ul>
<li>Pivotal Cloud Foundry up &amp; running

<ul>
<li>Administrator access to Ops Manager and Apps Manager</li>
</ul>
</li>
<li>One of more Redis databases running on PCF

<ul>
<li>My environment has2 databases in version v5.4.2400147</li>
<li>One wit replication (<code>db:4</code>) another one without replication (<code>db:5</code>)</li>
</ul>
</li>
</ul>


<h3>Initial Environment</h3>

<p>Let&rsquo;s take a look to the environment before the update; for this you can access the Redis Enterprise Cluster Management Console:</p>

<ul>
<li><a href="https://">https://</a>[Cluster Management Console Subdomain].[System Domain]</li>
<li>for example <a href="https://console-redis.sys.my-domain.cf-app.com">https://console-redis.sys.my-domain.cf-app.com</a> .</li>
</ul>


<blockquote><p>Do not use this to create/delete a database, you must use Cloud Foundry to do it. (<code>cf</code> command or UI)</p></blockquote>

<p>In the Web console, go to &ldquo;Cluster&rdquo; then &ldquo;Configuration&rdquo;, you can see the version of Redis Labs Enterprise Cluster (5.4.0-24), and Redis (5.0.2) versions.</p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/img-001-webui-cluster-version.png"></p>

<p>You can also use the <code>rladmin</code> command line to achieve this.</p>

<p><strong>Checking Redis cluster using the command line</strong></p>

<p>SSH to your Ops Manager and, <code>bosh ssh</code> to one of the Redis cluster VMs.</p>

<p>When I run the <code>bosh vms</code> command on my environment I can see the following VMs related to my Redis deployment:</p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/img-002-redis-vms-list.png"></p>

<p>The deployment is made of 5 VMs:</p>

<ul>
<li>the 3 first VMs are the Redis Nodes</li>
<li>the 2 others are related to the PCF integration (Registrar and Service Broker)</li>
</ul>


<p>We can look in more details into the role of each VMS in the cluster, for this I will <code>bosh ssh</code> into one of the nodes:</p>

<pre><code>$ bosh -d redis-enterprise-[your-deployment-id] ssh redis-enterprise-node/[your-vm-id]
</code></pre>

<p>Once connected use the <code>sudo rladmin status</code> to look at the Redis cluster deployed on PCF.</p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/img-003-rladmin-view.png"></p>

<p>In this cluster you see:</p>

<ul>
<li>in the <strong><em>Cluster Nodes</em></strong> section that we have 3 nodes in version 5.4.0-24</li>
<li>in the <strong><em>Databases</em></strong> section that we have 2 database instances, the name is generated by Cloud Foundry. In this environment, the <code>db:4</code> is replicated with shards on <code>node:1</code> (master) and <code>node:2</code> (slave/replica), while <code>db:5</code> is not replicated.</li>
</ul>


<p>Let&rsquo;s now see the Redis version of the databases using:</p>

<ul>
<li><code>sudo rladmin status databases extra redis_version</code></li>
</ul>


<p>As expected the version if 5.0.2, the same value that you have seen in the Web console.</p>

<h2>Installing the latest version of Redis Enterprise for PCF</h2>

<p>Once the latest release of Redis Enterprise on PCF is imported, the upgrade is easy to do:</p>

<ol>
<li>Click on &ldquo;Redis Enterprise on PCF&rdquo; in the left menu.</li>
<li>Click on the &ldquo;<strong>+</strong>&rdquo; link.

<ul>
<li>The tiles is updated to the new version, you can review the configuration, not needed in this tutorial.</li>
</ul>
</li>
<li><p>Click on &ldquo;Review Pending Changes&rdquo; button.
 <img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/img-004-tile-update.png"></p></li>
<li><p>Unselect all product except Redis</p></li>
<li>Click Apply Changes</li>
</ol>


<p>Once you have clicked the update process will start, and you can follow the progress using the log information.</p>

<p>Nevertheless, it is interesting to see what is happening behind the scene using the command line on the VMS.</p>

<p>The update process using PCF will do the following:</p>

<ul>
<li>Update and restart each node one by one (the 5 nodes of the Redis Enterprise deployment)</li>
<li>during these steps, Redis Cluster will fail over moving the master and endpoint to another node to provide service continuity to the applications.</li>
</ul>


<p>Let&rsquo;s look at the following screenshots to see how the rolling upgrade was done by PCF.</p>

<h4>Starting Point</h4>

<p>The cluster is up and running with 3 nodes with the version 5.4.0-24, and the <code>node:1</code> is the master of the cluster</p>

<p><strong><em>Cluster Nodes:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/001-rladmin-cluster-version.png"></p>

<p><strong><em>Endpoints:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/001-rladmin-cluster-version-endpoint.png"></p>

<p>The <code>node:1</code> is also the endpoint for the <code>db:4</code></p>

<p><strong><em>Shards:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/001-rladmin-cluster-db.png"></p>

<p>You can see 3 shards in this deployment:</p>

<ul>
<li><code>db:4</code> is replicated and has 2 shards the master on <code>node:1</code> and a replica on <code>node:2</code>, the failover will automatically happen with no data loss.</li>
<li><code>db:5</code> is not replicated and has a single shard, so the database will be recreated fresh on a new node during the update.</li>
</ul>


<p>So if you want to have a full service continuity with no data loss it is mandatory to use replication.</p>

<h4>PCF Updating Node 1</h4>

<p>PCF has now started the process and stopped the <code>node:1</code>.</p>

<p><strong><em>Cluster Nodes:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/002-rladmin-cluster-status.png"></p>

<p>All the nodes are still on the &ldquo;old version&rdquo;, but the cluster master has been moved now to <code>node:2</code>; so applications will continue to work.</p>

<p>The errors are here to indicate that the <code>node:1</code> is not accessible, and the <code>node:3</code> also raised an error since the replication link is not available.</p>

<p><strong><em>Endpoints:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/002-rladmin-cluster-version-endpoint.png"></p>

<p>Here we see that the <code>db:4</code> endpoint, now on <code>node:2</code>, Redis Enterprises cluster manager has moved the endpoint to this node automatically.</p>

<p><strong><em>Shards:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/002-rladmin-cluster-db.png"></p>

<ul>
<li><code>db:4</code> is up and the master shard has been moved from <code>node:1</code> to <code>node:2</code></li>
<li><code>db:5</code> is not present anymore, a new master will be created automatically on <code>node:3</code>, but empty.</li>
</ul>


<p>The fail over is done transparently with no impact for the application.</p>

<h4>PCF is restarting the updated Node 1</h4>

<p>Once the node:1 VM is restarted with the updated version of Redis Enterprise you can see the new version number and status.</p>

<p><strong><em>Cluster Nodes:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/003-rladmin-cluster-version.png"></p>

<p>The 3 nodes of the cluster are up and running, and you can see that the <code>node:1</code> has been updated to the new version 5.4.4-7.</p>

<p>The master is still the <code>node:2</code></p>

<p>For a short time the cluster will have heterogeneous nodes, this is not an issue.</p>

<p><strong><em>Shards:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/003-rladmin-cluster-db.png"></p>

<p>You can see that the <code>db:4</code> shards have the status <code>OK, OLD VERSION</code> that indicates that:</p>

<ul>
<li>the database is up and running</li>
<li>but the database itself has not yet been updated to the latest Redis version</li>
</ul>


<p>The update of the database is done automatically, so after a while, if you run the command <code>sudo rladmin status databases extra redis_version</code> you will see something like:</p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/003-rladmin-cluster-db-version.png"></p>

<h4>Updating all the nodes</h4>

<p>The PCF update will continue and upgrade:</p>

<ul>
<li><code>node:2</code>, Redis Cluster will move the masters (cluster, shard, endpoint) to another node, in our case <code>node:1</code> for the replicated database (<code>db:4</code>)</li>
<li>once the <code>node:2</code> is done the same work will be done on node 3.</li>
</ul>


<p><strong><em>Cluster Nodes:</em></strong></p>

<p>All the nodes of the clusters are now updated to the latest version of Redis Enterprise (5.4.4-7) supported on PCF.</p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/004-rladmin-cluster-version.png"></p>

<p><strong><em>Shards:</em></strong></p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/004-rladmin-cluster-db.png"></p>

<p>The update of the database is done automatically, so after a while if your run the command <code>sudo rladmin status databases extra redis_version</code> you will see something like:</p>

<p><img class="center" src="/images/posts/redis-rolling-upgrade-on-pivotal-cloud-foundry-pcf/steps/004-rladmin-cluster-db-version.png"></p>

<blockquote><p>In this example I am doing a “minor upgrade”, from Redis Cluster 5.4.0/Redis 5.0.2 to Redis Cluster 5.4.4/Redis 5.0.4, and everything is done automatically.</p>

<p>If you are doing a major upgrade for example from 4.x to 5.x, the cluster will automatically be updated to the proper release, but you will have to manually update the existing databases as documented here.</p></blockquote>

<h4>Updating Redis on PCF Services</h4>

<p>During the update, you will see other VMs stopped and started in the process. These VMs are used for:</p>

<ul>
<li>Redis Registrar</li>
<li>ResisLabs Service Broker</li>
</ul>


<p>These services and nodes are not part of the &ldquo;Redis Enterprise&rdquo; per se, but are part of the integration with PCF.</p>

<h2>Conclusion</h2>

<p>The update of the Redis Cluster is now complete:</p>

<ul>
<li>All the nodes are on 5.4.4-7 (from 5.4.0-024)</li>
<li>All the databases have been updated to the new Redis 5.0.4 (from 5.0.2)</li>
</ul>


<p>The upgrade has been done automatically without any interruptions of service:</p>

<ul>
<li>PCF scripts have been responsible for upgrading, stoping and starting each part of the installation in the correct order</li>
<li>while Redis Enterprise Cluster has been responsible for keeping the databases available for the applications, during the process.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Redis Streams &amp; Java]]></title>
    <link href="http://tgrall.github.io/blog/2019/09/02/getting-with-redis-streams-and-java/"/>
    <updated>2019-09-02T09:24:24+02:00</updated>
    <id>http://tgrall.github.io/blog/2019/09/02/getting-with-redis-streams-and-java</id>
    <content type="html"><![CDATA[<p>As you may have seen, I have joined <a href="https://www.redislabs.com">Redis Labs</a> a month ago; one of the first task as a new hire is to learn more about Redis. So I learned, and I am still learning.</p>

<p>This is when I discovered <a href="https://redis.io/topics/streams-intro">Redis Streams</a>. I am a big fan of streaming-based applications so it is natural that I start with a small blog post explaining how to use Redis Streams and Java.</p>

<p><strong><em>What is Redis Streams?</em></strong></p>

<p>Redis Streams is a Redis Data Type, that represents a log so you can add new information/message in an append-only mode <em>(this is not 100% accurate since you can remove messages from the log)</em>. Using Redis Streams you can build &ldquo;Kafka Like&rdquo; applications, what I mean by that you can:</p>

<ul>
<li>create applications that publish and consume messages (nothing extraordinary here, you could already do that with Redis Pub/Sub)</li>
<li>consume messages that are published even when your client application (consumer) is not running. This is a big difference with Redis Pub/Sub</li>
<li>consume messages starting a specific offset, for example, read the whole history, or only new messages</li>
</ul>


<p>In addition to this, Redis Streams has the concept of <strong>Consumer Groups</strong>. Redis Streams Consumer Groups, like Apache Kafka ones, allows the client applications to consume messages in a distributed fashion (multiple clients), providing an easy way to scale and create highly available systems.</p>

<p><img class="center" src="/images/posts/getting-with-redis-streams-and-java/redis-streams-101-img-1.png"></p>

<p>Enroll in the <a href="https://university.redislabs.com/courses/course-v1:redislabs+RU202+2019_03/about">Redis University: Redis Streams</a> to learn more and get certified.</p>

<p><strong><em>Sample Application</em></strong></p>

<p>The <a href="https://github.com/tgrall/redis-streams-101-java">redis-streams-101-java GitHub Repository</a> contains sample code that shows how to</p>

<ul>
<li>post messages to a streams</li>
<li>consume messages using a consumer group</li>
</ul>


<!--more -->


<h4>Prerequisites</h4>

<ul>
<li>Redis 5.x, you have here multiple options:

<ul>
<li><a href="https://redis.io">Download</a> and install Redis Community</li>
<li>Install and Run a Docker image: <a href="https://hub.docker.com/_/redis">Community</a> or <a href="https://hub.docker.com/r/redislabs/redis">Redis Enterprise</a></li>
<li>Create a online instance on <a href="https://redislabs.com/redis-enterprise/essentials/">Redis Labs Cloud</a> (30mb for free)</li>
</ul>
</li>
<li>Java 8 or later</li>
<li>Apache Maven 3.5.x</li>
<li>Git</li>
</ul>


<h3>Java &amp; Redis Streams</h3>

<p>Redis has many Java clients developed by the community, as you can see on the <a href="https://redis.io/clients#java">Redis.io site</a>.</p>

<p>It looks, based on my short experience with Redis so far, that the most complete one around Redis Streams support is <a href="https://lettuce.io">Lettuce</a>, this is the one I will be using in the following code.</p>

<h4>1- Adding Lettuce to Your Maven Project</h4>

<p>Add the following dependency to your project file:</p>

<pre><code class="xml">        &lt;dependency&gt;
            &lt;groupId&gt;io.lettuce&lt;/groupId&gt;
            &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
            &lt;version&gt;5.1.8.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>

<h4>2- Connecting to Redis</h4>

<p>Import the following classes</p>

<pre><code class="java">import io.lettuce.core.*;
import io.lettuce.core.api.StatefulRedisConnection;
import io.lettuce.core.api.sync.RedisCommands;
</code></pre>

<p>Then connect with:</p>

<pre><code class="java">RedisClient redisClient = RedisClient.create("redis://password@host:port"); // change to reflect your environment
StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect();
RedisCommands&lt;String, String&gt; syncCommands = connection.sync();
</code></pre>

<p>When your application is done with the connection you should disconnect with the following code:</p>

<pre><code class="java">connection.close();
redisClient.shutdown();
</code></pre>

<h4>3- Sending Message to Streams</h4>

<p>Once you have a connection you can send a message. In this example, I will let Redis generate the message ID, which is time-based, and the body will be built using a Map representing IoT data, for example, a weather data capturing Wind speed and direction in real-time.</p>

<pre><code class="java">    public static void main(String[] args) {

        RedisClient redisClient = RedisClient.create("redis://localhost:6379"); // change to reflect your environment
        StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect();
        RedisCommands&lt;String, String&gt; syncCommands = connection.sync();

        Map&lt;String, String&gt; messageBody = new HashMap&lt;&gt;();
        messageBody.put( "speed", "15" );
        messageBody.put( "direction", "270" );
        messageBody.put( "sensor_ts", String.valueOf(System.currentTimeMillis()) );

        String messageId = syncCommands.xadd(
                "weather_sensor:wind",
                messageBody);

        System.out.println( String.format("Message %s : %s posted", messageId, messageBody) );

        connection.close();
        redisClient.shutdown();

    }
</code></pre>

<p>Let me explain the code:</p>

<ul>
<li>Lines 3-5 are used to connect to Redis</li>
<li>Lines 7-10 are used to create the message body, using a Map, since Redis Streams messages are string key/values.</li>
<li>Lines 12-14 call the <code>syncCommands.xadd()</code> method using the streams key &ldquo;weather_sensor:wind&rdquo; and the message body itself

<ul>
<li>this method returns the message ID.</li>
</ul>
</li>
<li>line 16 just print the message ID and content</li>
<li>the lines 18-19 close the connection and client.</li>
</ul>


<p>The complete producer code is available <a href="https://github.com/tgrall/redis-streams-101-java/blob/master/src/main/java/com/kanibl/redis/streams/simple/RedisStreams101Producer.java">here</a>.</p>

<h4>4- Consuming Messages</h4>

<p>Redis Streams offers various way to consume/read messages using the commands: <a href="https://redis.io/commands/xrange">XRANGE</a>, <a href="https://redis.io/commands/xrevrange">XREVRANGE</a>, <a href="https://redis.io/commands/xread">XREAD</a>, <a href="https://redis.io/commands/xreadgroup">XREADGROUP</a>.</p>

<p>I want to keep the article short and close to the way you would build an application with Apache Kafka, this is why I will use the <a href="https://redis.io/commands/xreadgroup">XREADGROUP</a> command from Lettuce.</p>

<p>The Consumer Groups allow developers to create a group of clients that will cooperate to consume messages from the streams (for scale and high availability); it is also a way to associate the client to specific applications roles; for example:</p>

<ul>
<li>a consumer group called &ldquo;data warehouse&rdquo; will consume messages and send them to a data warehouse</li>
<li>another consumer group called &ldquo;aggregator&rdquo; will consume the messages and aggregate the data and send them to another sink (another stream or storage)</li>
</ul>


<p>Each of this group will act independently, and each of this group could have multiple &ldquo;consumers&rdquo; (client).</p>

<p>Let&rsquo;s see how you use this in Java.</p>

<pre><code class="java">...

        try {
            // WARNING: Streams must exist before creating the group
            //          This will not be necessary in Lettuce 5.2, see https://github.com/lettuce-io/lettuce-core/issues/898
            syncCommands.xgroupCreate( XReadArgs.StreamOffset.from("weather_sensor:wind", "0-0"), "application_1"  );
        }
        catch (RedisBusyException redisBusyException) {
            System.out.println( String.format("\t Group '%s already' exists","application_1"));
        }


        System.out.println("Waiting for new messages");

        while(true) {

            List&lt;StreamMessage&lt;String, String&gt;&gt; messages = syncCommands.xreadgroup(
                    Consumer.from("application_1", "consumer_1"),
                    XReadArgs.StreamOffset.lastConsumed("weather_sensor:wind")
            );

            if (!messages.isEmpty()) {
                System.out.println( messages );
            }


        }

...
</code></pre>

<p>This code is a subset of the <code>main()</code> method I have removed the connection management part, to add readability. Let&rsquo;s take a look to the code:</p>

<ul>
<li>line 3 to 10, using the method <code>xgroupCreate()</code>, that matches the <a href="https://redis.io/commands/xgroup">XGROUP CREATE</a> command,

<ul>
<li>is used to create a new group called <code>application_1</code>,</li>
<li>consume messages from the stream <code>weather_sensor:wind</code></li>
<li>starting at the first message in the stream, this is indicated using the message ID <code>0-0</code>. <em>Note that it is also possible to indicate to the group to start to read at a specific message ID, or only the new messages that arrive after the creating of the consumer group using <code>$</code> special ID (or the helper method <code>XReadArgs.StreamOffset.latest()</code></em>.</li>
</ul>
</li>
<li>line 15 to 27, in this example we use an infinite loop (<code>while(true)</code>) to wait for any new messages published to the streams</li>
<li>line 17 to 20, the method <code>xreadgroup()</code> returns the messages based on the group configuration

<ul>
<li>line 18 define the consumer named <code>consumer_1</code> that is associated with the group <code>application_1</code>: you can create new group do distribute the read to multiple clients</li>
<li>line 19 indicates where to start, in this case, <code>StreamOffset.lastConsumed("weather_sensor:wind")</code> the consumer will consume messages that have not been read already. With the current configuration of the group (offset <code>0-0</code>), when the consumer will start for the first time, it will read all the existing messages.</li>
<li>the <a href="https://redis.io/commands/xreadgroup">XREADGROUP</a> command by default sends an acknowledgment for each consumed message.</li>
</ul>
</li>
</ul>


<p>The complete consumer code is available <a href="https://github.com/tgrall/redis-streams-101-java/blob/master/src/main/java/com/kanibl/redis/streams/simple/RedisStreams101Consumer.java">here</a>.</p>

<h3>Build &amp; Run the Simple Java Application</h3>

<p>Now that you have a better understanding of the code, let&rsquo;s run the producer and consumer. You can run this from your IDE, or using Maven.</p>

<p>Let&rsquo;s do it using Maven CLI, for this open 2 terminals:</p>

<ul>
<li>one to produce messages</li>
<li>one to consume them</li>
</ul>


<p><em>1- Clone and Build the project</em></p>

<pre><code class="bash">&gt; git clone https://github.com/tgrall/redis-streams-101-java.git

&gt; cd redis-streams-101-java

&gt; mvn clean verify
</code></pre>

<p><em>2- Post a new message</em></p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Producer"
</code></pre>

<p><em>3- Consume messages</em></p>

<p>Open a new terminal and run the following command:</p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Consumer"
</code></pre>

<p>The consumer will start and consume the message you just posted, and wait for any new messages.</p>

<p><em>4- In the first terminal post 100 new messages</em></p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Producer" -Dexec.args="100"
</code></pre>

<p>The consumer will receive and print all the messages.</p>

<p><em>5- Kill the consumer and post more messages</em></p>

<p>Let&rsquo;s now do another test, stop the consumer using a simple <code>ctrl+C</code>.</p>

<p>Then post 5 new messages.</p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Producer" -Dexec.args="5"
</code></pre>

<p>The messages are not yet consumed by any application, but still store in Redis Streams.</p>

<p>So when you start the consumer, it will consumes these new messages.</p>

<pre><code class="bash">
&gt; mvn exec:java -Dexec.mainClass="com.kanibl.redis.streams.simple.RedisStreams101Consumer"
</code></pre>

<p>This is a one of the differences between <a href="https://redis.io/topics/streams-intro">Redis Streams</a> and <a href="https://redis.io/topics/pubsub">Redis PubSub</a>. The producer application has publish many messages while the consumer application was not running. Since the consumer is ran with <code>StreamOffset.lastConsumed()</code>, when the consumer is starting, it looks to the last consumed ID, and start to read the streams from there. This method generate a XGROUPREAD command with the group</p>

<h3>Conclusion</h3>

<p>In this small project, you have learned, how to use Lettuce, a Java client for Redis to:</p>

<ul>
<li>publish messages to a stream</li>
<li>create a consumer group</li>
<li>consume messages using the consumer group.</li>
</ul>


<p>This is a very basic example, and in a next post I will show you how to work with multiple consumers, and to configure the Consumer Group and Consumers to control which messages you want to read</p>

<p>More to come!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MQTT and Java]]></title>
    <link href="http://tgrall.github.io/blog/2017/01/02/getting-started-with-mqtt/"/>
    <updated>2017-01-02T16:03:09+01:00</updated>
    <id>http://tgrall.github.io/blog/2017/01/02/getting-started-with-mqtt</id>
    <content type="html"><![CDATA[<p>MQTT (MQ Telemetry Transport) is a lightweight publish/subscribe messaging protocol.
MQTT is used a lot in the Internet of Things applications, since it has been designed to
run on remote locations with system with small footprint.</p>

<p>The MQTT 3.1 is an OASIS standard, and you can find all the information at <a href="http://mqtt.org/">http://mqtt.org/</a></p>

<p>This article will guide you into the various steps to run your first MQTT application:</p>

<ol>
<li>Install and Start a MQTT Broker</li>
<li>Write an application that publishes messages</li>
<li>Write an application that consumes messages</li>
</ol>


<p>The source code of the sample application is available on <a href="https://github.com/tgrall/mqtt-sample-java">GitHub</a>.</p>

<!-- more -->


<h4>Prerequisites</h4>

<ul>
<li>Apache Maven 3.x</li>
<li>Git</li>
</ul>


<h3>Install and Start a MQTT Broker</h3>

<p>You can find many MQTT Brokers, for this example I will use one of the most common broker <a href="https://mosquitto.org">Mosquitto</a>.</p>

<p>You can download and install from the <a href="https://mosquitto.org/download/">binary package</a>. I have used <a href="http://brew.sh/">Homebrew</a> to install it on my Mac:</p>

<pre><code>$ brew install mosquitto
</code></pre>

<p>Start the MQTT Broker with the default configuration</p>

<pre><code>$ /usr/local/sbin/mosquitto
</code></pre>

<h3>Publish and Consume messages</h3>

<p>Open two terminal windows and run the following commands :</p>

<p>Consume</p>

<pre><code>$ mosquitto_sub -h 127.0.0.1 -t iot_data
</code></pre>

<p>Publish</p>

<pre><code>$ mosquitto_pub -h 127.0.0.1 -t iot_data -m "Hello world"
</code></pre>

<p>You should see the message <code>Hello world</code> in the consumer/subscriber window.</p>

<h3>Write your first MQTT Application</h3>

<p>For this example I will write a small Java application, since it is the language
that I am using in my global project.</p>

<h4>Maven Dependencies</h4>

<p>Add the <a href="https://eclipse.org/paho/">Eclipse Paho</a> dependency to your Maven project</p>

<pre><code class="xml">&lt;dependency&gt;
  &lt;groupId&gt;org.eclipse.paho&lt;/groupId&gt;
  &lt;artifactId&gt;org.eclipse.paho.client.mqttv3&lt;/artifactId&gt;
  &lt;version&gt;1.1.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<h4>Publishing a Message</h4>

<p>Publishing a message is quite easy, create a MqttClient and use it to post on a topic.</p>

<pre><code class="java">MqttClient client = new MqttClient("tcp://localhost:1883", MqttClient.generateClientId());
client.connect();
MqttMessage message = new MqttMessage();
message.setPayload("Hello world from Java".getBytes());
client.publish("iot_data", message);
client.disconnect();
</code></pre>

<p>You have many other options, configurations that you can use when posting a message
such as security, quality of service (QoS), and more; but in this post I want to simply
show how easy is to publish and consume MQTT messages.</p>

<h4>Consuming messages</h4>

<p>To consume messages you need to implement a <code>org.eclipse.paho.client.mqttv3.MqttCallback</code> that will receive the message and used this Callback class in the MqttClient of the Subscriber application.</p>

<p>The Callback class:</p>

<pre><code class="java">public class SimpleMqttCallBack implements MqttCallback {

  public void connectionLost(Throwable throwable) {
    System.out.println("Connection to MQTT broker lost!");
  }

  public void messageArrived(String s, MqttMessage mqttMessage) throws Exception {
    System.out.println("Message received:\n\t"+ new String(mqttMessage.getPayload()) );
  }

  public void deliveryComplete(IMqttDeliveryToken iMqttDeliveryToken) {
    // not used in this example
  }
}
</code></pre>

<p>This Callback class is used in the Subscriber application as follow:</p>

<pre><code class="java">MqttClient client=new MqttClient("tcp://localhost:1883", MqttClient.generateClientId());
client.setCallback( new SimpleMqttCallBack() );
client.connect();
</code></pre>

<p>Like for the publisher, I am using the broker and client without any option (QoS, security).</p>

<h2>Build and Run the Application</h2>

<p><strong>1- Get the Sample Code</strong></p>

<p>Clone the project from GitHub</p>

<pre><code>$ git clone https://github.com/tgrall/mqtt-sample-java.git
</code></pre>

<p><strong>2- Build the project with Apache Maven:</strong></p>

<p>This project is a simple Java application that runs a publisher and subscriber using the <a href="https://eclipse.org/paho/">Eclipse Paho library</a>.</p>

<pre><code>$ mvn clean package
</code></pre>

<p>For convenience, the example programs project is set up so that the maven package target produces a single executable,
<code>/mqtt-sample</code>, that includes all of the example programs and dependencies.</p>

<p><strong>3- Run the Subscriber</strong></p>

<p>The subscriber will receive and print all messages published on the <code>iot_data</code> topic.</p>

<pre><code>$ ./target/mqtt-sample subscriber
</code></pre>

<p><strong>4- Run the Publisher</strong></p>

<p>Run the publisher with the following command, the second parameter is the message to publish</p>

<pre><code>$ ./target/mqtt-sample publisher "My first MQTT message..."
</code></pre>

<h2>Conclusion</h2>

<p>In this article you have learned how to:</p>

<ul>
<li>Install and start a MQTT Broker, Mosquitto</li>
<li>Create a publisher and subscriber developed in Java</li>
</ul>


<p>This article is very simple by choice, to quickly run your first MQTT Application. I wrote this article as part of a global IoT project I am working on that will capture devices data, publish them into MapR Converged Data Platform using MQTT and MapR Streams; this is why I used Java for the application. You can use any MQTT client library to build the publishers and subscribers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MapR Streams]]></title>
    <link href="http://tgrall.github.io/blog/2016/03/10/getting-started-with-mapr-streams/"/>
    <updated>2016-03-10T10:09:32+01:00</updated>
    <id>http://tgrall.github.io/blog/2016/03/10/getting-started-with-mapr-streams</id>
    <content type="html"><![CDATA[<p>You can find a new tutorial that explains how to deploy an Apache Kafka application to MapR Streams, the tutorial is available here:</p>

<ul>
<li><a href="https://www.mapr.com/blog/getting-started-sample-programs-mapr-streams">Getting Started with MapR Streams</a></li>
</ul>


<p>MapR Streams is a new distributed messaging system for streaming event data at scale, and it’s integrated into the MapR converged platform.
MapR Streams uses the Apache Kafka API, so if you’re already familiar with Kafka, you’ll find it particularly easy to get started with MapR Streams.</p>
]]></content>
  </entry>
  
</feed>
