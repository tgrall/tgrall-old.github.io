<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tug's Blog]]></title>
  <link href="http://tgrall.github.io/atom.xml" rel="self"/>
  <link href="http://tgrall.github.io/"/>
  <updated>2019-08-30T17:15:00+02:00</updated>
  <id>http://tgrall.github.io/</id>
  <author>
    <name><![CDATA[Tug Grall]]></name>
    <email><![CDATA[tugdual@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Getting Started With MapR-DB JSON REST API]]></title>
    <link href="http://tgrall.github.io/blog/2018/04/23/getting-started-with-mapr-db-json-rest-api/"/>
    <updated>2018-04-23T14:37:51+02:00</updated>
    <id>http://tgrall.github.io/blog/2018/04/23/getting-started-with-mapr-db-json-rest-api</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>In this project you will learn how to use the MapR-DB JSON REST API to:</p>

<p>Create and Delete tables
Create, Read, Update and Delete documents (CRUD)
MapR Extension Package 5.0 (MEP) introduced the MapR-DB JSON REST API that allow application to use REST to interact with MapR-DB JSON.</p>

<p>You can find information about the MapR-DB JSON REST API in the documentation: <a href="https://maprdocs.mapr.com/home/MapR-DB/JSON_DB/UsingMapRDBJSONRESTAPI.html">Using the MapR-DB JSON REST API</a></p>

<!-- more -->


<h2>Prerequisites</h2>

<p>You system should have the following components:</p>

<ul>
<li>A running MapR 6.0.1 &amp; MEP 5.0 cluster with the MapR-DB REST API service installed</li>
<li><code>curl</code> or equivalent tool</li>
</ul>


<h2>Discover the MapR-DB JSON REST API</h2>

<p>The easiest way to discover it, is to use curl command (or equivalent).</p>

<p><strong>1 - Create a table</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -X PUT \
</span><span class='line'>  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp' \
</span><span class='line'>  -u root:mapr \
</span><span class='line'>  -k</span></code></pre></td></tr></table></div></figure>


<p>In this command:</p>

<ul>
<li>the MapR-DB REST Service (MapR Data Access Gateway) is running on the mapr-node host with the default port <code>8243</code> using HTTPS</li>
<li>the HTTP verb <code>PUT</code> on <code>/api/v2/table/</code> endoint creates a new table</li>
<li>the protocol is HTTP since HTTPS is not enabled on this cluster</li>
<li>the new table will be created wit the path <code>/apps/emp</code> that is encoded to <code>%2Fapps%2Femp</code></li>
<li>the user <code>root</code> with the password <code>mapr</code> is used for authentication, using basic authentication</li>
<li>the <code>-k</code> parameter is used to indicate to turn off curl’s verification of the certificate.</li>
</ul>


<p>In this example, you use the basic authentication, it is also possible to use <a href="https://jwt.io/introduction/">JSON Web Token</a>. You will learn more about this when you will write an application in Go.</p>

<p><strong>2 - Insert Documents</strong></p>

<p>Insert one document</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -X POST \
</span><span class='line'>  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp' \
</span><span class='line'>  -u root:mapr \
</span><span class='line'>  -H 'Content-Type: application/json' \
</span><span class='line'>  -d '{"_id":"user001","first_name":"John","last_name":"Doe", "age" : 28}' \
</span><span class='line'>  -k</span></code></pre></td></tr></table></div></figure>


<p>In this command:</p>

<ul>
<li>the <code>/api/v2/table/{path}</code> with the verb <code>GET</code> is used with a <code>condition</code> query parameter</li>
<li>the OJAI JSON syntax is used to express the condition: <code>{"$eq":{"last_name":"Doe"}}</code></li>
</ul>


<p><strong>3 - Update a document</strong></p>

<p>The following example will increment the age by 1 and update the last name.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -X POST \
</span><span class='line'>  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp%2F/document/user001' \
</span><span class='line'>  -u root:mapr \
</span><span class='line'>  -H 'Content-Type: application/json' \
</span><span class='line'>  -d '{"$set" : {"last_name" : "New Doe"}, "$increment" : {"age":1}}' \
</span><span class='line'>  -k</span></code></pre></td></tr></table></div></figure>


<p>In this comamnd:</p>

<ul>
<li>the URL points to the document <code>_id</code> to update</li>
<li>the HTTP verb <code>POST</code> is used to modify the resource</li>
<li>the request body <code>-d</code> is the OJAI JSON Mutation that update the last name and increment the age.</li>
</ul>


<p>You can check that the document has been updated using the following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -X GET \
</span><span class='line'>  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp%2F/document/user001' \
</span><span class='line'>  -u root:mapr \
</span><span class='line'>  -k</span></code></pre></td></tr></table></div></figure>


<p><strong>4 - Delete a document</strong></p>

<p>Delete the document with the <code>_id</code> user001.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -X DELETE \
</span><span class='line'>  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp%2F/document/user001' \
</span><span class='line'>  -u root:mapr \
</span><span class='line'>  -k</span></code></pre></td></tr></table></div></figure>


<p>In this command:</p>

<ul>
<li>the URI <code>/api/v2/table/{path}/document/{id}</code> with the HTTP verb <code>DELETE</code> is used to delete the document</li>
</ul>


<p><strong>5 - Delete the MapR-DB JSON table</strong></p>

<p>The last step of this tutorial is to delete the table using the following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -X DELETE \
</span><span class='line'>  'https://mapr-node:8243/api/v2/table/%2Fapps%2Femp' \
</span><span class='line'>  -u root:mapr \
</span><span class='line'>  -k</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this tutorial you have learned how to use the MapR-DB JSON REST API to:</p>

<ul>
<li>Create a table</li>
<li>Insert and query documents</li>
<li>Update and delete documents</li>
<li>Drop table</li>
</ul>


<p>You can now use the API to create MapR-DB JSON Application using your favorite language.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MapR-DB Table Replication]]></title>
    <link href="http://tgrall.github.io/blog/2017/08/08/getting-started-with-mapr-db-table-replication/"/>
    <updated>2017-08-08T10:01:19+02:00</updated>
    <id>http://tgrall.github.io/blog/2017/08/08/getting-started-with-mapr-db-table-replication</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>MapR-DB Table Replication allows data to be replicated to another table that could be on on the same cluster or in another cluster. This is different from the automatic and intra-cluster replication that copies the data into different physical nodes for high availability and prevent data loss.</p>

<p>This tutorial focuses on the MapR-DB Table Replication that replicates data between tables on different clusters.</p>

<p>Replicating data between different clusters allows you to:</p>

<ul>
<li>provide another level of disaster recovery that protects your data and applications against global data center failure,</li>
<li>push data close to the applications and users,</li>
<li>aggregate the data from mutliple datacenters.</li>
</ul>


<p><strong>Replication Topologies</strong></p>

<p>MapR-DB Table Replication provides various topologies to adapt the replication to the business and technical requirements:</p>

<ul>
<li><em>Master-slave replication</em> : in this topology, you replicate one way from source tables to replicas. The replicas can be in a remote cluster or in the cluster where the source tables are located.</li>
<li><em>Multi-Master replication</em> : in this replication topology, there are two master-slave relationships, with each table playing both the role of a master and a slave. Client applications update both tables and each table replicates updates to the other.</li>
</ul>


<p>In this example you will learn how to setup multi-master replication.</p>

<!-- more -->


<h3>Prerequisites</h3>

<ul>
<li>2 MapR Clusters 5.x with Enterprise Edition license

<ul>
<li>in this demonstration they are called <code>cluster1</code> and <code>cluster2</code></li>
</ul>
</li>
</ul>


<h2>Setting Up Replication</h2>

<p>In the next steps you will configure your clusters to enable mutip-master replication as follow:</p>

<p><img src="http://tgrall.github.io/images/posts/maprdb-replication/replication.png" alt="Architecture" /></p>

<h3>Configuring the clusters</h3>

<p>Each node of the source cluster must communicate with the destination cluster&rsquo;s CLDB nodes. On each node of your source cluster edit the <code>mapr-clusters.conf</code> file and add the destination cluster information.</p>

<p><em>Cluster 1 Configuration</em></p>

<p>In all the nodes of <code>cluster1</code>, edit the  <code>/opt/mapr/conf/mapr-clusters.conf</code> file and add the <code>cluster2</code> configuration. The file should look like the following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster1 secure=false cluster1-node1:7222 cluster1-node2:7222 cluster1-node2:7222
</span><span class='line'>
</span><span class='line'>cluster2 secure=false cluster2-node1:7222 cluster2-node2:7222 cluster2-node3:7222</span></code></pre></td></tr></table></div></figure>


<p><em>Cluster 2 Configuration</em></p>

<p>In all the nodes of <code>cluster2</code>, edit the  <code>/opt/mapr/conf/mapr-clusters.conf</code> file and add the <code>cluster1</code> configuration. The file should look like the following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster2 secure=false cluster2-node1:7222 cluster2-node2:7222 cluster2-node3:7222
</span><span class='line'>
</span><span class='line'>cluster1 secure=false cluster1-node1:7222 cluster1-node2:7222 cluster1-node2:7222</span></code></pre></td></tr></table></div></figure>


<p>You can find information about the <code>mapr-clusters.conf</code> format in <a href="http://maprdocs.mapr.com/home/ReferenceGuide/mapr-clusters.conf.html">the documentation</a>.</p>

<p>Open a terminal window on one of the <code>cluster1</code> node using <code>mapr</code> user, and do the following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ls /mapr/cluster1/
</span><span class='line'>apps   hbase  installer  opt  tmp  user  var
</span><span class='line'>
</span><span class='line'>$ ls /mapr/cluster2/
</span><span class='line'>apps   hbase  installer  opt  tmp  user  var
</span></code></pre></td></tr></table></div></figure>


<h3>Installing and Configuring the MapR Gateway</h3>

<p>A MapR gateway mediates one-way communication between a source MapR cluster and a destination MapR cluster. In this example you will use mult-master replication, this means that data will be replicated from <code>cluster1</code> to <code>cluster2</code> and from <code>cluster2</code> to <code>cluster1</code>.</p>

<p>The good practice is to install the MapR-Gateway to the destination cluster, so in our case let&rsquo;s install one gateway on one of the <code>cluster1</code> node, and one gateway on one of the <code>cluster2</code> node. Note that this configuration will not be highly available, and usually you will deploy more than 1 gateway by cluster.</p>

<h4>Installing the MapR-Gateway</h4>

<p>As root on one node of the <code>cluster1</code>, adapt the command to your linux environment, for example on the node <code>cluster1-node2</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ yum install mapr-gateway
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Update MapR configuration
</span><span class='line'>$ /opt/mapr/server/configure.sh -N cluster1 -C cluster1-node1:7222,cluster1-node2:7222,cluster1-node3:7222 -R
</span></code></pre></td></tr></table></div></figure>


<p>Do the same on <code>cluster2</code>, for example on the node <code>cluster2-node2</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ yum install mapr-gateway
</span><span class='line'>
</span><span class='line'>
</span><span class='line'># Update MapR configuration
</span><span class='line'>$ /opt/mapr/server/configure.sh -N cluster1 -C cluster2-node1:7222,cluster2-node2:7222,cluster2-node3:7222 -R
</span></code></pre></td></tr></table></div></figure>


<h4>Registering the Gateway to the Clusters</h4>

<p>Now that we have a gateway running on each cluster, you have to <strong><em>register the gateway</em></strong> in each cluster.</p>

<p>On <code>cluster1</code> run the following command to register the <code>cluster2</code> gateway as destination:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli cluster gateway set -dstcluster cluster2 -gateways cluster2-node2
</span><span class='line'>
</span><span class='line'># Check the configuration
</span><span class='line'>$ maprcli cluster gateway list</span></code></pre></td></tr></table></div></figure>


<p>On <code>cluster2</code> run the following command to register the <code>cluster1</code> gateway as destination:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli cluster gateway set -dstcluster cluster1 -gateways cluster1-node2
</span><span class='line'>
</span><span class='line'># Check the configuration
</span><span class='line'>$ maprcli cluster gateway list</span></code></pre></td></tr></table></div></figure>


<h3>Creating Table with Replication</h3>

<p>In a terminal window, as <code>mapr</code> user on <code>cluster1</code>, create a table and insert documents:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli table create -path /apps/user_profiles  -tabletype json
</span></code></pre></td></tr></table></div></figure>


<p>This create a new JSON table; it is also possible to use <code>/mapr/cluster1/apps/user_profiles</code>.</p>

<p>Let&rsquo;s now add documents using MapR-DB Shell:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mapr dbshell
</span><span class='line'>
</span><span class='line'>maprdb mapr:&gt; insert /apps/user_profiles --value '{"_id":"user001" , "first_name":"John", "last_name":"Doe"}'
</span><span class='line'>
</span><span class='line'>maprdb mapr:&gt; find /apps/user_profiles
</span></code></pre></td></tr></table></div></figure>


<h4>Adding Table Replication</h4>

<p>Let&rsquo;s now enable replication between <code>user_profiles</code> on <code>cluster1</code> to a <code>user_profiles</code> table in <code>cluster2</code>.</p>

<p>In <code>cluster1</code>, on a terminal window as <code>mapr</code> run the following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli table replica autosetup -path /apps/user_profiles -replica /mapr/cluster2/apps/user_profiles -multimaster yes</span></code></pre></td></tr></table></div></figure>


<p>You can get information about the replication configuration for the table using the following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli table replica list -path /apps/user_profiles -json</span></code></pre></td></tr></table></div></figure>


<h4>Testing Replication</h4>

<p>Open another terminal in <code>cluster2</code> and use MapR-DB Shell to look at the replicated data:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mapr dbshell
</span><span class='line'>
</span><span class='line'>maprdb mapr:&gt; find /apps/user_profiles
</span><span class='line'>{"_id":"user001","first_name":"John","last_name":"Doe"}
</span><span class='line'>1 document(s) found.
</span></code></pre></td></tr></table></div></figure>


<p>You can also use the full path <code>/mapr/cluster2/apps/user_profiles</code></p>

<p>In <code>cluster1</code> add a new document using MapR-DB Shell:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mapr dbshell
</span><span class='line'>
</span><span class='line'>maprdb mapr:&gt; insert /apps/user_profiles --value '{"_id":"user002" , "first_name":"Simon", "last_name":"Dupont"}'
</span><span class='line'>
</span><span class='line'>maprdb mapr:&gt; find /apps/user_profiles</span></code></pre></td></tr></table></div></figure>


<p>Do a find in <code>cluster2</code> table, and you will see that the data have been replicated.</p>

<p>You can insert or delete a document in <code>cluster2</code> and do a find in <code>cluster1</code>, you will see that the new document is also replicated in the other direction.</p>

<p>Note, for this demonstration, we use 2 terminals connected to each cluster you can do some test using the Global Namespace in a single MapR-DB Shell.</p>

<h2>Conclusion</h2>

<p>In this tutorial you have learned how to setup the MapR-DB Multi-Master replication to have data automatically replicated between 2 clusters.</p>

<p>MapR-DB Table Replication provides many options, not only in term of topology (master-slave/mult-master), but also some options and commands to:</p>

<ul>
<li>replicate some columns/attributes or column family</li>
<li>configure replication in a secured cluster</li>
<li>pause replication.</li>
</ul>


<p>You can find more information about the MapR-DB Table Replication, and MapR-Gateway in the documentation:</p>

<ul>
<li><a href="http://maprdocs.mapr.com/home/MapR-DB/ReplicatingMapR-DBTables.html">Table Replication</a></li>
<li><a href="http://maprdocs.mapr.com/home/MapR-DB/ConfiguringMapRClustersForTR.html">Setting up Table Replication</a></li>
<li><a href="http://maprdocs.mapr.com/home/Gateways/MapRGateways.html">Configuring and Managing MapR Gateways</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Kafka REST Proxy for MapR Streams]]></title>
    <link href="http://tgrall.github.io/blog/2017/01/20/getting-started-with-kafka-rest-proxy-for-mapr-streams/"/>
    <updated>2017-01-20T10:31:22+01:00</updated>
    <id>http://tgrall.github.io/blog/2017/01/20/getting-started-with-kafka-rest-proxy-for-mapr-streams</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>MapR Ecosystem Package 2.0 (MEP) is coming with some new features related to MapR Streams:</p>

<ul>
<li><a href="http://maprdocs.mapr.com/home/Kafka/kafkaREST.html">Kafka REST Proxy for MapR Streams</a> provides a RESTful interface to MapR Streams and Kafka clusters to consume and product messages and to perform administrative operations.</li>
<li><a href="http://maprdocs.mapr.com/home/Kafka/kafkaConnect.html">Kafka Connect for MapR Streams</a> is a utility for streaming data between MapR Streams and Apache Kafka and other storage systems.</li>
</ul>


<p>MapR Ecosystem Packs (MEPs) are a way to deliver ecosystem upgrades decoupled from core upgrades - allowing you to upgrade your tooling independently of your Converged Data Platform. You can lean more about MEP 2.0 in <a href="https://www.mapr.com/blog/announcing-mapr-ecosystem-pack-mep-20">this article</a>.</p>

<p>In this blog we describe how to use the REST Proxy to publish and consume messages to/from MapR Streams. The REST Proxy is a great addition to the MapR Converged Data Platform allowing any programming language to use MapR Streams.</p>

<p>The Kafka REST Proxy provided with the MapR Streams tools, can be used with MapR Streams (default), but also used in a hybrid mode with Apache Kafka. In this article we will focus on MapR Streams.</p>

<!-- more -->


<h2>Prerequisites</h2>

<ul>
<li>MapR Converged Data Platform 5.2 with MEP 2.0

<ul>
<li>with MapR Streams Tools</li>
</ul>
</li>
<li>curl, wget or any HTTP/REST Client tool</li>
</ul>


<h2>Create the MapR Streams and Topic</h2>

<p>A stream is a collection of topics that you can manage as a group by:</p>

<ol>
<li>Setting security policies that apply to all topics in that stream</li>
<li>Setting a default number of partitions for each new topic that is created in the stream</li>
<li>Set a time-to-live for messages in every topic in the stream</li>
</ol>


<p>You can find more information about MapR Streams concepts in the <a href="http://maprdocs.mapr.com/home/MapR_Streams/mapr_streams.html">documentation</a>.</p>

<p>On your Mapr Cluster or Sandbox, run the following commands:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli stream create -path /apps/iot-stream -produceperm p -consumeperm p -topicperm p
</span><span class='line'>
</span><span class='line'>$ maprcli stream topic create -path /apps/iot-stream -topic sensor-json -partitions 3
</span><span class='line'>
</span><span class='line'>$ maprcli stream topic create -path /apps/iot-stream -topic sensor-binary -partitions 3</span></code></pre></td></tr></table></div></figure>


<h2>Start Kafka Console Producers and Consumers</h2>

<p>Open two terminal windows and run the consumer Kafka utilities using the following commands:</p>

<h4>Consumer</h4>

<ul>
<li>Topic sensor-json</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ /opt/mapr/kafka/kafka-0.9.0/bin/kafka-console-consumer.sh --new-consumer --bootstrap-server this.will.be.ignored:9092 --topic /apps/iot-stream:sensor-json</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Topic sensor-binary</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ /opt/mapr/kafka/kafka-0.9.0/bin/kafka-console-consumer.sh --new-consumer --bootstrap-server this.will.be.ignored:9092 --topic /apps/iot-stream:sensor-binary</span></code></pre></td></tr></table></div></figure>


<p>This two terminal windows will allow you to see the messages posted on the different topics</p>

<h2>Using Kafka REST Proxy</h2>

<h3>Inspect Topic Metadata</h3>

<p>The endpoint <code>/topics/[topic_name]</code> allows you to get some informations about the topic. In MapR Streams, topics are part of a <em>stream</em> identified by a path;
to use the topic using the REST API you have to use the full path, and encode it in the URL; for example:</p>

<ul>
<li><code>/apps/iot-stream:sensor-json</code> will be encoded with <code>%2Fapps%2Fiot-stream%3Asensor-json</code></li>
</ul>


<p>Run the following command, to get information about the <code>sensor-json</code> topic</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X GET  http://localhost:8082/topics/%2Fapps%2Fiot-stream%3Asensor-json</span></code></pre></td></tr></table></div></figure>


<p>Note: For simplicity reason I am running the command from the node where the Kafka REST proxy is running, so it is possible to use <code>localhost</code>.</p>

<p>You can print JSON in a pretty way, by adding a Python command such as :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -X GET  http://localhost:8082/topics/%2Fapps%2Fiot-stream%3Asensor-json | python -m json.tool</span></code></pre></td></tr></table></div></figure>


<p><strong>Default Stream</strong></p>

<p>As mentioned above, the Stream path is part of the topic name you have to use in the command;
however it is possible to configure the MapR Kafka REST Proxy to use a default stream.
For this you should add the following property in the <code>/opt/mapr/kafka-rest/kafka-rest-2.0.1/config/kafka-rest.properties</code> file:</p>

<ul>
<li><code>streams.default.stream=/apps/iot-stream</code></li>
</ul>


<p> When you change the Kafka REST proxy configuration, you must restart the service using maprcli or MCS.</p>

<p> The main reason to use the <code>streams.default.stream</code> properties is to simplify the URLs used by the application for example
 * with <code>streams.default.stream</code> you can use <code>curl -X GET  http://localhost:8082/topics/</code>
 * without this configuration, or if you want to use a specific stream you must specify it in the URL <code>http://localhost:8082/topics/%2Fapps%2Fiot-stream%3Asensor-json</code></p>

<p> In this article, all the URLs contains the encoded stream name, like that you can start using the Kafka REST proxy without changind the configuration and also use it with different streams.</p>

<h3>Publishing Messages</h3>

<p>The Kafka REST Proxy for MapR Streams allows application to publish messages to MapR Streams. Messages could be send as JSON or Binary content (base64 encoding).</p>

<h4>To send a JSON Message:</h4>

<ul>
<li>the query should be a HTTP <code>POST</code></li>
<li>the Content-Type should be : <code>application/vnd.kafka.json.v1+json</code></li>
<li>the Body:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;records&quot;</span><span class="p">:</span>
</span><span class='line'>  <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;value&quot;</span><span class="p">:</span>
</span><span class='line'>      <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;temp&quot;</span> <span class="p">:</span> <span class="mi">10</span> <span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;speed&quot;</span> <span class="p">:</span> <span class="mi">40</span> <span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;direction&quot;</span> <span class="p">:</span> <span class="s2">&quot;NW&quot;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The complete request is:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/vnd.kafka.json.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">--data</span> <span class="err">&#39;</span><span class="p">{</span><span class="nt">&quot;records&quot;</span><span class="p">:[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;temp&quot;</span> <span class="p">:</span> <span class="mi">10</span> <span class="p">,</span> <span class="nt">&quot;speed&quot;</span> <span class="p">:</span> <span class="mi">40</span> <span class="p">,</span> <span class="nt">&quot;direction&quot;</span> <span class="p">:</span> <span class="s2">&quot;NW&quot;</span><span class="p">}</span>  <span class="p">}]}</span><span class="err">&#39;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/topics/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-json</span>
</span></code></pre></td></tr></table></div></figure>


<p>You should see the message printed in the terminal window where the <code>/apps/iot-stream:sensor-json</code> consumer is running.</p>

<h4>To send a binary Message:</h4>

<ul>
<li>the query should be a HTTP <code>POST</code></li>
<li>the Content-Type should be : <code>application/vnd.kafka.binary.v1+json</code></li>
<li>the Body:</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;records&quot;</span><span class="p">:</span>
</span><span class='line'>  <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;SGVsbG8gV29ybGQ=&quot;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that <code>SGVsbG8gV29ybGQ=</code> is the string &ldquo;Hello World&rdquo; encoded in Base64.</p>

<p>The complete request is:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/vnd.kafka.binary.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">--data</span> <span class="err">&#39;</span><span class="p">{</span><span class="nt">&quot;records&quot;</span><span class="p">:[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;SGVsbG8gV29ybGQ=&quot;</span><span class="p">}]}</span><span class="err">&#39;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/topics/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-binary</span>
</span></code></pre></td></tr></table></div></figure>


<p>You should see the message printed in the terminal window where the <code>/apps/iot-stream:sensor-binary</code> consumer is running.</p>

<h4>Sending multiple messages</h4>

<p>The <code>records</code> field of the HTTP Body allows you to send multiple messages for example you can send:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/vnd.kafka.json.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">--data</span> <span class="err">&#39;</span><span class="p">{</span><span class="nt">&quot;records&quot;</span><span class="p">:[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;temp&quot;</span> <span class="p">:</span> <span class="mi">12</span> <span class="p">,</span> <span class="nt">&quot;speed&quot;</span> <span class="p">:</span> <span class="mi">42</span> <span class="p">,</span> <span class="nt">&quot;direction&quot;</span> <span class="p">:</span> <span class="s2">&quot;NW&quot;</span><span class="p">}</span>  <span class="p">},</span> <span class="p">{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;temp&quot;</span> <span class="p">:</span> <span class="mi">10</span> <span class="p">,</span> <span class="nt">&quot;speed&quot;</span> <span class="p">:</span> <span class="mi">37</span> <span class="p">,</span> <span class="nt">&quot;direction&quot;</span> <span class="p">:</span> <span class="s2">&quot;N&quot;</span><span class="p">}</span>  <span class="p">}</span> <span class="p">]}</span><span class="err">&#39;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/topics/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-json</span>
</span></code></pre></td></tr></table></div></figure>


<p>This command will send 2 messages, and increment the offset by 2. You can do the same
with binary content, just add new element in the JSON array; for example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/vnd.kafka.binary.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">--data</span> <span class="err">&#39;</span><span class="p">{</span><span class="nt">&quot;records&quot;</span><span class="p">:[{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;SGVsbG8gV29ybGQ=&quot;</span><span class="p">},</span> <span class="p">{</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;Qm9uam91cg==&quot;</span><span class="p">}]}</span><span class="err">&#39;</span> <span class="err">\</span>
</span><span class='line'>  <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/topics/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-binary</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you probably know, it is possible to set a key to a message to be sure that all the messages
with the same key will arrive in the same partition. For this, add the <code>key</code> attribute to the message as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;records&quot;</span><span class="p">:</span>
</span><span class='line'>  <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;K001&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;value&quot;</span><span class="p">:</span>
</span><span class='line'>      <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;temp&quot;</span> <span class="p">:</span> <span class="mi">10</span> <span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;speed&quot;</span> <span class="p">:</span> <span class="mi">40</span> <span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;direction&quot;</span> <span class="p">:</span> <span class="s2">&quot;NW&quot;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now that you know how to post messages to MapR Stream topics usinf the REST Proxy, let&rsquo;s see how to consume the messages.</p>

<h3>Consuming Messages</h3>

<p>The REST proxy can also be used to consume messages from topics; for this you need to:</p>

<ol>
<li>Create a consumer instance.</li>
<li>Use this URL returned by the first call to read message.</li>
<li>Delete the consumer instanced if needed.</li>
</ol>


<h4>Creating the consumer instance</h4>

<p>The following request creates the consumer instance:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='JSON'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/vnd.kafka.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'>      <span class="err">--data</span> <span class="err">&#39;</span><span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;iot_json_consumer&quot;</span><span class="p">,</span> <span class="nt">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="nt">&quot;auto.offset.reset&quot;</span><span class="p">:</span> <span class="s2">&quot;earliest&quot;</span><span class="p">}</span><span class="err">&#39;</span> <span class="err">\</span>
</span><span class='line'>      <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/consumers/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-json</span>
</span></code></pre></td></tr></table></div></figure>


<p>The response from the server looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;instance_id&quot;</span><span class="p">:</span><span class="s2">&quot;iot_json_consumer&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;base_uri&quot;</span><span class="p">:</span><span class="s2">&quot;http://localhost:8082/consumers/%2Fapps%2Fiot-stream%3Asensor-json/instances/iot_json_consumer&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that we have used the <code>/consumers/[topic_name]</code> to create the consumer.</p>

<p>The <code>base_uri</code> will be used by the subsequent requests to get the messages from the topic. Like any MapR Streams/Kafka consumer the <code>auto.offset.reset</code> defines its behavior. In this example the value is set to <code>earliest</code>, this means that the consumer will read the messages from the beginning. You can find more information about the consumer configuration in the <a href="http://maprdocs.mapr.com/home/MapR_Streams/configuration_parameters_for_consumers.html">MapR Streams documentation</a>.</p>

<h4>Consuming the messages</h4>

<p>To consume the messages, just add the Mapr Streams topic to the URL of the consumer isntance.</p>

<p>The following request consumes the messages from the topic:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">GET</span> <span class="err">-H</span> <span class="s2">&quot;Accept: application/vnd.kafka.json.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'><span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/consumers/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-json/instances/iot_json_consumer/topics/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-json</span>
</span></code></pre></td></tr></table></div></figure>


<p>This call returns the messages in a JSON document:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="kc">null</span><span class="p">,</span><span class="nt">&quot;value&quot;</span><span class="p">:{</span><span class="nt">&quot;temp&quot;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="nt">&quot;speed&quot;</span><span class="p">:</span><span class="mi">40</span><span class="p">,</span><span class="nt">&quot;direction&quot;</span><span class="p">:</span><span class="s2">&quot;NW&quot;</span><span class="p">},</span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;/apps/iot-stream:sensor-json&quot;</span><span class="p">,</span><span class="nt">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="nt">&quot;offset&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="kc">null</span><span class="p">,</span><span class="nt">&quot;value&quot;</span><span class="p">:{</span><span class="nt">&quot;temp&quot;</span><span class="p">:</span><span class="mi">12</span><span class="p">,</span><span class="nt">&quot;speed&quot;</span><span class="p">:</span><span class="mi">42</span><span class="p">,</span><span class="nt">&quot;direction&quot;</span><span class="p">:</span><span class="s2">&quot;NW&quot;</span><span class="p">},</span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;/apps/iot-stream:sensor-json&quot;</span><span class="p">,</span><span class="nt">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="nt">&quot;offset&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">},</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="kc">null</span><span class="p">,</span><span class="nt">&quot;value&quot;</span><span class="p">:{</span><span class="nt">&quot;temp&quot;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="nt">&quot;speed&quot;</span><span class="p">:</span><span class="mi">37</span><span class="p">,</span><span class="nt">&quot;direction&quot;</span><span class="p">:</span><span class="s2">&quot;N&quot;</span><span class="p">},</span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;/apps/iot-stream:sensor-json&quot;</span><span class="p">,</span><span class="nt">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="nt">&quot;offset&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">}</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>Each call to the API returns the new messages published, based on the offset of the last call.</p>

<p>Note that the Consumer will be destroyed:</p>

<ul>
<li>after some idle time set by the <code>consumer.instance.timeout.ms</code> (default value set to 300000ms / 5 minutes)</li>
<li>where it is destroyed using a REST API call (see below).</li>
</ul>


<h3>Consuming binary format messages</h3>

<p>The approach is the same if you need to consume binary messages, you need to change the format and accept header.</p>

<p>Call this URL to create a consumer instance for the binary topic:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/vnd.kafka.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'>      <span class="err">--data</span> <span class="err">&#39;</span><span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;iot_binary_consumer&quot;</span><span class="p">,</span> <span class="nt">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="nt">&quot;auto.offset.reset&quot;</span><span class="p">:</span> <span class="s2">&quot;earliest&quot;</span><span class="p">}</span><span class="err">&#39;</span> <span class="err">\</span>
</span><span class='line'>      <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/consumers/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-binary</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then consume messages, the accept header is set to <code>application/vnd.kafka.binary.v1+json</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">GET</span> <span class="err">-H</span> <span class="s2">&quot;Accept: application/vnd.kafka.binary.v1+json&quot;</span> <span class="err">\</span>
</span><span class='line'><span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/consumers/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-binary/instances/iot_binary_consumer/topics/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-binary</span>
</span></code></pre></td></tr></table></div></figure>


<p>This call returns the messages in a JSON document, and the value is encoded in Base64</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="kc">null</span><span class="p">,</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;SGVsbG8gV29ybGQ=&quot;</span><span class="p">,</span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;/apps/iot-stream:sensor-binary&quot;</span><span class="p">,</span><span class="nt">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="nt">&quot;offset&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="kc">null</span><span class="p">,</span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="s2">&quot;Qm9uam91cg==&quot;</span><span class="p">,</span><span class="nt">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;/apps/iot-stream:sensor-binary&quot;</span><span class="p">,</span><span class="nt">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="nt">&quot;offset&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">}</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Delete consumer instances</h3>

<p>As mentioned before the consumer will be destroyed automatically based on the <code>consumer.instance.timeout.ms</code> configuration of the REST Proxy;
it is also possible to destroyed the instance using the consumer instance URI and an HTTP DELETE call, as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">curl</span> <span class="err">-X</span> <span class="err">DELETE</span> <span class="err">http://localhost:</span><span class="mi">8082</span><span class="err">/consumers/%</span><span class="mi">2</span><span class="err">Fapps%</span><span class="mi">2</span><span class="err">Fiot-stream%</span><span class="mi">3</span><span class="err">Asensor-binary/instances/iot_binary_consumer</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this article you have learned how to use the Kafka REST Proxy for MapR Streams that allow any application to
use messages published in the MapR Converged Data Platform.</p>

<p>You can find more information about the Kafka REST Proxy in the <a href="http://maprdocs.mapr.com/home/Kafka/REST-proxy.html">MapR documentation</a> and the following resources:</p>

<ul>
<li><a href="https://www.mapr.com/blog/getting-started-sample-programs-mapr-streams">Getting Started with MapR Streams</a></li>
<li><a href="https://www.mapr.com/streaming-architecture-using-apache-kafka-mapr-streams">&ldquo;Streaming Architecture: New Designs Using Apache Kafka and MapR Streams&rdquo; ebook by Ted Dunning and Ellen Friedman</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MQTT and Java]]></title>
    <link href="http://tgrall.github.io/blog/2017/01/02/getting-started-with-mqtt/"/>
    <updated>2017-01-02T16:03:09+01:00</updated>
    <id>http://tgrall.github.io/blog/2017/01/02/getting-started-with-mqtt</id>
    <content type="html"><![CDATA[<p>MQTT (MQ Telemetry Transport) is a lightweight publish/subscribe messaging protocol.
MQTT is used a lot in the Internet of Things applications, since it has been designed to
run on remote locations with system with small footprint.</p>

<p>The MQTT 3.1 is an OASIS standard, and you can find all the information at <a href="http://mqtt.org/">http://mqtt.org/</a></p>

<p>This article will guide you into the various steps to run your first MQTT application:</p>

<ol>
<li>Install and Start a MQTT Broker</li>
<li>Write an application that publishes messages</li>
<li>Write an application that consumes messages</li>
</ol>


<p>The source code of the sample application is available on <a href="https://github.com/tgrall/mqtt-sample-java">GitHub</a>.</p>

<!-- more -->


<h4>Prerequisites</h4>

<ul>
<li>Apache Maven 3.x</li>
<li>Git</li>
</ul>


<h3>Install and Start a MQTT Broker</h3>

<p>You can find many MQTT Brokers, for this example I will use one of the most common broker <a href="https://mosquitto.org">Mosquitto</a>.</p>

<p>You can download and install from the <a href="https://mosquitto.org/download/">binary package</a>. I have used <a href="http://brew.sh/">Homebrew</a> to install it on my Mac:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ brew install mosquitto</span></code></pre></td></tr></table></div></figure>


<p>Start the MQTT Broker with the default configuration</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ /usr/local/sbin/mosquitto</span></code></pre></td></tr></table></div></figure>


<h3>Publish and Consume messages</h3>

<p>Open two terminal windows and run the following commands :</p>

<p>Consume</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mosquitto_sub -h 127.0.0.1 -t iot_data</span></code></pre></td></tr></table></div></figure>


<p>Publish</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ mosquitto_pub -h 127.0.0.1 -t iot_data -m "Hello world"</span></code></pre></td></tr></table></div></figure>


<p>You should see the message <code>Hello world</code> in the consumer/subscriber window.</p>

<h3>Write your first MQTT Application</h3>

<p>For this example I will write a small Java application, since it is the language
that I am using in my global project.</p>

<h4>Maven Dependencies</h4>

<p>Add the <a href="https://eclipse.org/paho/">Eclipse Paho</a> dependency to your Maven project</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>  <span class="nt">&lt;groupId&gt;</span>org.eclipse.paho<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>  <span class="nt">&lt;artifactId&gt;</span>org.eclipse.paho.client.mqttv3<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
</span><span class='line'><span class="nt">&lt;/dependency&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Publishing a Message</h4>

<p>Publishing a message is quite easy, create a MqttClient and use it to post on a topic.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">MqttClient</span> <span class="n">client</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">MqttClient</span><span class="o">(</span><span class="s">&quot;tcp://localhost:1883&quot;</span><span class="o">,</span> <span class="n">MqttClient</span><span class="o">.</span><span class="na">generateClientId</span><span class="o">());</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="na">connect</span><span class="o">();</span>
</span><span class='line'><span class="n">MqttMessage</span> <span class="n">message</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">MqttMessage</span><span class="o">();</span>
</span><span class='line'><span class="n">message</span><span class="o">.</span><span class="na">setPayload</span><span class="o">(</span><span class="s">&quot;Hello world from Java&quot;</span><span class="o">.</span><span class="na">getBytes</span><span class="o">());</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="na">publish</span><span class="o">(</span><span class="s">&quot;iot_data&quot;</span><span class="o">,</span> <span class="n">message</span><span class="o">);</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="na">disconnect</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>You have many other options, configurations that you can use when posting a message
such as security, quality of service (QoS), and more; but in this post I want to simply
show how easy is to publish and consume MQTT messages.</p>

<h4>Consuming messages</h4>

<p>To consume messages you need to implement a <code>org.eclipse.paho.client.mqttv3.MqttCallback</code> that will receive the message and used this Callback class in the MqttClient of the Subscriber application.</p>

<p>The Callback class:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SimpleMqttCallBack</span> <span class="kd">implements</span> <span class="n">MqttCallback</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">connectionLost</span><span class="o">(</span><span class="n">Throwable</span> <span class="n">throwable</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Connection to MQTT broker lost!&quot;</span><span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">messageArrived</span><span class="o">(</span><span class="n">String</span> <span class="n">s</span><span class="o">,</span> <span class="n">MqttMessage</span> <span class="n">mqttMessage</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Message received:\n\t&quot;</span><span class="o">+</span> <span class="k">new</span> <span class="nf">String</span><span class="o">(</span><span class="n">mqttMessage</span><span class="o">.</span><span class="na">getPayload</span><span class="o">())</span> <span class="o">);</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">deliveryComplete</span><span class="o">(</span><span class="n">IMqttDeliveryToken</span> <span class="n">iMqttDeliveryToken</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="c1">// not used in this example</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This Callback class is used in the Subscriber application as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">MqttClient</span> <span class="n">client</span><span class="o">=</span><span class="k">new</span> <span class="nf">MqttClient</span><span class="o">(</span><span class="s">&quot;tcp://localhost:1883&quot;</span><span class="o">,</span> <span class="n">MqttClient</span><span class="o">.</span><span class="na">generateClientId</span><span class="o">());</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="na">setCallback</span><span class="o">(</span> <span class="k">new</span> <span class="nf">SimpleMqttCallBack</span><span class="o">()</span> <span class="o">);</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="na">connect</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>Like for the publisher, I am using the broker and client without any option (QoS, security).</p>

<h2>Build and Run the Application</h2>

<p><strong>1- Get the Sample Code</strong></p>

<p>Clone the project from GitHub</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">$</span> <span class="n">git</span> <span class="n">clone</span> <span class="nl">https:</span><span class="c1">//github.com/tgrall/mqtt-sample-java.git</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>2- Build the project with Apache Maven:</strong></p>

<p>This project is a simple Java application that runs a publisher and subscriber using the <a href="https://eclipse.org/paho/">Eclipse Paho library</a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">$</span> <span class="n">mvn</span> <span class="n">clean</span> <span class="kn">package</span>
</span></code></pre></td></tr></table></div></figure>


<p>For convenience, the example programs project is set up so that the maven package target produces a single executable,
<code>/mqtt-sample</code>, that includes all of the example programs and dependencies.</p>

<p><strong>3- Run the Subscriber</strong></p>

<p>The subscriber will receive and print all messages published on the <code>iot_data</code> topic.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">$</span> <span class="o">./</span><span class="n">target</span><span class="o">/</span><span class="n">mqtt</span><span class="o">-</span><span class="n">sample</span> <span class="n">subscriber</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>4- Run the Publisher</strong></p>

<p>Run the publisher with the following command, the second parameter is the message to publish</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">$</span> <span class="o">./</span><span class="n">target</span><span class="o">/</span><span class="n">mqtt</span><span class="o">-</span><span class="n">sample</span> <span class="n">publisher</span> <span class="s">&quot;My first MQTT message...&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this article you have learned how to:</p>

<ul>
<li>Install and start a MQTT Broker, Mosquitto</li>
<li>Create a publisher and subscriber developed in Java</li>
</ul>


<p>This article is very simple by choice, to quickly run your first MQTT Application. I wrote this article as part of a global IoT project I am working on that will capture devices data, publish them into MapR Converged Data Platform using MQTT and MapR Streams; this is why I used Java for the application. You can use any MQTT client library to build the publishers and subscribers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Apache Flink and Mapr Streams]]></title>
    <link href="http://tgrall.github.io/blog/2016/10/17/getting-started-with-apache-flink-and-mapr-streams/"/>
    <updated>2016-10-17T10:12:10+02:00</updated>
    <id>http://tgrall.github.io/blog/2016/10/17/getting-started-with-apache-flink-and-mapr-streams</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p><a href="https://flink.apache.org/">Apache Flink</a> is an open source platform for distributed stream and batch data processing. Flink is a streaming data flow engine with several APIs to create data streams oriented application.</p>

<p>It is very common for Flink applications to use <a href="http://kafka.apache.org/">Apache Kafka</a> for data input and output.</p>

<p>This article will guide you into  the steps to use Apache Flink with <a href="https://www.mapr.com/products/mapr-streams">MapR Streams</a>. MapR Streams is a distributed messaging system for streaming event data at scale, and it’s integrated into the <a href="https://www.mapr.com/products/mapr-converged-data-platform">MapR Converged Data Platform</a>, based on the Apache Kafka API (0.9.0),
this article use the same code and approach than the <a href="http://tgrall.github.io/blog/2016/10/12/getting-started-with-apache-flink-and-kafka/">Flink and Kafka Getting Started</a>.</p>

<p><img src="http://tgrall.github.io/images/posts/flink-kafka/flink-mapr-streams.png" alt="MapR Streams and Flink" />.</p>

<!-- more -->


<h3>Prerequisites</h3>

<ul>
<li>MapR 5.2

<ul>
<li>You can use <a href="https://www.mapr.com/products/mapr-sandbox-hadoop">MapR Converged Data Platform Sandbox</a></li>
</ul>
</li>
<li>MapR Client installed on your development host

<ul>
<li><a href="http://maprdocs.mapr.com/home/AdvancedInstallation/SettingUptheClient-install-mapr-client.html">Installation and Configuration steps</a></li>
</ul>
</li>
<li>Git</li>
<li>Maven 3.x or later</li>
</ul>


<h2>Create your Flink Streaming Project</h2>

<p>The first step is to create an Java application, the easiest is to use the flink-quickstart-java archetype, that contains the core dependencies and packaging tasks. This article is similar with the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/quickstart/run_example_quickstart.html">Apache Flink Quick Start Example</a>, with a clear focus on data input and output with MapR Streams.</p>

<p>In this application we will create two jobs:</p>

<ul>
<li><code>WriteToKafka</code> : that generates random string and post them to a MapR Streams Topic using the Kafka Flink Connector and its Producer API.</li>
<li><code>ReadFromKafka</code> : that reads the same topic and print the messages in the standard output using the Kafka Flink Connector and its Consumer. API.</li>
</ul>


<p>The full project is available on GitHub:</p>

<ul>
<li><a href="https://github.com/mapr-demos/mapr-streams-flink-demo">MapR Streams Flink Demo</a></li>
</ul>


<p>Let’s create the project using Apache Maven:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mvn archetype:generate \
</span><span class='line'>      -DarchetypeGroupId=org.apache.flink\
</span><span class='line'>      -DarchetypeArtifactId=flink-quickstart-java \
</span><span class='line'>      -DarchetypeVersion=1.1.2 \
</span><span class='line'>      -DgroupId=com.mapr.demos \
</span><span class='line'>      -DartifactId=mapr-streams-flink-demo \
</span><span class='line'>      -Dversion=1.0-SNAPSHOT \
</span><span class='line'>      -DinteractiveMode=false 
</span></code></pre></td></tr></table></div></figure>


<p>Maven will create the following structure:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tree mapr-streams-flink-demo/
</span><span class='line'>mapr-streams-flink-demo/
</span><span class='line'>├── pom.xml
</span><span class='line'>└── src
</span><span class='line'>    └── main
</span><span class='line'>        ├── java
</span><span class='line'>        │   └── com
</span><span class='line'>        │       └── mapr
</span><span class='line'>        │           └── demos
</span><span class='line'>        │               ├── BatchJob.java
</span><span class='line'>        │               ├── SocketTextStreamWordCount.java
</span><span class='line'>        │               ├── StreamingJob.java
</span><span class='line'>        │               └── WordCount.java
</span><span class='line'>        └── resources
</span><span class='line'>            └── log4j.properties</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>This project is configured to create a Jar file that contains your flink project code and also includes all dependencies needed to run it.</p>

<p>The project contains some other sample jobs, we do not need them for this article, you can either keep them to educational purposes or simply remove them from the project.</p>

<h2>Add Kafka &amp; MapR Streams Dependencies</h2>

<p>Open the <code>pom.xml</code> and add the following dependencies to your project:</p>

<p><strong>1- Add MapR Maven Repository</strong></p>

<p>In the <code>&lt;repositories&gt;</code> element add :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>   &lt;repository&gt;
</span><span class='line'>     &lt;id&gt;mapr-releases&lt;/id&gt;
</span><span class='line'>     &lt;url&gt;http://repository.mapr.com/maven/&lt;/url&gt;
</span><span class='line'>     &lt;snapshots&gt;&lt;enabled&gt;false&lt;/enabled&gt;&lt;/snapshots&gt;
</span><span class='line'>     &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt;
</span><span class='line'>   &lt;/repository&gt;</span></code></pre></td></tr></table></div></figure>


<p><strong>2- Add MapR Streams libraries</strong></p>

<p>In the <code>&lt;dependencies&gt;</code> element:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> &lt;dependency&gt;
</span><span class='line'>   &lt;groupId&gt;com.mapr.streams&lt;/groupId&gt;
</span><span class='line'>   &lt;artifactId&gt;mapr-streams&lt;/artifactId&gt;
</span><span class='line'>   &lt;version&gt;5.2.0-mapr&lt;/version&gt;
</span><span class='line'> &lt;/dependency&gt;
</span><span class='line'> &lt;dependency&gt;
</span><span class='line'>   &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
</span><span class='line'>   &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
</span><span class='line'>   &lt;version&gt;0.9.0.0-mapr-1602&lt;/version&gt;
</span><span class='line'> &lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p><strong>3- Add Flink Kafka Connector libraries</strong></p>

<p>As a first step, we have to add the Flink Kafka connector as a dependency so that we can use the Kafka sink. Add this to the pom.xml file in the dependencies section:</p>

<p>You must add now the Flink Kafka Connector dependency to use the Kafka sink. Add the following entry in the <code>&lt;dependencies&gt;</code> element:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> &lt;dependency&gt;
</span><span class='line'>      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
</span><span class='line'>      &lt;artifactId&gt;flink-connector-kafka-0.9_2.10&lt;/artifactId&gt;
</span><span class='line'>      &lt;version&gt;${flink.version}&lt;/version&gt;
</span><span class='line'> &lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p><strong>4- Exclude Kafka Client to allow use of MapR Streams Client</strong></p>

<p>As you may know, MapR Streams uses the Kafka 0.9.0 API to produce and consume messages. So we need now to remove (exclude) tha Apache Kafka Client API to be sure that Flink use MapR Streams.</p>

<p>In the Flink Kafka Connector dependency add the following exclusion:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  &lt;dependency&gt;
</span><span class='line'>    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
</span><span class='line'>    &lt;artifactId&gt;flink-connector-kafka-0.9_2.10&lt;/artifactId&gt;
</span><span class='line'>    &lt;version&gt;${flink.version}&lt;/version&gt;
</span><span class='line'>      &lt;exclusions&gt;
</span><span class='line'>        &lt;exclusion&gt;
</span><span class='line'>          &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
</span><span class='line'>          &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
</span><span class='line'>        &lt;/exclusion&gt;
</span><span class='line'>        &lt;exclusion&gt;
</span><span class='line'>          &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
</span><span class='line'>          &lt;artifactId&gt;kafka_2.10&lt;/artifactId&gt;
</span><span class='line'>        &lt;/exclusion&gt;
</span><span class='line'>      &lt;/exclusions&gt;
</span><span class='line'>  &lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p>The Flink project is now ready to use the DataStream using the Kafka Connector so you can send and receive messages from MapR Streams.</p>

<p>Let’s now create a Stream in MapR and write some simple Flink code to use it.</p>

<h2>Create the MapR Streams and Topic</h2>

<p>A stream is a collection of topics that you can manage as a group by:</p>

<ol>
<li>Setting security policies that apply to all topics in that stream</li>
<li>Setting a default number of partitions for each new topic that is created in the stream</li>
<li>Set a time-to-live for messages in every topic in the stream</li>
</ol>


<p>You can find more information about MapR Streams concepts in the <a href="http://maprdocs.mapr.com/51/MapR_Streams/concepts.html">documentation</a>.</p>

<p>On your Mapr Cluster or Sandbox run the following commands:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli stream create -path /apps/application-stream -produceperm p -consumeperm p -topicperm p
</span><span class='line'>$ maprcli stream topic create -path /apps/application-stream -topic flink-demo </span></code></pre></td></tr></table></div></figure>


<h3>Install and use MapR Kafka utilities</h3>

<p>Install <code>the mapr-kafka</code> package on your cluster :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install mapr-kafka</span></code></pre></td></tr></table></div></figure>


<p>Open two terminal windows and run the producer and consumer kafka utilities using the following commands:</p>

<p>Producer</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/kafka/kafka-0.9.0/bin/kafka-console-producer.sh --broker-list this.will.be.ignored:9092 --topic /apps/application-stream:flink-demo</span></code></pre></td></tr></table></div></figure>


<p>Consumer</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/kafka/kafka-0.9.0/bin/kafka-console-consumer.sh --new-consumer --bootstrap-server this.will.be.ignored:9092 --topic /apps/application-stream:flink-demo</span></code></pre></td></tr></table></div></figure>


<p>In the producer window, you can post some messages and see them in the consumer windows. We will use these tools to follow the interactions between MapR Streams and Flink.</p>

<h2>Write your Flink application</h2>

<p>Let’s now use the Flink Kafka Connector to send messages to MapR Streams and consume them.</p>

<h3>Producer</h3>

<p>The producer generates messages using the <code>SimpleStringGenerator()</code> class and send the string to the <code>/apps/application-stream:flink-demo</code> topic.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public static void main(String[] args) throws Exception {
</span><span class='line'>    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
</span><span class='line'>
</span><span class='line'>    Properties properties = new Properties();
</span><span class='line'>    // properties.setProperty("bootstrap.servers", "&lt;kafka-broker&gt;:9092"); // not used by MapR Streams
</span><span class='line'>    properties.setProperty("streams.buffer.max.time.ms", "200");
</span><span class='line'>
</span><span class='line'>    DataStream&lt;String&gt; stream = env.addSource(new SimpleStringGenerator());
</span><span class='line'>    stream.addSink(new FlinkKafkaProducer09&lt;&gt;("/apps/application-stream:flink-demo", new SimpleStringSchema(), properties));
</span><span class='line'>
</span><span class='line'>    env.execute();
</span><span class='line'>  }
</span><span class='line'>    </span></code></pre></td></tr></table></div></figure>


<p>The <code>SimpleStringGenerator()</code> method code is available <a href="https://github.com/mapr-demos/mapr-streams-flink-demo/blob/master/src/main/java/com/mapr/demos/WriteToKafka.java#L46-L61">here</a>.</p>

<p>The main steps are:</p>

<ul>
<li>create a new <code>StreamExecutionEnvironment</code> the basis of any Flink application</li>
<li>create a new <code>DataStream</code> in the application environment, the <code>SimpleStringGenerator</code> class implements the <code>[SourceFunction](https://ci.apache.org/projects/flink/flink-docs-release-1.1/api/java/)</code> the base interface for all streams data sources in Flink.</li>
<li>add the <code>FlinkKafkaProducer09</code> sink to the streams; since MapR Streams is based on Kafka API 0.9, it is possible to use the FlinkKafkaProducer09 class; with 2 small differences:

<ul>
<li>the broker list (first parameter) is not used since MapR Streams use the cluster location defined in the <code>/opt/mapr/conf/mapr-clusters.conf</code> class.</li>
<li>the topic name include the path and name of the MapR Stream stream in which the topic is located for example <code>/apps/application-stream:flink-demo</code></li>
</ul>
</li>
</ul>


<h3>Consumer</h3>

<p>The consumer simply reads the messages from the <code>/apps/application-stream:flink-demo</code> topic, and print them into the console.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  public static void main(String[] args) throws Exception {
</span><span class='line'>    // create execution environment
</span><span class='line'>    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
</span><span class='line'>
</span><span class='line'>    Properties properties = new Properties();
</span><span class='line'>    // properties.setProperty("bootstrap.servers", "&lt;kafka-broker&gt;:9092"); // not used by MapR Streams
</span><span class='line'>    properties.setProperty("group.id", "flink_consumer");
</span><span class='line'>
</span><span class='line'>    DataStream&lt;String&gt; stream = env.addSource(new FlinkKafkaConsumer09&lt;&gt;(
</span><span class='line'>      "/apps/application-stream:flink-demo", new SimpleStringSchema(), properties) );
</span><span class='line'>
</span><span class='line'>    stream.map(new MapFunction&lt;String, String&gt;() {
</span><span class='line'>      private static final long serialVersionUID = -6867736771747690202L;
</span><span class='line'>
</span><span class='line'>      @Override
</span><span class='line'>      public String map(String value) throws Exception {
</span><span class='line'>        return "Stream Value: " + value;
</span><span class='line'>      }
</span><span class='line'>    }).print();
</span><span class='line'>
</span><span class='line'>    env.execute();
</span><span class='line'>  }
</span><span class='line'>  ```
</span><span class='line'>  
</span><span class='line'>The main steps are:
</span><span class='line'>
</span><span class='line'>* create a new `StreamExecutionEnvironment` the basis of any Flink application
</span><span class='line'>* create a set of properties with the consumer information, in this application we can only set the consumer `group.id`. Note that the `bootstrap.servers` property is not used by MapR Streams, so no need to set it.
</span><span class='line'>* use the `FlinkKafkaConsumer09` to get the message from the MapR Streams topic `/apps/application-stream:flink-demo`
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>## Build and Run the application
</span><span class='line'>
</span><span class='line'>Let’s run the application directly from Maven (or from your favorite IDE).
</span><span class='line'>
</span><span class='line'>1- Build the project:
</span></code></pre></td></tr></table></div></figure>


<p>$ mvn clean package</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>2- Run the Flink Producer Job
</span></code></pre></td></tr></table></div></figure>


<p>$ mvn exec:java -Dexec.mainClass=com.mapr.demos.WriteToKafka</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>3- Run the Flink Consumer Job
</span></code></pre></td></tr></table></div></figure>


<p>$ mvn exec:java -Dexec.mainClass=com.mapr.demos.ReadFromKafka
&#8220;`</p>

<p>In the terminal, you should see the messages generated from the producer</p>

<p>You can now deploy and execute this job on your Flink cluster.</p>

<h2>Conclusion</h2>

<p>In this article you have learned how to use Flink with MapR Streams to write and read data streams. The key element is the configuration of the Maven Dependencies to configure the project to use MapR Streams libraries instead of Kafka ones.</p>

<p>This was originally published on the <a href="https://www.mapr.com/blog/getting-started-apache-flink-and-mapr-streams">MapR blog here</a>.</p>

<p>Learn about what Apache Flink can do and how it maintains consistency and provides flexibility in the &ldquo;<a href="https://www.mapr.com/introduction-to-apache-flink">Introduction to Apache Flink</a>&rdquo; ebook.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Apache Flink and Kafka]]></title>
    <link href="http://tgrall.github.io/blog/2016/10/12/getting-started-with-apache-flink-and-kafka/"/>
    <updated>2016-10-12T04:54:17+02:00</updated>
    <id>http://tgrall.github.io/blog/2016/10/12/getting-started-with-apache-flink-and-kafka</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p><a href="https://flink.apache.org/">Apache Flink</a> is an open source platform for distributed stream and batch data processing. Flink is a streaming data flow engine with several APIs to create data streams oriented application.</p>

<p>It is very common for Flink applications to use <a href="http://kafka.apache.org/">Apache Kafka</a> for data input and output. This article will guide you into  the steps to use Apache Flink with Kafka.</p>

<p><img class="center" src="http://tgrall.github.io/images/posts/flink-kafka/flink-kafka.png" title="Flink-Kafka" ></p>

<!-- more -->


<h3>Prerequisites</h3>

<ul>
<li>Apache Kafka 0.9.x</li>
<li>Git</li>
<li>Maven 3.x or later</li>
</ul>


<h2>Create your Flink Streaming Project</h2>

<p>The first step is to create an Java application, the easiest is to use the flink-quickstart-java archetype, that contains the core dependencies and packaging tasks. This article is similar with the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/quickstart/run_example_quickstart.html">Apache Flink Quick Start Example</a>, with a clear focus on data input and output with MapR Streams.</p>

<p>In this application we will create two jobs:</p>

<ul>
<li><code>WriteToKafka</code> : that generates random string and post them to a MapR Streams Topic using the Kafka Flink Connector and its Producer API.</li>
<li><code>ReadFromKafka</code> : that reads the same topic and print the messages in the standard output using the Kafka Flink Connector and its Consumer. API.</li>
</ul>


<p>The full project is available on GitHub:</p>

<ul>
<li><a href="https://github.com/tgrall/kafka-flink-101">Flink and Kakfa Application</a></li>
</ul>


<p>Let’s create the project using Apache Maven:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mvn archetype:generate <span class="se">\</span>
</span><span class='line'>      -DarchetypeGroupId<span class="o">=</span>org.apache.flink<span class="se">\</span>
</span><span class='line'>      -DarchetypeArtifactId<span class="o">=</span>flink-quickstart-java <span class="se">\</span>
</span><span class='line'>      -DarchetypeVersion<span class="o">=</span>1.1.2 <span class="se">\</span>
</span><span class='line'>      -DgroupId<span class="o">=</span>com.grallandco.demos <span class="se">\</span>
</span><span class='line'>      -DartifactId<span class="o">=</span>kafka-flink-101 <span class="se">\</span>
</span><span class='line'>      -Dversion<span class="o">=</span>1.0-SNAPSHOT <span class="se">\</span>
</span><span class='line'>      -DinteractiveMode<span class="o">=</span><span class="nb">false</span>
</span></code></pre></td></tr></table></div></figure>


<p>Maven will create the following structure:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tree kafka-flink-101/
</span><span class='line'>kafka-flink-101/
</span><span class='line'>├── pom.xml
</span><span class='line'>└── src
</span><span class='line'>    └── main
</span><span class='line'>        ├── java
</span><span class='line'>        │   └── com
</span><span class='line'>        │       └── grallandco
</span><span class='line'>        │           └── demos
</span><span class='line'>        │               ├── BatchJob.java
</span><span class='line'>        │               ├── SocketTextStreamWordCount.java
</span><span class='line'>        │               ├── StreamingJob.java
</span><span class='line'>        │               └── WordCount.java
</span><span class='line'>        └── resources
</span><span class='line'>            └── log4j.properties
</span><span class='line'>
</span><span class='line'><span class="m">7</span> directories, <span class="m">6</span> files
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>This project is configured to create a Jar file that contains your flink project code and also includes all dependencies needed to run it.</p>

<p>The project contains some other sample jobs, we do not need them for this article, you can either keep them to educational purposes or simply remove them from the project.</p>

<h2>Add Kafka Connector</h2>

<p>Open the <code>pom.xml</code> and add the following dependencies to your project:</p>

<p>As a first step, we have to add the Flink Kafka connector as a dependency so that we can use the Kafka sink. Add this to the pom.xml file in the dependencies section:</p>

<p>You must add now the Flink Kafka Connector dependency to use the Kafka sink. Add the following entry in the <code>&lt;dependencies&gt;</code> element:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'> &lt;dependency&gt;
</span><span class='line'>      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
</span><span class='line'>      &lt;artifactId&gt;flink-connector-kafka-0.9_2.10&lt;/artifactId&gt;
</span><span class='line'>      &lt;version&gt;<span class="k">${</span><span class="nv">flink</span><span class="p">.version</span><span class="k">}</span>&lt;/version&gt;
</span><span class='line'> &lt;/dependency&gt;
</span></code></pre></td></tr></table></div></figure>


<p>The Flink project is now ready to use the DataStream using the Kafka Connector so you can send and receive messages from Apache Kafka.</p>

<h2>Install and Start Kafka</h2>

<p>Download Kafka, enter the following commands in your terminal:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -O http://www.us.apache.org/dist/kafka/0.9.0.0/kafka_2.11-0.9.0.0.tgz
</span><span class='line'>tar -xzf kafka_2.11-0.9.0.0.tgz
</span><span class='line'><span class="nb">cd </span>kafka_2.11-0.9.0.0
</span></code></pre></td></tr></table></div></figure>


<p>Kafka uses ZooKeeper, if you do not have Zookeeper running, you can start it using the following command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/zookeeper-server-start.sh config/zookeeper.properties
</span></code></pre></td></tr></table></div></figure>


<p>Start a Kafka broker by running the following command in a new terminal:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/kafka-server-start.sh config/server.properties
</span></code></pre></td></tr></table></div></figure>


<p>In another terminal, run the following command to create a Kafka topic called <code>flink-demo</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor <span class="m">1</span> --partitions <span class="m">1</span> --topic flink-demo
</span></code></pre></td></tr></table></div></figure>


<p>Use the Kafka tools to post and consume messages to the <code>flink-demo</code> topic.</p>

<p>Producer</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic flink-demo
</span></code></pre></td></tr></table></div></figure>


<p>Consumer</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic flink-demo --from-beginning
</span></code></pre></td></tr></table></div></figure>


<p>In the producer window, you can post some messages and see them in the consumer windows. We will use these tools to follow the interactions between Kafka and Flink.</p>

<h2>Write your Flink application</h2>

<p>Let’s now use the Flink Kafka Connector to send messages to Kafka and consume them.</p>

<h3>Producer</h3>

<p>The producer generates messages using the <code>SimpleStringGenerator()</code> class and send the string to the <code>flink-demo</code> topic.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>  public static void main<span class="o">(</span>String<span class="o">[]</span> args<span class="o">)</span> throws Exception <span class="o">{</span>
</span><span class='line'>    StreamExecutionEnvironment <span class="nv">env</span> <span class="o">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="o">()</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    Properties <span class="nv">properties</span> <span class="o">=</span> new Properties<span class="o">()</span><span class="p">;</span>
</span><span class='line'>    properties.setProperty<span class="o">(</span><span class="s2">&quot;bootstrap.servers&quot;</span>, “localhost:9092<span class="s2">&quot;); </span>
</span><span class='line'>
</span><span class='line'><span class="s2">    DataStream&lt;String&gt; stream = env.addSource(new SimpleStringGenerator());</span>
</span><span class='line'><span class="s2">    stream.addSink(new FlinkKafkaProducer09&lt;&gt;(&quot;</span>flink-demo<span class="err">&quot;</span>, new SimpleStringSchema<span class="o">()</span>, properties<span class="o">))</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    env.execute<span class="o">()</span><span class="p">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>SimpleStringGenerator()</code> method code is available <a href="https://github.com/tgrall/kafka-flink-101/blob/master/src/main/java/com/grallandco/demos/WriteToKafka.java#L45-L60">here</a>.</p>

<p>The main steps are:</p>

<ul>
<li>create a new <code>StreamExecutionEnvironment</code> the basis of any Flink application</li>
<li>create a new <code>DataStream</code> in the application environment, the <code>SimpleStringGenerator</code> class implements the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/api/java/">SourceFunction</a> the base interface for all streams data sources in Flink.</li>
<li>add the <code>FlinkKafkaProducer09</code> sink to the topic.</li>
</ul>


<h3>Consumer</h3>

<p>The consumer simply reads the messages from the <code>flink-demo</code> topic, and print them into the console.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>  public static void main<span class="o">(</span>String<span class="o">[]</span> args<span class="o">)</span> throws Exception <span class="o">{</span>
</span><span class='line'>    // create execution environment
</span><span class='line'>    StreamExecutionEnvironment <span class="nv">env</span> <span class="o">=</span> StreamExecutionEnvironment.getExecutionEnvironment<span class="o">()</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    Properties <span class="nv">properties</span> <span class="o">=</span> new Properties<span class="o">()</span><span class="p">;</span>
</span><span class='line'>    properties.setProperty<span class="o">(</span><span class="s2">&quot;bootstrap.servers&quot;</span>, “localhost:9092<span class="s2">&quot;);</span>
</span><span class='line'><span class="s2">    properties.setProperty(&quot;</span>group.id<span class="s2">&quot;, &quot;</span>flink_consumer<span class="s2">&quot;);</span>
</span><span class='line'>
</span><span class='line'><span class="s2">    DataStream&lt;String&gt; stream = env.addSource(new FlinkKafkaConsumer09&lt;&gt;(</span>
</span><span class='line'><span class="s2">     &quot;</span>flink-demo<span class="s2">&quot;, new SimpleStringSchema(), properties) );</span>
</span><span class='line'>
</span><span class='line'><span class="s2">    stream.map(new MapFunction&lt;String, String&gt;() {</span>
</span><span class='line'><span class="s2">      private static final long serialVersionUID = -6867736771747690202L;</span>
</span><span class='line'>
</span><span class='line'><span class="s2">      @Override</span>
</span><span class='line'><span class="s2">      public String map(String value) throws Exception {</span>
</span><span class='line'><span class="s2">        return &quot;</span>Stream Value: <span class="err">&quot;</span> + value<span class="p">;</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>    <span class="o">})</span>.print<span class="o">()</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    env.execute<span class="o">()</span><span class="p">;</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The main steps are:</p>

<ul>
<li>create a new <code>StreamExecutionEnvironment</code> the basis of any Flink application</li>
<li>create a set of properties with the consumer information, in this application we can only set the consumer <code>group.id</code>.</li>
<li>use the <code>FlinkKafkaConsumer09</code> to get the message from the topic <code>flink-demo</code></li>
</ul>


<h2>Build and Run the application</h2>

<p>Let’s run the application directly from Maven (or from your favorite IDE).</p>

<p>1- Build the project:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>mvn clean package
</span></code></pre></td></tr></table></div></figure>


<p>2- Run the Flink Producer Job</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>mvn <span class="nb">exec</span>:java -Dexec.mainClass<span class="o">=</span>com.mapr.demos.WriteToKafka
</span></code></pre></td></tr></table></div></figure>


<p>3- Run the Flink Consumer Job</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>mvn <span class="nb">exec</span>:java -Dexec.mainClass<span class="o">=</span>com.mapr.demos.ReadFromKafka
</span></code></pre></td></tr></table></div></figure>


<p>In the terminal, you should see the messages generated from the producer</p>

<p>You can now deploy and execute this job on your Flink cluster.</p>

<h2>Conclusion</h2>

<p>In this article you have learned how to use Flink with kafka to write and read data streams.</p>

<p>Learn about what Apache Flink can do and how it maintains consistency and provides flexibility in the &ldquo;<a href="https://www.mapr.com/introduction-to-apache-flink">Introduction to Apache Flink</a>&rdquo; ebook.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Streaming Analytics in a Digitally Industrialized World]]></title>
    <link href="http://tgrall.github.io/blog/2016/09/26/streaming-analytics-in-a-digitally-industrialized-world/"/>
    <updated>2016-09-26T15:30:20+02:00</updated>
    <id>http://tgrall.github.io/blog/2016/09/26/streaming-analytics-in-a-digitally-industrialized-world</id>
    <content type="html"><![CDATA[<p>Get an introduction to streaming analytics, which allows you real-time insight from captured events and big data. There are applications across industries, from finance to wine making, though there are two primary challenges to be addressed.</p>

<p>Did you know that a plane flying from Texas to London can generate 30 million data points per flight? As Jim Daily of GE Aviation notes, that equals <a href="https://www.ge.com/digital/blog/industrial-iot-improving-airline-economics">10 billion data points</a> in one year. And we’re talking about one plane alone. So you can understand why <a href="http://cloudblog.ericsson.com/cloud-scalability-combined-with-speed-inside-ges-cloud-transformation">another top GE executive recently told Ericsson Business Review</a> that &ldquo;Cloud is the future of IT,&rdquo; with a focus on supporting challenging applications in industries such as aviation and energy.</p>

<!-- more -->


<h3>The benefits of big data</h3>

<p>Today, thanks to modern big data platforms, many companies are able to take advantage of the same methods as industry giant GE to store, process, and analyze massive amounts of data. This means that you can also capture core business data, such as that coming from a CRM system, or traffic sensors, or say jet engines, and associate it to other data such as social, application, blog or industrial data. Ultimately, this will result in greater data insights and can enable things like better customer segmentation and prediction.</p>

<p>Sounds great, right? There’s a catch. The challenge is that these data are processed in batch mode, meaning that you have to wait a few hours or even days to access relevant KPI’s and insights. Not only is there a delay, but analysis is based on data that’s out of date – even if only by a few hours.</p>

<h3>Analysis of big event streams</h3>

<p>That’s where streaming analytics comes in. Streaming analytics is the <a href="http://searchcloudapplications.techtarget.com/opinion/Streaming-analytics-lets-you-view-the-past-to-see-the-future?utm_medium=EM&amp;asrc=EM_NLN_58517129&amp;utm_campaign=20160606_Seeing%20the%20future...with%20the%20past?_fchurchville&amp;utm_source=NLN&amp;track=NL-1839&amp;ad=908120&amp;src=908120">analysis of large event streams</a>, which is data that is in constant movement. These streams can include actions that can be incredibly small, say one click, yet result in an explosion of data. The benefit is that you can capture events and data as they happen, delivering value to the enterprise in near real time.</p>

<p>What does streaming analytics look like regarding the previously mentioned CRM system? It means that an enterprise can get immediate feedback on something like a specific marketing campaign, website update, or product alteration. When a user clicks within one of these realms and an order is immediately processed, that information is pushed out in real time to various tools, allowing the enterprise to adjust its customer interaction.</p>

<h3>Streaming analytics in practice</h3>

<p>Where else is streaming analytics applicable? Think about the benefits of fraud detection in the financial sector, or the growth of sensors in manufacturing, or collection of data from large scale machines. One example is where Ericsson has collaborated with <a href="http://cloudblog.ericsson.com/can-the-networked-society-and-iot-make-better-wine">vintners in Germany, using IoT to improve traditional harvesting methods</a> through greater precision and speed of response to outside factors. In these streaming analytics scenarios, the key is “<a href="https://www.mapr.com/blog/lets-get-real-acting-data-real-time">High-Frequency Decisioning,</a>” where you move from knowing to doing in real-time synergy. Time to action is compressed, resulting in dramatic results like achieving greater user satisfaction, higher revenue, or reduced risk.</p>

<h3>Two primary challenges with streaming analytics</h3>

<p>Streaming analytics is not without challenges. Systems must capture events in near real time, at scale, and in a distributed fashion. And of course, events must be stored and processed in real time. Since big data is generated one event at a time, you need to have an incredibly powerful storage and processing layer, which can provide deep analytics and rich features like machine learning systems.</p>

<p>To take on the first challenge, new messaging systems like <a href="http://kafka.apache.org">Apache Kafka</a> and <a href="https://www.mapr.com/products/mapr-streams">MapR Streams</a> provide a common API for developers to publish and subscribe to any event. And to process and store data in real-time, one of the most efficient methods would be to use a <a href="https://www.mapr.com/products/mapr-fs">distributed file system</a> and <a href="https://www.mapr.com/products/mapr-db-in-hadoop-nosql">NoSQL databases</a>. This provides horizontal scalability and flexibility. A storage system must also process and do analytics calculations in real time in a distributed manner.</p>

<p>Tools such as <a href="https://www.mapr.com/products/apache-spark">Apache Spark</a> and <a href="http://flink.apache.org">Flink</a> come to mind, which provide rich analytical functions that can be integrated with any tool, including real time alerting systems. It is also interesting to mention that all the events, data, that are now stored in real time continue to be accessible with traditional analytics tools; thanks to the distributed, and scalable distributed SQL Engines provided in modern big data platforms.</p>

<p>This was originally published on the <a href="http://cloudblog.ericsson.com/streaming-analytics-of-big-data-in-real-time">Ericsson Cloud blog here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Up Spark Dynamic Allocation on MapR]]></title>
    <link href="http://tgrall.github.io/blog/2016/09/01/setting-up-spark-dynamic-allocation-on-mapr/"/>
    <updated>2016-09-01T11:15:57+02:00</updated>
    <id>http://tgrall.github.io/blog/2016/09/01/setting-up-spark-dynamic-allocation-on-mapr</id>
    <content type="html"><![CDATA[<p>Apache Spark can use various cluster manager to execute application (Stand Alone, YARN, Apache Mesos). When you install Apache Spark on MapR you can submit application in a Stand Alone mode or using YARN.</p>

<p>This article focuses on YARN and Dynamic Allocation, a feature that lets Spark add or remove executors dynamically based on the workload. You can find more information about this feature in this presentation from Databricks:</p>

<ul>
<li><a href="http://www.slideshare.net/databricks/dynamic-allocation-in-spark">Dynamic Allocation in Spark</a></li>
</ul>


<p>Let’s see how to configure Spark and YARN to use dynamic allocation (that is disabled by default).</p>

<!-- more -->


<h4>Prerequisites</h4>

<ul>
<li>MapR Converged Data Platform Cluster</li>
<li>Apache Spark for MapR installed</li>
</ul>


<p>This example has been described for MapR 5.2 with Apache Spark 1.6.1, you just need to adapt the version to your environment.</p>

<h3>Enabling Dynamic Allocation in Apache Spark</h3>

<p>The first thing to do is to enable Dynamic Allocation in Spark, for this you need to edit the spark configuration file on each Spark node.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/spark/spark-1.6.1/conf/spark-defaults.conf</span></code></pre></td></tr></table></div></figure>


<p>and add the following entries:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>spark.dynamicAllocation.enabled = true
</span><span class='line'>spark.shuffle.service.enabled = true
</span><span class='line'>spark.dynamicAllocation.minExecutors = 5 
</span><span class='line'>spark.executor.instances = 0</span></code></pre></td></tr></table></div></figure>


<p>You can find additional configuration options in the <a href="http://spark.apache.org/docs/1.6.1/configuration.html#dynamic-allocation">Apache Spark Documentation</a>.</p>

<h3>Enabling Spark External Shuffle for YARN</h3>

<p>You have now to edit YARN configuration to add information about Spark Shuffle Service, edit the following file, on each YARN node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/hadoop/hadoop-2.7.0/etc/hadoop/yarn-site.xml</span></code></pre></td></tr></table></div></figure>


<p>add these properties:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>  &lt;property&gt;
</span><span class='line'>    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;mapreduce_shuffle,mapr_direct_shuffle,spark_shuffle&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;
</span><span class='line'>  &lt;property&gt;
</span><span class='line'>    &lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;
</span><span class='line'>    &lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;
</span><span class='line'>  &lt;/property&gt;</span></code></pre></td></tr></table></div></figure>


<h4>Add Spark Shuffle to YARN classpath</h4>

<p>Spark Shuffle service must be added to the YARN classpath. The jar is located in the spark distribution:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/spark/spark-1.6.1/lib/spark-1.6.1-mapr-1605-yarn-shuffle.jar</span></code></pre></td></tr></table></div></figure>


<p>To achieve this add the jar in the following folder on each node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/hadoop/hadoop-2.7.0/share/hadoop/yarn/lib</span></code></pre></td></tr></table></div></figure>


<p>You can either copyy the file or create a symlink:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ln -s /opt/mapr/spark/spark-1.6.1/lib/spark-1.6.1-mapr-1605-yarn-shuffle.jar /opt/mapr/hadoop/hadoop-2.7.0/share/hadoop/yarn/lib</span></code></pre></td></tr></table></div></figure>


<h4>Restart YARN</h4>

<p>Since you have changed the YARN configuration <em>you must restart your node managers</em> using the following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ maprcli node services -name nodemanager -action restart -nodes [list of nodes]</span></code></pre></td></tr></table></div></figure>


<h3>Submitting a Spark Job</h3>

<p>Your MapR Cluster is not ready to use Spark dynamic allocation, this means that when you submit a job you do not need to specify any resource configuration, for example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/spark/spark-1.6.1/bin/spark-submit \
</span><span class='line'>  --class com.mapr.demo.WordCountSorted \
</span><span class='line'>  --master yarn \
</span><span class='line'>  ~/spark-examples-1.0-SNAPSHOT.jar \
</span><span class='line'>  /mapr/my.cluster.com/input/4gb_txt_file.txt \
</span><span class='line'>  /mapr/my.cluster.com/user/mapr/output/</span></code></pre></td></tr></table></div></figure>


<p>note that you can still specify the resources, but in this case the dynamic allocation will not be used for this specific job, for example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/mapr/spark/spark-1.6.1/bin/spark-submit \
</span><span class='line'>  --class com.mapr.demo.WordCountSorted \
</span><span class='line'>  --master yarn \
</span><span class='line'>  --num-executors 3
</span><span class='line'>  --executor-memory 1G \
</span><span class='line'>  ~/spark-examples-1.0-SNAPSHOT.jar \
</span><span class='line'>  /mapr/my.cluster.com/input/4gb_txt_file.txt \
</span><span class='line'>  /mapr/my.cluster.com/user/mapr/output/</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Save MapR Streams Messages Into MapR DB JSON]]></title>
    <link href="http://tgrall.github.io/blog/2016/03/31/save-mapr-streams-messages-into-mapr-db-json/"/>
    <updated>2016-03-31T09:00:07+02:00</updated>
    <id>http://tgrall.github.io/blog/2016/03/31/save-mapr-streams-messages-into-mapr-db-json</id>
    <content type="html"><![CDATA[<p>In this article you will learn how to create a MapR Streams Consumer that saves all the messages into a <a href="http://maprdocs.mapr.com/51/#MapR-DB/JSON_DB/mapr_db_json_top.html">MapR-DB JSON Table</a>.</p>

<!-- more -->


<h3>Install and Run the sample MapR Streams application</h3>

<p>The steps to install and run the applications are the same as the one defined in the following article:</p>

<ul>
<li><a href="https://www.mapr.com/blog/getting-started-sample-programs-mapr-streams">MapR Streams application</a></li>
</ul>


<p>Once you have the default producer and consumer running in your environment using the commands:</p>

<p>Producer:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ java -cp $(mapr classpath):./mapr-streams-examples-1.0-SNAPSHOT-jar-with-dependencies.jar com.mapr.examples.Run producer</span></code></pre></td></tr></table></div></figure>


<p>Consumer:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ java -cp $(mapr classpath):./mapr-streams-examples-1.0-SNAPSHOT-jar-with-dependencies.jar com.mapr.examples.Run consumer</span></code></pre></td></tr></table></div></figure>


<h3>Save messages into MapR-DB JSON</h3>

<p>The <a href="https://github.com/mapr-demos/mapr-streams-sample-programs/blob/master/src/main/java/com/mapr/examples/DBConsumer.java">DBConsumer</a> class is a copy of the <a href="https://github.com/mapr-demos/mapr-streams-sample-programs/blob/master/src/main/java/com/mapr/examples/Consumer.java">Consumer</a> class with small changes to save the messages coming from the <code>/sample-stream:fast-messages</code> topic into a MapR-DB table named <code>/apps/fast-messages</code>.</p>

<p><strong>1- Add MapR-DB Maven dependency to your project</strong></p>

<p>Edit the <code>pom.xml</code> file and add the following entry in the <code>dependencies</code> tag:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>   <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>      <span class="nt">&lt;groupId&gt;</span>com.mapr.db<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>      <span class="nt">&lt;artifactId&gt;</span>maprdb<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>      <span class="nt">&lt;version&gt;</span>5.1.0-mapr<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>   <span class="nt">&lt;/dependency&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>This add support for:</p>

<ul>
<li><a href="http://ojai.io/">OJAI</a> Open JSON Application Interface</li>
<li><a href="http://maprdocs.mapr.com/51/#MapR-DB/JSON_DB/crud_with_maprdb_ojai_java_api.html">MapR-DB JSON API</a></li>
</ul>


<p><strong>2- Create and Get a JSON Table</strong></p>

<p>To save the messages, the application must access a JSON Table, for this just call the <code>MapRDB.getTable(TABLE_PATH)</code> method. If the table does not exist, create it with the <code>MapRDB.createTable(TABLE_PATH)</code>.</p>

<p>This is what the <a href="https://github.com/mapr-demos/mapr-streams-sample-programs/blob/master/src/main/java/com/mapr/examples/DBConsumer.java#L113-L119"><code>DBConsumer.getTable(TABLE_PATH)</code></a> method is doing.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>  <span class="kd">private</span> <span class="kd">static</span> <span class="n">Table</span> <span class="nf">getTable</span><span class="o">(</span><span class="n">String</span> <span class="n">tablePath</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(</span> <span class="o">!</span> <span class="n">MapRDB</span><span class="o">.</span><span class="na">tableExists</span><span class="o">(</span><span class="n">tablePath</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">MapRDB</span><span class="o">.</span><span class="na">createTable</span><span class="o">(</span><span class="n">tablePath</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">MapRDB</span><span class="o">.</span><span class="na">getTable</span><span class="o">(</span><span class="n">tablePath</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>When the DBConsumer starts the <a href="https://github.com/mapr-demos/mapr-streams-sample-programs/blob/master/src/main/java/com/mapr/examples/DBConsumer.java#L41"><code>getTable("/apps/fast-messages")</code></a> method is called.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>  <span class="n">Table</span> <span class="n">fastMessagesTable</span> <span class="o">=</span> <span class="n">getTable</span><span class="o">(</span><span class="s">&quot;/apps/fast-messages&quot;</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The table <code>fastMessagesTable</code> is not available to the consumer.</p>

<p><strong>3- Save messages into the JSON Table</strong></p>

<p>Messages can be saved into the table using the <a href="https://github.com/mapr-demos/mapr-streams-sample-programs/blob/master/src/main/java/com/mapr/examples/DBConsumer.java#L78-L81">MapR-DB JSON Java API</a>.</p>

<p>The producer sends the message as JSON String that is converted into a JSON object names <code>msg</code>. This object can be used to create an OJAI Document:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>  <span class="n">Document</span> <span class="n">messageDocument</span> <span class="o">=</span> <span class="n">MapRDB</span><span class="o">.</span><span class="na">newDocument</span><span class="o">(</span><span class="n">msg</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>To be saved into MapR-DB, a document must have a <code>_id</code> field. In this example let’s use the message number generated by the producer <em>(JSON field <code>k</code>)</em>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>  <span class="n">messageDocument</span><span class="o">.</span><span class="na">setId</span><span class="o">(</span> <span class="n">Integer</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">messageDocument</span><span class="o">.</span><span class="na">getInt</span><span class="o">(</span><span class="s">&quot;k&quot;</span><span class="o">)));</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let’s now save the document into the table:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>  <span class="n">fastMessagesTable</span><span class="o">.</span><span class="na">insertOrReplace</span><span class="o">(</span> <span class="n">messageDocument</span> <span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Each time the producer will be executed, the message number counter will be initialized to 0. So the document _id will be the same, and the document into the table must be replaced; this is why the <code>insertOrReplace</code> method is used.</p>

<p>Let’s run the new consumer.</p>

<p><strong>4- Run the DBConsumer</strong></p>

<p>To run the DBConsumer just pass the parameter <code>dbconsumer</code> as follow:</p>

<p>Consumer:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">$</span> <span class="n">java</span> <span class="o">-</span><span class="n">cp</span> <span class="nf">$</span><span class="o">(</span><span class="n">mapr</span> <span class="n">classpath</span><span class="o">):./</span><span class="n">mapr</span><span class="o">-</span><span class="n">streams</span><span class="o">-</span><span class="n">examples</span><span class="o">-</span><span class="mf">1.0</span><span class="o">-</span><span class="n">SNAPSHOT</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="o">.</span><span class="na">jar</span> <span class="n">com</span><span class="o">.</span><span class="na">mapr</span><span class="o">.</span><span class="na">examples</span><span class="o">.</span><span class="na">Run</span> <span class="n">dbconsumer</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that a new <a href="https://github.com/mapr-demos/mapr-streams-sample-programs/blob/master/src/main/java/com/mapr/examples/DBConsumer.java#L48-L54">group is created</a> to be sure that messages are read by the two different consumers (Consumer and DBConsumer).</p>

<p><strong>5- Query the messages saved into MapR-DB</strong></p>

<p>Messages are saved into the <code>/apps/fast-messages</code> table, let’s used the MapR DBShell to query the data. On your cluster run the following commands, as <code>mapr</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">$</span> <span class="n">mapr</span> <span class="n">dbshell</span>
</span><span class='line'><span class="n">maprdb</span> <span class="nl">mapr:</span><span class="o">&gt;</span> <span class="n">find</span> <span class="o">/</span><span class="n">apps</span><span class="o">/</span><span class="n">fast</span><span class="o">-</span><span class="n">messages</span> <span class="o">--</span><span class="n">id</span> <span class="mi">100</span>
</span><span class='line'><span class="o">{</span><span class="s">&quot;_id&quot;</span><span class="o">:</span><span class="s">&quot;100&quot;</span><span class="o">,</span><span class="s">&quot;type&quot;</span><span class="o">:</span><span class="s">&quot;test&quot;</span><span class="o">,</span><span class="s">&quot;t&quot;</span><span class="o">:</span><span class="mf">64986.787</span><span class="o">,</span><span class="s">&quot;k&quot;</span><span class="o">:{</span><span class="s">&quot;$numberLong&quot;</span><span class="o">:</span><span class="mi">100</span><span class="o">}}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Conclusion</h3>

<p>In this very simple example, the DBConsumer takes each message and saved it as a simple JSON Document into MapR-DB JSON. The table can be used to create any type of application, or using Apache Drill <em>(1.6 or later)</em> to do some analytics.</p>

<p>In a real application the messages will probably be modified, enriched and/or aggregated and then the result be saved into MapR-DB Table. The goal of this sample is just to show that it is easy to integrate MapR Streams and MapR-DB.</p>

<p>You have also other alternative to achieve the same thing using for example:</p>

<ul>
<li>Spark Streaming</li>
<li>3rd Party ETL and Tools</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With MapR Streams]]></title>
    <link href="http://tgrall.github.io/blog/2016/03/10/getting-started-with-mapr-streams/"/>
    <updated>2016-03-10T10:09:32+01:00</updated>
    <id>http://tgrall.github.io/blog/2016/03/10/getting-started-with-mapr-streams</id>
    <content type="html"><![CDATA[<p>You can find a new tutorial that explains how to deploy an Apache Kafka application to MapR Streams, the tutorial is available here:</p>

<ul>
<li><a href="https://www.mapr.com/blog/getting-started-sample-programs-mapr-streams">Getting Started with MapR Streams</a></li>
</ul>


<p>MapR Streams is a new distributed messaging system for streaming event data at scale, and it’s integrated into the MapR converged platform.
MapR Streams uses the Apache Kafka API, so if you’re already familiar with Kafka, you’ll find it particularly easy to get started with MapR Streams.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With Sample Programs for Apache Kafka 0.9]]></title>
    <link href="http://tgrall.github.io/blog/2016/02/10/getting-started-with-sample-programs-for-apache-kafka-0-dot-9/"/>
    <updated>2016-02-10T10:25:44+01:00</updated>
    <id>http://tgrall.github.io/blog/2016/02/10/getting-started-with-sample-programs-for-apache-kafka-0-dot-9</id>
    <content type="html"><![CDATA[<p>Ted Dunning and I have worked on a tutorial that explains how to write your first Kafka application. In this tutorial you will learn how to:</p>

<ul>
<li>Install and start Kafka</li>
<li>Create and Run a producer and a consumer</li>
</ul>


<p>You can find the tutorial on the MapR blog:</p>

<ul>
<li><a href="https://goo.gl/cWmbmY">Getting Started with Sample Programs for Apache Kafka 0.9</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Apache Drill REST API to Build ASCII Dashboard With Node]]></title>
    <link href="http://tgrall.github.io/blog/2015/12/10/using-apache-drill-rest-api-to-build-ascii-dashboard-with-node/"/>
    <updated>2015-12-10T11:30:44+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/12/10/using-apache-drill-rest-api-to-build-ascii-dashboard-with-node</id>
    <content type="html"><![CDATA[<p><a href="http://drill.apache.org">Apache Drill</a> has a hidden gem: an easy to use REST interface. This API can be used to Query, Profile and Configure Drill engine.</p>

<p>In this blog post I will explain how to use Drill REST API to create ascii dashboards using <a href="https://www.npmjs.com/package/blessed-contrib">Blessed Contrib</a>.</p>

<p>The ASCII Dashboard looks like</p>

<p><img class="center" src="http://tgrall.github.io/images/posts/drill_dashboard/dashboard_demo.gif" title="Dashboard" ></p>

<!-- more -->


<h4>Prerequisites</h4>

<ul>
<li>Node.js</li>
<li>Apache Drill 1.2</li>
<li>For this post, you will use the SFO Passengers CSV file available <a href="http://www.flysfo.com/media/facts-statistics/air-traffic-statistics">here</a>.

<ul>
<li>Download this locally, unzip the files and put the CSV into a folder that will be access uzing the following path in Drill : <code>dfs.data.`/airport/*.csv`</code></li>
</ul>
</li>
</ul>


<p><em>Note: I am still using Apache 1.2 to allow this example to be executed in context of a MapR cluster.</em></p>

<h2>The Query and View</h2>

<p>In Drill 1.2, CSV headers are not automatically parsed. (This is one of the new features of 1.3: look for <code>extractHeader</code> in the <a href="https://drill.apache.org/docs/text-files-csv-tsv-psv/">documentation</a>).</p>

<p>For simplicity, remove the first line of the CSV.</p>

<p>The basic query will look like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT
</span><span class='line'>CAST(SUBSTR(columns[0],1,4) AS INT)  `YEAR`,
</span><span class='line'>CAST(SUBSTR(columns[0],5,2) AS INT) `MONTH`,
</span><span class='line'>columns[1] as `AIRLINE`,
</span><span class='line'>columns[2] as `IATA_CODE`,
</span><span class='line'>columns[3] as `AIRLINE_2`,
</span><span class='line'>columns[4] as `IATA_CODE_2`,
</span><span class='line'>columns[5] as `GEO_SUMMARY`,
</span><span class='line'>columns[6] as `GEO_REGION`,
</span><span class='line'>columns[7] as `ACTIVITY_CODE`,
</span><span class='line'>columns[8] as `PRICE_CODE`,
</span><span class='line'>columns[9] as `TERMINAL`,
</span><span class='line'>columns[10] as `BOARDING_AREA`,
</span><span class='line'>CAST(columns[11] AS DOUBLE) as `PASSENGER_COUNT`
</span><span class='line'>FROM dfs.data.`/airport/*.csv`
</span><span class='line'>LIMIT 10</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s now create a view with these columns: <em>(do not put any limit !)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE OR REPLACE VIEW dfs.tmp.`airport_data_view` AS
</span><span class='line'>SELECT
</span><span class='line'>CAST(SUBSTR(columns[0],1,4) AS INT)  `YEAR`,
</span><span class='line'>CAST(SUBSTR(columns[0],5,2) AS INT) `MONTH`,
</span><span class='line'>columns[1] as `AIRLINE`,
</span><span class='line'>columns[2] as `IATA_CODE`,
</span><span class='line'>columns[3] as `AIRLINE_2`,
</span><span class='line'>columns[4] as `IATA_CODE_2`,
</span><span class='line'>columns[5] as `GEO_SUMMARY`,
</span><span class='line'>columns[6] as `GEO_REGION`,
</span><span class='line'>columns[7] as `ACTIVITY_CODE`,
</span><span class='line'>columns[8] as `PRICE_CODE`,
</span><span class='line'>columns[9] as `TERMINAL`,
</span><span class='line'>columns[10] as `BOARDING_AREA`,
</span><span class='line'>CAST(columns[11] AS DOUBLE) as `PASSENGER_COUNT`
</span><span class='line'>FROM dfs.data.`/airport/*.csv`</span></code></pre></td></tr></table></div></figure>


<p>So you can now use the view in your query:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>select * from dfs.tmp.`airport_data_view` limit 5;</span></code></pre></td></tr></table></div></figure>


<h2>Use the REST API</h2>

<p>Now that you have the query you can use the REST API to retrieve the data as JSON document over HTTP. Open a terminal and run this curl command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl  \
</span><span class='line'>  --header "Content-type: application/json" \
</span><span class='line'>  --request POST \
</span><span class='line'>  --data '{
</span><span class='line'>    "queryType" : "SQL",
</span><span class='line'>    "query" : "select * from dfs.tmp.`airport_data_view` limit 5 " }' \
</span><span class='line'>  http://localhost:8047/query.json</span></code></pre></td></tr></table></div></figure>


<p>The returned JSON document looks like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "columns" : [ "YEAR", "MONTH", ... , "PASSENGER_COUNT" ],
</span><span class='line'>  "rows" : [ {
</span><span class='line'>    "GEO_REGION" : "US",
</span><span class='line'>    "IATA_CODE_2" : "TZ",
</span><span class='line'>      ...
</span><span class='line'>      ...
</span><span class='line'>    "AIRLINE" : "ATA Airlines",
</span><span class='line'>    "MONTH" : "7",
</span><span class='line'>    "ACTIVITY_CODE" : "Deplaned"
</span><span class='line'>  }, {
</span><span class='line'>    "GEO_REGION" : "US",
</span><span class='line'>    "IATA_CODE_2" : "TZ",
</span><span class='line'>    "GEO_SUMMARY" : "Domestic",
</span><span class='line'>    ...
</span><span class='line'>  }
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>As you can see it is quite simple:</p>

<ul>
<li>a first JSON attribute that list the columns</li>
<li>the list of rows, as JSON documents in an array.</li>
</ul>


<h2>Create a Graph using Node.js &amp; Blessed Contrib</h2>

<p>Let&rsquo;s create a node application.</p>

<p>First you have to include:</p>

<ul>
<li><code>request</code> : to call the REST API</li>
<li><code>blessed</code> : to get a rich Terminal API</li>
<li><code>blessed-contrib</code> : for the dashboard</li>
</ul>


<p>and then create a <code>screen</code> and a <code>bar</code> chard from Contrib.</p>

<p>So the <em>header</em> of your Javascript file looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">var</span> <span class="nx">blessed</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;blessed&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="nx">contrib</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;blessed-contrib&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="nx">request</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;request&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="nx">screen</span> <span class="o">=</span> <span class="nx">blessed</span><span class="p">.</span><span class="nx">screen</span><span class="p">()</span>
</span><span class='line'>  <span class="p">,</span> <span class="nx">bar</span> <span class="o">=</span> <span class="nx">contrib</span><span class="p">.</span><span class="nx">bar</span><span class="p">(</span>
</span><span class='line'>       <span class="p">{</span> <span class="nx">label</span><span class="o">:</span> <span class="s1">&#39;Bar Chart&#39;</span>
</span><span class='line'>       <span class="p">,</span> <span class="nx">barWidth</span><span class="o">:</span> <span class="mi">20</span>
</span><span class='line'>       <span class="p">,</span> <span class="nx">barSpacing</span><span class="o">:</span> <span class="mi">20</span>
</span><span class='line'>       <span class="p">,</span> <span class="nx">maxHeight</span><span class="o">:</span> <span class="mi">9</span>
</span><span class='line'>       <span class="p">,</span> <span class="nx">height</span><span class="o">:</span> <span class="s2">&quot;100%&quot;</span>
</span><span class='line'>       <span class="p">,</span> <span class="nx">width</span><span class="o">:</span> <span class="s2">&quot;100%&quot;</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>So here we have defined a bar char, that will be populated with the columns and rows. For this we need a query, let&rsquo;s use the number of passengers per year, as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">SELECT</span> <span class="err">`</span><span class="nx">YEAR</span><span class="err">`</span><span class="p">,</span> <span class="nx">SUM</span><span class="p">(</span><span class="err">`</span><span class="nx">PASSENGER_COUNT</span><span class="err">`</span><span class="p">)</span> <span class="nx">FROM</span> <span class="nx">dfs</span><span class="p">.</span><span class="nx">tmp</span><span class="p">.</span><span class="err">`</span><span class="nx">airport_data_view</span><span class="err">`</span> <span class="nx">GROUP</span> <span class="nx">BY</span> <span class="err">`</span><span class="nx">YEAR</span><span class="err">`</span>
</span></code></pre></td></tr></table></div></figure>


<p>The complete Bar Chat application looks like:</p>

<div><script src='https://gist.github.com/00c5d83b85f59d80ad95.js?file=app001.js'></script>
<noscript><pre><code>var blessed = require(&#39;blessed&#39;)
  , contrib = require(&#39;blessed-contrib&#39;)
  , request = require(&#39;request&#39;)
  , screen = blessed.screen()
  , bar = contrib.bar(
       { label: &#39;Bar Chart&#39;
       , barWidth: 12
       , barSpacing: 5
       , maxHeight: 9
       , height: &quot;100%&quot;
       , width: &quot;100%&quot;})

screen.append(bar);

var query =  {
    &quot;queryType&quot; : &quot;SQL&quot;,
    &quot;query&quot; : &quot;select `YEAR`, SUM(`PASSENGER_COUNT`) from dfs.tmp.`airport_data_view` GROUP BY `YEAR`&quot;
};

request(
    {
        url: &#39;http://localhost:8047/query.json&#39;, //URL to hit
        method: &#39;POST&#39;,
        json: query
    }, 
    function(error, response, body){
        var columns = body.columns;
        var data = {
            titles : [],
            data : []
        };
        for(var entry of body.rows){
            data.titles.push(entry[columns[0]]);
            data.data.push(entry[columns[1]]);
        }
        bar.setData(data);
        screen.render()
    });


screen.key([&#39;escape&#39;, &#39;q&#39;, &#39;C-c&#39;], function(ch, key) {
      return process.exit(0);
});
</code></pre></noscript></div>


<ul>
<li>The lines 15-17 contain the query object used by the Drill REST API</li>
<li>The lines 26-38 contain the callback from the HTTP call, and the results values are store in the data object (lines 33-34), and then set in the bar chart (line 36)</li>
</ul>


<h3>Run the &ldquo;Dashboard&rdquo;</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">npm</span> <span class="nx">install</span> <span class="nx">request</span> <span class="nx">blessed</span> <span class="nx">blessed</span><span class="o">-</span><span class="nx">contrib</span>
</span><span class='line'>
</span><span class='line'><span class="nx">node</span> <span class="nx">app001</span><span class="p">.</span><span class="nx">js</span>
</span></code></pre></td></tr></table></div></figure>


<p>This application shows a simple bar chart, in your terminal. Let&rsquo;s now create a richer dashboard.</p>

<h2>Complete Dashboard</h2>

<p>The Bless-Contrib node package allows developer to create rich dashboards that aggregate multiple graphs and could be refresh automatically, as seen in the screencast at the top of this post.</p>

<p>You can find a simple dashboard in this <a href="https://github.com/tgrall/drill-node-dashboard.git">Github repository</a>, once you have cloned it, you just need to run: (be sure that your view is called &lsquo;dfs.tmp.<code>airport_data_view</code>&rsquo;</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">git</span> <span class="nx">clone</span> <span class="nx">https</span><span class="o">:</span><span class="c1">//github.com/tgrall/drill-node-dashboard.git</span>
</span><span class='line'>
</span><span class='line'><span class="nx">cd</span> <span class="nx">drill</span><span class="o">-</span><span class="nx">node</span><span class="o">-</span><span class="nx">dashboard</span>
</span><span class='line'>
</span><span class='line'><span class="nx">npm</span> <span class="nx">install</span>
</span><span class='line'>
</span><span class='line'><span class="nx">node</span> <span class="nx">dashboard</span><span class="p">.</span><span class="nx">js</span> <span class="nx">http</span><span class="o">:</span><span class="c1">//localhost:8047</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can even change the CSV file, for example adding new months, and the line chart on the right will be refreshed automatically.</p>

<p><em>Note: this dashboard sample is very basic and just a quick example explaning how to use Drill REST API in a node.js application</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert a CSV File to Apache Parquet With Drill]]></title>
    <link href="http://tgrall.github.io/blog/2015/08/17/convert-csv-file-to-apache-parquet-dot-dot-dot-with-drill/"/>
    <updated>2015-08-17T14:07:00+02:00</updated>
    <id>http://tgrall.github.io/blog/2015/08/17/convert-csv-file-to-apache-parquet-dot-dot-dot-with-drill</id>
    <content type="html"><![CDATA[<p>A very common use case when working with Hadoop is to store and query simple files (CSV, TSV, &hellip;); then to get better performance and efficient storage convert these files into more efficient format, for example <a href="https://parquet.apache.org/">Apache Parquet</a>.</p>

<p><a href="https://parquet.apache.org/">Apache Parquet</a> is a <a href="https://en.wikipedia.org/wiki/Column-oriented_DBMS">columnar storage format</a> available to any project in the Hadoop ecosystem. Apache Parquet has the following characteristics:</p>

<ul>
<li>Self-describing</li>
<li>Columnar format</li>
<li>Language-independent</li>
</ul>


<p>Let&rsquo;s take a concrete example, you can find many interesting Open Data sources that distribute data as CSV files- or equivalent format-. So you can store them into your distributed file system and use them in your applications/jobs/analytics queries. This is not the most efficient way especially when we know that these data won&rsquo;t move that often. So instead of simply storing the CSV let&rsquo;s copy this information into Parquet.</p>

<h3>How to convert CSV files into Parquet files?</h3>

<p>You can use code to achieve this, as you can see in the <a href="https://github.com/Parquet/parquet-compatibility/blob/master/parquet-compat/src/test/java/parquet/compat/test/ConvertUtils.java">ConvertUtils</a> sample/test class. You can use a simpler way with Apache Drill. Drill allows you save the result of a query as Parquet files.</p>

<p>The following steps will show you how to do convert a simple CSV into a Parquet file using Drill.</p>

<!-- more -->


<h4>Prerequisites</h4>

<ul>
<li>Apache Drill : Standalone <a href="https://drill.apache.org/">Apache Drill</a> or using <a href="https://www.mapr.com/products/mapr-sandbox-hadoop/download-sandbox-drill">Apache Drill Sandbox from MapR</a></li>
<li>Some CSV Files: for example <a href="http://www.flysfo.com/media/facts-statistics/air-traffic-statistics">Passenger Dataset from SFO Air Traffic Statistics</a></li>
</ul>


<h4>Querying the CSV file</h4>

<p>Let&rsquo;s execute a basic query:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span> <span class="o">*</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">dfs</span><span class="p">.</span><span class="o">`/</span><span class="n">opendata</span><span class="o">/</span><span class="n">Passenger</span><span class="o">/</span><span class="n">SFO_Passenger_Data</span><span class="o">/</span><span class="n">MonthlyPassengerData_200507_to_201503</span><span class="p">.</span><span class="n">csv</span><span class="o">`</span>
</span><span class='line'><span class="k">LIMIT</span> <span class="mi">5</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="p">[</span><span class="ss">&quot;200507&quot;</span><span class="p">,</span><span class="ss">&quot;ATA Airlines&quot;</span><span class="p">,</span><span class="ss">&quot;TZ&quot;</span><span class="p">,</span><span class="ss">&quot;ATA Airlines&quot;</span><span class="p">,</span><span class="ss">&quot;TZ&quot;</span><span class="p">,</span><span class="ss">&quot;Domestic&quot;</span><span class="p">,</span><span class="ss">&quot;US&quot;</span><span class="p">,</span><span class="ss">&quot;Deplaned&quot;</span><span class="p">,</span><span class="ss">&quot;Low Fare&quot;</span><span class="p">,</span><span class="ss">&quot;Terminal 1&quot;</span><span class="p">,</span><span class="ss">&quot;B&quot;</span><span class="p">,</span><span class="ss">&quot;27271\r&quot;</span><span class="p">]</span>
</span><span class='line'><span class="p">...</span>
</span><span class='line'><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see, by default Drill processes each line as an array of columns, all values being simple String. So if you need to do some operations with these values (projection or where clause) you must use the column index, and cast the value to the proper type. You can see a simple example below:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="nb">DATE</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">AIRLINE</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="k">CAST</span><span class="p">(</span><span class="n">columns</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span> <span class="k">AS</span> <span class="n">DOUBLE</span><span class="p">)</span> <span class="k">as</span> <span class="o">`</span><span class="n">PASSENGER_COUNT</span><span class="o">`</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">dfs</span><span class="p">.</span><span class="o">`/</span><span class="n">opendata</span><span class="o">/</span><span class="n">Passenger</span><span class="o">/</span><span class="n">SFO_Passenger_Data</span><span class="cm">/*.csv`</span>
</span><span class='line'><span class="cm">WHERE CAST(columns[11] AS DOUBLE) &lt; 5</span>
</span><span class='line'><span class="cm">;</span>
</span><span class='line'>
</span><span class='line'><span class="cm">+---------+-----------------------------------+------------------+</span>
</span><span class='line'><span class="cm">|  DATE   |              AIRLINE              | PASSENGER_COUNT  |</span>
</span><span class='line'><span class="cm">+---------+-----------------------------------+------------------+</span>
</span><span class='line'><span class="cm">| 200610  | United Airlines - Pre 07/01/2013  | 2.0              |</span>
</span><span class='line'><span class="cm">...</span>
</span><span class='line'><span class="cm">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>We are now ready to create our Parquet files using the &ldquo;Create Table As Select&rdquo; (aka <a href="http://drill.apache.org/docs/create-table-as-ctas-command/">CTAS</a>)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">alter</span> <span class="k">session</span> <span class="k">set</span> <span class="o">`</span><span class="n">store</span><span class="p">.</span><span class="n">format</span><span class="o">`=</span><span class="s1">&#39;parquet&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">dfs</span><span class="p">.</span><span class="n">tmp</span><span class="p">.</span><span class="o">`/</span><span class="n">stats</span><span class="o">/</span><span class="n">airport_data</span><span class="o">/`</span> <span class="k">AS</span>
</span><span class='line'><span class="k">SELECT</span>
</span><span class='line'><span class="k">CAST</span><span class="p">(</span><span class="n">SUBSTR</span><span class="p">(</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="k">AS</span> <span class="nb">INT</span><span class="p">)</span>  <span class="o">`</span><span class="k">YEAR</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="k">CAST</span><span class="p">(</span><span class="n">SUBSTR</span><span class="p">(</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="k">AS</span> <span class="nb">INT</span><span class="p">)</span> <span class="o">`</span><span class="k">MONTH</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">AIRLINE</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">IATA_CODE</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">AIRLINE_2</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">IATA_CODE_2</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">GEO_SUMMARY</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">GEO_REGION</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">ACTIVITY_CODE</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">PRICE_CODE</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">TERMINAL</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="n">columns</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span> <span class="k">as</span> <span class="o">`</span><span class="n">BOARDING_AREA</span><span class="o">`</span><span class="p">,</span>
</span><span class='line'><span class="k">CAST</span><span class="p">(</span><span class="n">columns</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span> <span class="k">AS</span> <span class="n">DOUBLE</span><span class="p">)</span> <span class="k">as</span> <span class="o">`</span><span class="n">PASSENGER_COUNT</span><span class="o">`</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">dfs</span><span class="p">.</span><span class="o">`/</span><span class="n">opendata</span><span class="o">/</span><span class="n">Passenger</span><span class="o">/</span><span class="n">SFO_Passenger_Data</span><span class="cm">/*.csv`</span>
</span></code></pre></td></tr></table></div></figure>


<p>That&rsquo;s it! You have now a Parquet file, a single file in our case since our dataset is really small. Apache Drill will create multiples files for the tables depending of the size and configuration your environment.</p>

<p>I invite you to read this Chapter in the Apache Drill documentation to learn more about <a href="https://drill.apache.org/docs/parquet-format/">Drill and Parquet</a>.</p>

<h3>Query Parquet Files</h3>

<p>Now that you have created your Parquet files you can use them in any of your Hadoop processes, but you can also use them in Drill, as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span> <span class="o">*</span>
</span><span class='line'><span class="k">FROM</span> <span class="n">dfs</span><span class="p">.</span><span class="n">tmp</span><span class="p">.</span><span class="o">`/</span><span class="n">stats</span><span class="o">/</span><span class="n">airport_data</span><span class="cm">/*`</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this article you have learned how to convert a CSV file using an Apache Drill query.</p>

<p>You can do that with any source supported by Drill, for example from JSON to Parquet, or even a complex join query between multiple data sources. You can also chose a different output format for example JSON, or a CSV.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Drill : How to Create a New Function?]]></title>
    <link href="http://tgrall.github.io/blog/2015/07/22/apache-drill-how-to-create-a-new-function/"/>
    <updated>2015-07-22T02:32:54+02:00</updated>
    <id>http://tgrall.github.io/blog/2015/07/22/apache-drill-how-to-create-a-new-function</id>
    <content type="html"><![CDATA[<p><a href="https://drill.apache.org/">Apache Drill</a> allows users to explore <em>any type of</em> data using ANSI SQL. This is great, but Drill goes even further than that and allows you to create custom functions to extend the query engine. These custom functions have all the performance of any of the Drill primitive operations, but allowing that performance makes writing these functions a little trickier than you might expect.</p>

<p>In this article, I&rsquo;ll explain step by step how to create and deploy a new function using a very basic example. Note that you can find lot of information about <a href="https://drill.apache.org/docs/develop-custom-functions-introduction/">Drill Custom Functions in the documentation</a>.</p>

<p>Let&rsquo;s create a new function that allows you to mask some characters in a string, and let&rsquo;s make it very simple. The new function will allow user to hide <em>x</em> number of characters from the start and replace then by any characters of their choice. This will look like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MASK( 'PASSWORD' , '#' , 4 ) =&gt; ####WORD</span></code></pre></td></tr></table></div></figure>


<p>You can find the full project in the following <a href="https://github.com/tgrall/drill-simple-mask-function">Github Repository</a>.</p>

<p>As mentioned before, we could imagine many advanced features to this, but my goal is to focus on the steps to write a custom function, not
so much on what the function does.</p>

<!--more-->


<h2>Prerequisites</h2>

<p>For this you will need:</p>

<ul>
<li>Java Developer Kit 7 or later</li>
<li>Apache Drill 1.1 or later</li>
<li>Maven 3.0 or later</li>
</ul>


<h2>Dependencies</h2>

<p>The following Drill dependency should be added to your maven project</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>      <span class="nt">&lt;groupId&gt;</span>org.apache.drill.exec<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>      <span class="nt">&lt;artifactId&gt;</span>drill-java-exec<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>      <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
</span><span class='line'><span class="nt">&lt;/dependency&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Source</h2>

<p>The <code>Mask</code> function is an implementation of the <a href="https://github.com/apache/drill/blob/master/exec/java-exec/src/main/java/org/apache/drill/exec/expr/DrillSimpleFunc.java"><code>DrillSimpleFunc</code></a>.</p>

<p>Developers can create 2 types of custom functions:</p>

<ul>
<li>Simple Functions: these functions have a single row as input and produce a single value as output</li>
<li>Aggregation Functions: that will accept multiple rows as input and produce one value as output</li>
</ul>


<p>Simple functions are often referred to as UDF&rsquo;s which stands for user defined function.  Aggregation functions are referred to as UDAF which
stands for user defined aggregation function.</p>

<p>In this example, we just need to transform the value of a column on each row, so a simple function is enough.</p>

<h4>Create the function</h4>

<p>The first step is to implement the <a href="https://github.com/apache/drill/blob/master/exec/java-exec/src/main/java/org/apache/drill/exec/expr/DrillSimpleFunc.java"><code>DrillSimpleFunc</code></a> interface.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">package</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">drill</span><span class="o">.</span><span class="na">contrib</span><span class="o">.</span><span class="na">function</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.DrillSimpleFunc</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.annotations.FunctionTemplate</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="nd">@FunctionTemplate</span><span class="o">(</span>
</span><span class='line'>        <span class="n">name</span><span class="o">=</span><span class="s">&quot;mask&quot;</span><span class="o">,</span>
</span><span class='line'>        <span class="n">scope</span><span class="o">=</span> <span class="n">FunctionTemplate</span><span class="o">.</span><span class="na">FunctionScope</span><span class="o">.</span><span class="na">SIMPLE</span><span class="o">,</span>
</span><span class='line'>        <span class="n">nulls</span> <span class="o">=</span> <span class="n">FunctionTemplate</span><span class="o">.</span><span class="na">NullHandling</span><span class="o">.</span><span class="na">NULL_IF_NULL</span>
</span><span class='line'><span class="o">)</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SimpleMaskFunc</span> <span class="kd">implements</span> <span class="n">DrillSimpleFunc</span><span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setup</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">eval</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The behavior of the function is driven by annotations (line 6-10)
  * <em>Name</em> of the function
  * <em>Scope</em> of the function, in our case Simple
  * What to do when the value is NULL, in this case Reverse will just returns NULL</p>

<p>Now we need to implement the logic of the function using <code>setup()</code> and <code>eval()</code> methods.</p>

<ul>
<li><code>setup</code> is self-explanatory, and in our case we do not need to setup anything.</li>
<li><code>eval</code> that is the core of the function. As you can see this method does not have any parameter, and return void. So how does it work?</li>
</ul>


<p>In fact the function will be generated dynamically (see <a href="https://github.com/apache/drill/blob/master/exec/java-exec/src/main/java/org/apache/drill/exec/expr/fn/DrillSimpleFuncHolder.java#L42">DrillSimpleFuncHolder</a>), and the input parameters and output holders are defined using holders by annotations. Let&rsquo;s look into this.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">io.netty.buffer.DrillBuf</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.DrillSimpleFunc</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.annotations.FunctionTemplate</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.annotations.Output</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.annotations.Param</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.holders.IntHolder</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.holders.NullableVarCharHolder</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.drill.exec.expr.holders.VarCharHolder</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">javax.inject.Inject</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="nd">@FunctionTemplate</span><span class="o">(</span>
</span><span class='line'>        <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;mask&quot;</span><span class="o">,</span>
</span><span class='line'>        <span class="n">scope</span> <span class="o">=</span> <span class="n">FunctionTemplate</span><span class="o">.</span><span class="na">FunctionScope</span><span class="o">.</span><span class="na">SIMPLE</span><span class="o">,</span>
</span><span class='line'>        <span class="n">nulls</span> <span class="o">=</span> <span class="n">FunctionTemplate</span><span class="o">.</span><span class="na">NullHandling</span><span class="o">.</span><span class="na">NULL_IF_NULL</span>
</span><span class='line'><span class="o">)</span>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SimpleMaskFunc</span> <span class="kd">implements</span> <span class="n">DrillSimpleFunc</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Param</span>
</span><span class='line'>    <span class="n">NullableVarCharHolder</span> <span class="n">input</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Param</span><span class="o">(</span><span class="n">constant</span> <span class="o">=</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'>    <span class="n">VarCharHolder</span> <span class="n">mask</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Param</span><span class="o">(</span><span class="n">constant</span> <span class="o">=</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'>    <span class="n">IntHolder</span> <span class="n">toReplace</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Output</span>
</span><span class='line'>    <span class="n">VarCharHolder</span> <span class="n">out</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Inject</span>
</span><span class='line'>    <span class="n">DrillBuf</span> <span class="n">buffer</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setup</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">eval</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We need to define the parameters of the function. In this case we have 3 parameters, each defined using the <code>@Param</code> annotation.  In addition, we also have to define the returned value using the <code>@Output</code> annotation.</p>

<p>The parameters of our mask function are:</p>

<ul>
<li>A nullable string</li>
<li>The mask char or string</li>
<li>The number of characters to replace starting from the first</li>
</ul>


<p>The function returns :</p>

<ul>
<li>A string</li>
</ul>


<p>For each of these parameters you have to use an holder class. For the <code>String</code>, this is managed by a <code>VarCharHolder</code> or <code>NullableVarCharHolder</code> -lines 21, 24,30- that provides a buffer to manage larger objects in a efficient way. Since we are manipulating a <code>VarChar</code> you also have to inject another buffer that will be used for the output -line 33-. Note that Drill doesn&rsquo;t actually use the Java heap for data being processed in a query but instead keeps this data off the heap and manages the life-cycle for us without using the Java
garbage collector.</p>

<p>We are almost done since we have the proper class, the input/output object, we just need to implement the <code>eval()</code> method itself, and use these objects.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kt">void</span> <span class="nf">eval</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// get the value and replace with</span>
</span><span class='line'>    <span class="n">String</span> <span class="n">maskValue</span> <span class="o">=</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">drill</span><span class="o">.</span><span class="na">exec</span><span class="o">.</span><span class="na">expr</span><span class="o">.</span><span class="na">fn</span><span class="o">.</span><span class="na">impl</span><span class="o">.</span><span class="na">StringFunctionHelpers</span><span class="o">.</span><span class="na">getStringFromVarCharHolder</span><span class="o">(</span><span class="n">mask</span><span class="o">);</span>
</span><span class='line'>    <span class="n">String</span> <span class="n">stringValue</span> <span class="o">=</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">drill</span><span class="o">.</span><span class="na">exec</span><span class="o">.</span><span class="na">expr</span><span class="o">.</span><span class="na">fn</span><span class="o">.</span><span class="na">impl</span><span class="o">.</span><span class="na">StringFunctionHelpers</span><span class="o">.</span><span class="na">toStringFromUTF8</span><span class="o">(</span><span class="n">input</span><span class="o">.</span><span class="na">start</span><span class="o">,</span> <span class="n">input</span><span class="o">.</span><span class="na">end</span><span class="o">,</span> <span class="n">input</span><span class="o">.</span><span class="na">buffer</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="kt">int</span> <span class="n">numberOfCharToReplace</span> <span class="o">=</span> <span class="n">Math</span><span class="o">.</span><span class="na">min</span><span class="o">(</span><span class="n">toReplace</span><span class="o">.</span><span class="na">value</span><span class="o">,</span> <span class="n">stringValue</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// build the mask substring</span>
</span><span class='line'>    <span class="n">String</span> <span class="n">maskSubString</span> <span class="o">=</span> <span class="n">com</span><span class="o">.</span><span class="na">google</span><span class="o">.</span><span class="na">common</span><span class="o">.</span><span class="na">base</span><span class="o">.</span><span class="na">Strings</span><span class="o">.</span><span class="na">repeat</span><span class="o">(</span><span class="n">maskValue</span><span class="o">,</span> <span class="n">numberOfCharToReplace</span><span class="o">);</span>
</span><span class='line'>    <span class="n">String</span> <span class="n">outputValue</span> <span class="o">=</span> <span class="o">(</span><span class="k">new</span> <span class="nf">StringBuilder</span><span class="o">(</span><span class="n">maskSubString</span><span class="o">)).</span><span class="na">append</span><span class="o">(</span><span class="n">stringValue</span><span class="o">.</span><span class="na">substring</span><span class="o">(</span><span class="n">numberOfCharToReplace</span><span class="o">)).</span><span class="na">toString</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// put the output value in the out buffer</span>
</span><span class='line'>    <span class="n">out</span><span class="o">.</span><span class="na">buffer</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">;</span>
</span><span class='line'>    <span class="n">out</span><span class="o">.</span><span class="na">start</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
</span><span class='line'>    <span class="n">out</span><span class="o">.</span><span class="na">end</span> <span class="o">=</span> <span class="n">outputValue</span><span class="o">.</span><span class="na">getBytes</span><span class="o">().</span><span class="na">length</span><span class="o">;</span>
</span><span class='line'>    <span class="n">buffer</span><span class="o">.</span><span class="na">setBytes</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">outputValue</span><span class="o">.</span><span class="na">getBytes</span><span class="o">());</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The code is quite simple:</p>

<ul>
<li>Get the mask itself - line 4</li>
<li>Get the value - line 5</li>
<li>Get the number of character to replace - line 7</li>
<li>Generate a new string with masked values - lines 10/11</li>
<li>Create and populate the output buffer - lines 14 to 17</li>
</ul>


<p>This code does, however, look a bit strange to somebody used to reading Java code. This strangeness arises because the final code that is executed in a query will actually be generated on the fly. This allows Drill to leverage Java&rsquo;s just-in-time (JIT) compiler for maximum speed. To make this work, you have to respect some basic rules:</p>

<ul>
<li><strong>Do not use imports, but instead use the fully qualified class name</strong>, this is what is done on line 10 with the <code>Strings</code> class. (coming from the Google Guava API packaged in Apache Drill)</li>
<li>The <code>ValueHolders</code> classes, in our case <code>VarCharHolder</code> and <code>IntHolder</code> should be manipulated like structs, so you must call helper methods, for example <code>getStringFromVarCharHolder</code> and <code>toStringFromUTF8</code>. Calling methods like <code>toString</code> will result in very bad problems.</li>
</ul>


<p>Starting in Apache Drill 1.3.x, it is mandatory to specify the package name of your function in the <code>./resources/drill-module.conf</code> file as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">drill</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">classpath</span><span class="o">.</span><span class="na">scanning</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">packages</span> <span class="o">:</span> <span class="n">$</span><span class="o">{?</span><span class="n">drill</span><span class="o">.</span><span class="na">classpath</span><span class="o">.</span><span class="na">scanning</span><span class="o">.</span><span class="na">packages</span><span class="o">}</span> <span class="o">[</span>
</span><span class='line'>      <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">drill</span><span class="o">.</span><span class="na">contrib</span><span class="o">.</span><span class="na">function</span>
</span><span class='line'>    <span class="o">]</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We are now ready to deploy and test this new function.</p>

<h3>Package</h3>

<p>Once again since, Drill will generate source, <em><strong>you must prepare your package in a way that classes and sources of the function are present in the classpath</strong></em>. This is different from the way that Java code is normally packaged but is necessary for Drill to be able to do the necessary code generation. Drill uses the compiled code to access the annotations and uses the source code to do code generation.</p>

<p>An easy way to do that is to use maven to build your project, and, in particular, use the <a href="https://maven.apache.org/plugins/maven-source-plugin/">maven-source-plugin</a> like this in your <code>pom.xml</code> file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;plugin&gt;</span>
</span><span class='line'>    <span class="nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>maven-source-plugin<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;version&gt;</span>2.4<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;executions&gt;</span>
</span><span class='line'>        <span class="nt">&lt;execution&gt;</span>
</span><span class='line'>            <span class="nt">&lt;id&gt;</span>attach-sources<span class="nt">&lt;/id&gt;</span>
</span><span class='line'>            <span class="nt">&lt;phase&gt;</span>package<span class="nt">&lt;/phase&gt;</span>
</span><span class='line'>            <span class="nt">&lt;goals&gt;</span>
</span><span class='line'>                <span class="nt">&lt;goal&gt;</span>jar-no-fork<span class="nt">&lt;/goal&gt;</span>
</span><span class='line'>            <span class="nt">&lt;/goals&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/execution&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/executions&gt;</span>
</span><span class='line'><span class="nt">&lt;/plugin&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, when you build using <code>mvn package</code>, Maven will generate 2 jars:</p>

<ul>
<li>The default jar with the classes and resources (<em>drill-simple-mask-1.0.jar</em>)</li>
<li>A second jar with the sources (<em>drill-simple-mask-1.0-sources.jar</em>)</li>
</ul>


<p>Finally you must add a <code>drill-module.conf</code> file in the resources folder of your project, to tell Drill that your jar contains a custom function. If you have no specific configuration to set for your function you can keep this file empty.</p>

<p>We are all set, you can now package and deploy the new function, just package and copy the Jars into the Drill 3rd party folder; $DRILL_HOME/jars/3rdparty , where $DRILL_HOME being your Drill installation folder.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>mvn clean package
</span><span class='line'>
</span><span class='line'>cp target/*.jar  $DRILL_HOME/jars/3rdparty
</span></code></pre></td></tr></table></div></figure>


<p>Restart drill.</p>

<h3>Run !</h3>

<p>You should now be able to use your function in your queries:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>SELECT MASK(first_name, &#39;*&#39; , 3) FIRST , MASK(last_name, &#39;#&#39;, 7) LAST  FROM cp.`employee.json` LIMIT 5;
</span><span class='line'>+----------+------------+
</span><span class='line'>|  FIRST   |    LAST    |
</span><span class='line'>+----------+------------+
</span><span class='line'>| ***ri    | ######     |
</span><span class='line'>| ***rick  | #######    |
</span><span class='line'>| ***hael  | ######     |
</span><span class='line'>| ***a     | #######ez  |
</span><span class='line'>| ***erta  | #######    |
</span><span class='line'>+----------+------------+
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>In this simple project you have learned how to write, deploy and use a custom Apache Drill Function. You can now extend this to create your own function.</p>

<p>One important thing to remember when extending Apache Drill (using a custom function, storage plugin or format), is that Drill runtime is generating dynamically lot of code. This means you may have to use a very specific pattern when writing and deploying your extensions. With our basic function this meant we had to:</p>

<ul>
<li>deploy <strong>classes AND sources</strong></li>
<li>use <strong>fully Qualified Class Names</strong></li>
<li>use value holder classes and helper methods to manipulate parameters
*</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB : Playing With Arrays]]></title>
    <link href="http://tgrall.github.io/blog/2015/04/21/mongodb-playing-with-arrays/"/>
    <updated>2015-04-21T15:45:39+02:00</updated>
    <id>http://tgrall.github.io/blog/2015/04/21/mongodb-playing-with-arrays</id>
    <content type="html"><![CDATA[<p>As you know,  you have many differences between relational and document databases. The biggest, for the developer, is probably the data model: Row versus Document. This is particularly true when we talk about &ldquo;relations&rdquo; versus &ldquo;embedded documents <em>(or values)</em>&rdquo;. Let&rsquo;s look at some examples, then see what are the various operations provided by MongoDB to help you to deal with this.</p>

<!-- more -->


<p>I won&rsquo;t use this post to go in all the details about &ldquo;document design&rdquo;, but I just want to focus on the operations you can to with these arrays/list (so useful operations once you have chosen to embed documents).</p>

<p>Let&rsquo;s use a very simple example based on e-commerce platform, with two document types : <strong><em>user</em></strong> and <strong><em>orders</em></strong>.</p>

<p>The first thing you have, is a simple list of values into a JSON array. Let&rsquo;s look at a user profile where user have a list of interests  (field <code>interested_by</code>) :</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">654321</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;first_name&quot;</span> <span class="p">:</span> <span class="s2">&quot;John&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;last_name&quot;</span> <span class="p">:</span> <span class="s2">&quot;Doe&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;interested_by&quot;</span> <span class="p">:</span> <span class="p">[</span> <span class="s2">&quot;electronics&quot;</span><span class="p">,</span> <span class="s2">&quot;sports&quot;</span><span class="p">,</span> <span class="s2">&quot;music&quot;</span> <span class="p">],</span>
</span><span class='line'>  <span class="nt">&quot;address&quot;</span> <span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;John Doe&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;company&quot;</span> <span class="p">:</span> <span class="s2">&quot;Resultri&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;street&quot;</span> <span class="p">:</span> <span class="s2">&quot;1015 Mapple Street&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;city&quot;</span> <span class="p">:</span> <span class="s2">&quot;San Francisco&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;state&quot;</span> <span class="p">:</span> <span class="s2">&quot;CA&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;zip_code&quot;</span> <span class="p">:</span> <span class="mi">94105</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Another thing you do with array, is to represent &ldquo;one-to-many&rdquo; relations. These relations in your RDBMS are based on multiple tables and foreign keys.
In document databases, like MongoDB, these relations are, most of the time, represented using an <em>array of documents</em>, something like (look at the <code>items</code> field):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">45218468309</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;date&quot;</span> <span class="p">:</span> <span class="err">ISODate(</span><span class="s2">&quot;2015-01-28T09:40:50.615Z&quot;</span><span class="err">)</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;customer&quot;</span> <span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;id&quot;</span> <span class="p">:</span> <span class="mi">654321</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;John Doe&quot;</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nt">&quot;ship_to&quot;</span> <span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;John Doe&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;company&quot;</span> <span class="p">:</span> <span class="s2">&quot;Resultri&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;street&quot;</span> <span class="p">:</span> <span class="s2">&quot;1015 Mapple Street&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;city&quot;</span> <span class="p">:</span> <span class="s2">&quot;San Francisco&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;state&quot;</span> <span class="p">:</span> <span class="s2">&quot;CA&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;zip_code&quot;</span> <span class="p">:</span> <span class="mi">94105</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nt">&quot;items&quot;</span> <span class="p">:</span> <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;sku&quot;</span> <span class="p">:</span> <span class="s2">&quot;WA34R&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;description&quot;</span> <span class="p">:</span> <span class="s2">&quot;Wireless Qwerty Keyboard&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;quantity&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;unit_price&quot;</span> <span class="p">:</span> <span class="mf">41.5</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;price&quot;</span> <span class="p">:</span> <span class="mf">41.5</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;vat&quot;</span> <span class="p">:</span> <span class="mi">20</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;sku&quot;</span> <span class="p">:</span> <span class="s2">&quot;MW003&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;description&quot;</span> <span class="p">:</span> <span class="s2">&quot;MiWatch&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;quantity&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;unit_price&quot;</span> <span class="p">:</span> <span class="mi">245</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;price&quot;</span> <span class="p">:</span> <span class="mi">490</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;vat&quot;</span> <span class="p">:</span> <span class="mi">20</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Documents above are not necessary complete, I just want to focus on the various operations you can do on these arrays.</p>

<p><em>Note: you can add these documents into your MongoDB instance, I will use the collections <code>customers</code> and <code>orders</code>.</em></p>

<h3>Adding new interest to the user</h3>

<p>To achieve this you have 2 operators that you can use in your update: <a href="1"><code>$push</code></a> and <a href="2"><code>$addToSet</code></a>. Since these one a very simple I won&rsquo;t go into too much details.</p>

<p>The <code>$push</code> will add the value at the end of the list, if the value already exits it will be added (many copies), this is why it makes sense to use the <code>$addToSet</code> operator, that only add the value if the value does not already exist in the array.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.customers.update(</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">654321</span>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;$addToSet&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;interested_by&quot;</span> <span class="p">:</span>  <span class="s2">&quot;sports&quot;</span><span class="p">}</span>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>This update command above <strong>will not change</strong> the document since the &ldquo;sports&rdquo; value is already in the list.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.customers.update(</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">654321</span>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;$addToSet&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;interested_by&quot;</span> <span class="p">:</span>  <span class="s2">&quot;books&quot;</span><span class="p">}</span>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>This <strong>will add</strong> the &ldquo;books&rdquo; value at the end of the list.</p>

<p>If the attribute <code>interested_by</code> does not exist in the document, it will be added with one single entry (here the <code>$push</code> is working the same way ).</p>

<p>If the attribute is not an array, the database will not do anything and return the error <a href="3">#16837</a> <em>&ldquo;The field &lsquo;first_name&rsquo; must be an array but is of type String in document&rdquo;</em>.</p>

<p>Here we use <em>interest</em>, but you can imagine doing the same thing for tagging, or any other business use case with a list of values.</p>

<h3>Adding a new item into an order</h3>

<p>The previous case, is very simple since it is a scalar value. Now I need to add a new order line, it is not harder than before:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.orders.update(</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">45218468309</span>   <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;$push&quot;</span> <span class="p">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;items&quot;</span> <span class="p">:</span> <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;sku&quot;</span> <span class="p">:</span> <span class="s2">&quot;MO001&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;description&quot;</span> <span class="p">:</span> <span class="s2">&quot;Bluetooth mouse&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;quantity&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;unit_price&quot;</span> <span class="p">:</span> <span class="mf">20.00</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;price&quot;</span> <span class="p">:</span> <span class="mf">20.00</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;vat&quot;</span> <span class="p">:</span> <span class="mf">20.00</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>So you can see now that the value is added at the end of the list.</p>

<h3>Updating an item in the order</h3>

<p>Let&rsquo;s look at another requirement. Now I need to update for example the quantity of one of the line. In your relational application it is <em>easy</em> in the sense that you have one single record to update(in reality it is a different story since application are using complex data layer).</p>

<p>You can do the same, meaning you can only update the <em>items</em> directly in the array &ndash; (no need to replace the full document or list like I see too often).</p>

<p>For this, you  just need to use the <code>update</code> and <code>$set</code> and specify the positional operation <code>$</code>.</p>

<p>The <code>$</code> operator is a placeholder for the first entry in the array that match the filter (query document) sent to the update/findAndModify command.</p>

<p>In our example, to update a specific line in the order</p>

<p>The proper way is simply to use the an update and <code>$set</code>,
 but you have to select the exact entry in the array in your filter. For example in our case we want to update the number of mouses and the price, this will look like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.orders.update(</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">45218468309</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;items.sku&quot;</span> <span class="p">:</span> <span class="s2">&quot;MO001&quot;</span>
</span><span class='line'>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;$set&quot;</span> <span class="p">:</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;items.$&quot;</span> <span class="p">:</span> <span class="p">{</span>
</span><span class='line'>          <span class="nt">&quot;sku&quot;</span> <span class="p">:</span> <span class="s2">&quot;MO001&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;description&quot;</span> <span class="p">:</span> <span class="s2">&quot;Bluetooth mouse&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;quantity&quot;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;unit_price&quot;</span> <span class="p">:</span> <span class="mf">20.00</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;price&quot;</span> <span class="p">:</span> <span class="mf">40.00</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;vat&quot;</span> <span class="p">:</span> <span class="mf">20.00</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>As you can see, the <code>$</code> operator is telling MongoDB to update one specific entry in the array.</p>

<h2>Remove an item from the Array</h2>

<p>You have learned so far that you can easily query and add values into an array; using the same appraoch you can also remove entry in an array. This is done using 3 operators : <code>$pop</code>, <code>$pull</code> and <code>$pullAll</code></p>

<ul>
<li>The <code>$pop</code> operator removes one element from the end of the array</li>
<li>The <code>$pull</code> operator removes <em>all</em> elements in the array that match a specified value.</li>
<li>The <code>$pullAll</code> operator removes <em>all</em> elements in the array that match any of the specified values.</li>
</ul>


<h4>Remove some interests from a customer</h4>

<p>For example, let&rsquo;s remove the &ldquo;electronics&rdquo; interest from the customer id 654321.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.customers.update(</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">654321</span>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;$pull&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;interested_by&quot;</span> <span class="p">:</span>  <span class="s2">&quot;electronics&quot;</span><span class="p">}</span>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you want to remove sports and music interest from the customer you can use the <code>$pullAll</code> operator as follow:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.customers.update(</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">654321</span>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;$pullAll&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;interested_by&quot;</span> <span class="p">:</span>  <span class="p">[</span><span class="s2">&quot;sports&quot;</span><span class="p">,</span><span class="s2">&quot;music&quot;</span><span class="p">]}</span>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here we use <em>interest</em>, but you can imagine doing the same thing for tagging, or any other business use case with a list of values.</p>

<h4>Remove item into an order</h4>

<p>Using the same operator you can also remove a line order (item) from an order document, for example let&rsquo;s remove the line with the item MO001 (Bluetooth mouse). For this we can use the <code>$pull</code> operator with the proper sku.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.orders.update(</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">45218468309</span><span class="p">,</span>
</span><span class='line'>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;$pull&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;items&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;sku&quot;</span> <span class="p">:</span> <span class="s2">&quot;MO001&quot;</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Conclusion</h3>

<p>In this article you have learn how to create/edit arrays in JSON documents.</p>

<p>In addition to all the update operators, MongoDB provides many operators for querying arrays such as  <a href="5">$size</a> or <a href="4"><code>$elemMatch</code></a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to MongoDB Security]]></title>
    <link href="http://tgrall.github.io/blog/2015/02/04/introduction-to-mongodb-security/"/>
    <updated>2015-02-04T18:55:30+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/02/04/introduction-to-mongodb-security</id>
    <content type="html"><![CDATA[<p>Last week at the Paris MUG, I had a quick chat about security and MongoDB, and I have decided to create this post that explains how to configure out of the box security available in MongoDB.</p>

<p>You can find all information about MongoDB Security in following documentation chapter:</p>

<ul>
<li><a href="http://docs.mongodb.org/manual/security/">http://docs.mongodb.org/manual/security/</a></li>
</ul>


<p><img class="center" src="http://tgrall.github.io/images/posts/intro-mongodb-security/password.jpg"></p>

<p>In this post, <em>I won&rsquo;t go</em> into the detail about how to deploy your database in a secured environment (DMZ/Network/IP/Location/&hellip;)</p>

<p>I will focus on <strong>Authentication</strong> and <strong>Authorization</strong>, and provide you the steps to secure the access to your database and data.</p>

<p>I have to mention that by default, when you install and start MongoDB, security is not enabled. Just to make it easier to work with.</p>

<p>The first part of the security is the <strong>Authentication</strong>, you have multiple choices documented <a href="http://docs.mongodb.org/manual/core/authentication/">here</a>. Let&rsquo;s focus on &ldquo;MONGODB-CR&rdquo; mechanism.</p>

<p>The second part is <strong>Authorization</strong> to select what a user can do or not once he is connected to the database. The documentation about authorization is available <a href="http://docs.mongodb.org/manual/core/authorization/">here</a>.</p>

<p>Let&rsquo;s now document how-to:</p>

<ol>
<li>Create an Administrator User</li>
<li>Create Application Users</li>
</ol>


<p>For each type of users I will show how to grant specific permissions.</p>

<!-- more -->


<h2>1. Start MongoDB</h2>

<p>As I said before, by default security is not enabled when you start MongoDB; so the first think to do is to enable it using the <code>--auth</code> parameter.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; mkdir /data/db
</span><span class='line'>
</span><span class='line'>&gt; mongod --auth
</span><span class='line'>
</span><span class='line'>....
</span><span class='line'>....
</span><span class='line'>2015-02-04T06:56:37.875+0100 [conn1] note: no users configured in admin.system.users, allowing localhost access
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>MongoDB is starting, and until you have created a user you can connect from localhost to create some users (especially the administrator one). This is what is called the <em>localhost exception</em>.</p>

<p>Note: I am here documenting security in simple configuration, I invite you to look to the documentation when deploying a <a href="http://docs.mongodb.org/v2.2/administration/sharded-clusters/#sharded-cluster-security-considerations">Sharded cluster</a>.</p>

<p>Now that we have started MongoDB, we can create users.</p>

<h2>2. Create Admin User</h2>

<p>The first thing is to create an admin user, that can also create users, So we have to:</p>

<ol>
<li>go to the mongo shell</li>
<li>connect to the `admin&#8217; database</li>
<li>create a user and assign him the role <a href="http://docs.mongodb.org/manual/reference/built-in-roles/#userAdminAnyDatabase"><strong>userAdminAnyDatabase</strong></a></li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>use admin
</span><span class='line'>
</span><span class='line'>var user = {
</span><span class='line'>  "user" : "admin",
</span><span class='line'>  "pwd" : "manager",
</span><span class='line'>  roles : [
</span><span class='line'>      {
</span><span class='line'>          "role" : "userAdminAnyDatabase",
</span><span class='line'>          "db" : "admin"
</span><span class='line'>      }
</span><span class='line'>  ]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>db.createUser(user);
</span><span class='line'>
</span><span class='line'>exit</span></code></pre></td></tr></table></div></figure>


<p>Now that you have created a user, in a MongoDB running with <code>--auth</code>, anonymous connections won&rsquo;t be able to do do anything with the database.</p>

<p>You can test for example to execute <code>show dbs</code> or <code>db.coll.insert({'x':0})</code> commands, you&rsquo;ll see authorization errors.</p>

<h3>Connect with the Admnistrator user</h3>

<p>Now that we have an admin user you can connect to the database with this user:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>&gt; mongo admin -u admin -p
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>Our admin user, has the role <strong>userAdminAnyDatabase</strong>. With this role you can manage user; but this role cannot read/write data from application datatabases/collections.</p>

<p>So we need now to create a new user for our &ldquo;eCommerce&rdquo; application.</p>

<h2>3. Create Application User</h2>

<p>Now we will create a new user <em>website</em> that is responsible of the ecommerce database.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; mongo admin -u admin -p
</span><span class='line'>
</span><span class='line'>use ecommerce
</span><span class='line'>
</span><span class='line'>var user = {
</span><span class='line'>  "user" : "website",
</span><span class='line'>  "pwd" : "abc123",
</span><span class='line'>  roles : [
</span><span class='line'>      {
</span><span class='line'>          "role" : "readWrite",
</span><span class='line'>          "db" : "ecommerce"
</span><span class='line'>      }
</span><span class='line'>  ]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>db.createUser(user);
</span><span class='line'>
</span><span class='line'>exit
</span></code></pre></td></tr></table></div></figure>


<p>This user will be able to read/write on the <em>ecommerce</em> database</p>

<h3>Connect with the application user</h3>

<p>Using the mongo shell you can now connect and create/query data</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; mongo ecommerce -u website -p
</span><span class='line'>
</span><span class='line'>db.products.insert({ "title" : "MongoDB in Action"  });
</span><span class='line'>
</span><span class='line'>db.products.findOne();
</span><span class='line'>
</span><span class='line'>db.products.update({}, {"$set" : { "type" : "book" } })
</span></code></pre></td></tr></table></div></figure>


<p>As you can see this user has the perfect profile for your application.</p>

<p>Note, that if you try to query or modify another database with this user you will receive authorization exceptions.</p>

<h2>Create a reporting user (Read Only)</h2>

<p>You may need in your application, user that can only read data, let&rsquo;s say in all databases. For this you just need to assign the role <strong>readAnyDatabase</strong>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>&gt; mongo admin -u admin -p
</span><span class='line'>
</span><span class='line'>var user = {
</span><span class='line'>  "user" : "reporting",
</span><span class='line'>  "pwd" : "abc123",
</span><span class='line'>  roles : [
</span><span class='line'>      {
</span><span class='line'>          "role" : "readAnyDatabase",
</span><span class='line'>          "db" : "admin"
</span><span class='line'>      }
</span><span class='line'>  ]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>db.createUser(user);
</span><span class='line'>
</span><span class='line'>exit</span></code></pre></td></tr></table></div></figure>


<p>This user will be able to query all the databases and collections, including <code>show dbs</code> command.</p>

<p>Let&rsquo;s connect with the reporting user:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; mongo admin -u reporting -p
</span><span class='line'>
</span><span class='line'>show dbs
</span><span class='line'>
</span><span class='line'>use ecommerce
</span><span class='line'>
</span><span class='line'>db.products.find();
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>If you try to inser/update/delete document you will receive an exception.</p>

<h2>Add new role to a user</h2>

<p>Let&rsquo;s now see how to add a new role to a user. For example I want to let the admin the power of read and write any database. For this I just need to add the role <strong>readWriteAnyDatabase</strong> to the admin user.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; mongo admin -u admin -p
</span><span class='line'>
</span><span class='line'>db.grantRolesToUser(
</span><span class='line'>  "admin",
</span><span class='line'>  [{ "role" : "readWriteAnyDatabase", "db" : "admin" }]
</span><span class='line'>)
</span><span class='line'>
</span><span class='line'>db.getUser("admin");
</span></code></pre></td></tr></table></div></figure>


<p>Using the <code>db.grantRolesToUser</code> command I have added the role to the admin user, and using the <code>db.getUser</code> I can look at the user profile.</p>

<p>Now, admin user should be able to create new databases, collections and documents, let&rsquo;s try:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>use hr
</span><span class='line'>
</span><span class='line'>db.employees.insert({ "name":"John Doe", "hire_date" : new Date() });
</span><span class='line'>
</span><span class='line'>db.organization.insert({ "name" : "Development" });
</span><span class='line'>
</span><span class='line'>db.employees.findOne();
</span></code></pre></td></tr></table></div></figure>


<h2>Create and use custom roles</h2>

<p>Another feature that is used a lot around security is related to the roles. In some case you want to provide multiple roles to a user, for example:</p>

<ul>
<li>all permission on database <em>ecommerce</em></li>
<li>read the collection <em>employees</em> in database <em>hr</em></li>
</ul>


<p>For this you can create a role that provide all the permissions and assign it to users. Let&rsquo;s do that using admin user.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>use admin
</span><span class='line'>
</span><span class='line'>var role = {
</span><span class='line'>  "role"  : "webSiteManagerRole",
</span><span class='line'>  privileges : [
</span><span class='line'>      {
</span><span class='line'>          "resource": {"db" : "hr", "collection" : "employees"},
</span><span class='line'>          "actions": ["find"]
</span><span class='line'>      }
</span><span class='line'>  ],
</span><span class='line'>  "roles" : [
</span><span class='line'>      {
</span><span class='line'>          "role" : "readWrite",
</span><span class='line'>          "db" : "ecommerce"
</span><span class='line'>      }
</span><span class='line'>  ]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>db.createRole( role );
</span><span class='line'>
</span><span class='line'>var user = {
</span><span class='line'>  "user" : "master",
</span><span class='line'>  "pwd" : "abc123",
</span><span class='line'>  roles : [
</span><span class='line'>      {
</span><span class='line'>          "role" : "webSiteManagerRole",
</span><span class='line'>          "db" : "admin"
</span><span class='line'>      }
</span><span class='line'>  ]
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>db.createUser(user);
</span><span class='line'>
</span><span class='line'>exit
</span></code></pre></td></tr></table></div></figure>


<p>If you connect now with the user &ldquo;master&rdquo;, you will see that, the user:</p>

<ul>
<li>can do anything you want in the ecommerce database</li>
<li>can read the &ldquo;hr.employees&rdquo; collection, on only this</li>
<li>cannot do anything else.</li>
</ul>


<h2>Roles and Privileges</h2>

<p>As you have seen in the previous section, you can create roles, and assign privileges to these roles. This is very powerful and you can really control each action on the database.</p>

<p>I am inviting you to look in detail to the built-in roles and privileges, this will help you a lot to select the proper ones for your application:</p>

<ul>
<li><a href="http://docs.mongodb.org/manual/reference/built-in-roles/">Built-in Roles</a></li>
<li><a href="http://docs.mongodb.org/manual/reference/privilege-actions/">Privileges</a></li>
</ul>


<h2>Conclusion</h2>

<p>In this blog post I quickly explained, how to:</p>

<ul>
<li>Use MongoDB Authentication</li>
<li>Create Users</li>
<li>Assign Roles and Privileges for Users.</li>
</ul>


<p>It is interesting to know that everything that I have showed you in the shell could be done from a user interface in <a href="http://mms.mongodb.com">MMS</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moving My Beers From Couchbase to MongoDB]]></title>
    <link href="http://tgrall.github.io/blog/2015/02/01/moving-my-beers-from-couchbase-to-mongodb/"/>
    <updated>2015-02-01T15:37:46+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/02/01/moving-my-beers-from-couchbase-to-mongodb</id>
    <content type="html"><![CDATA[<p>Few days ago I have posted a <em>joke</em> on Twitter</p>

<blockquote class="twitter-tweet" lang="en"><p>Moving my Java from Couchbase to MongoDB <a href="http://t.co/Wnn3pXfMGi">pic.twitter.com/Wnn3pXfMGi</a></p>&mdash; Tugdual Grall (@tgrall) <a href="https://twitter.com/tgrall/status/559664540041117696">January 26, 2015</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>So I decided to move it from a simple picture to a <em>real</em> project. Let&rsquo;s look at the two phases of this so called project:</p>

<ul>
<li>Moving the data from Couchbase to MongoDB</li>
<li>Updating the application code to use MongoDB</li>
</ul>


<p>Look at this screencast to see it in action:</p>

<iframe width="560" height="420" src="http://www.youtube.com/embed/Fpl74Z0HbC0?color=white&theme=light"></iframe>




<!-- more -->


<h2>Moving the data</h2>

<p>I have created a replication server, that uses the Couchbase XDCR protocol to get the document out and insert them into MongoDB. This server use the Couchbase CAPI Server project available <a href="https://github.com/couchbaselabs/couchbase-capi-server">here</a>.</p>

<p>This server will receive all the mutations made in the Couchbase:</p>

<ul>
<li>When a document is inserted or updated the full document is sent</li>
<li>When a document is deleted, only the medata are sent</li>
<li>The <code>replication server</code>, save the data into MongoDB (inserts and/or updates - no delete), and then return the list to Couchbase as part of the XDCR Protocol.</li>
</ul>


<p>One of the challenges is the fact Couchbase does not have the notion of &ldquo;types&rdquo; or &ldquo;collections&rdquo;. You put everything in a <em>bucket</em> and the application code knows how to deal with the data. Not necessary a problem, just a choice of implementation, but make it sometime harder than expected when you want to write tools. So here the logic that I apply in my replication server, to organize the data in multiple collections when it makes sense <em>(and when it is possible)</em>:</p>

<ul>
<li>If the JSON document does not contains a <em>type field</em>, all the documents will be saved in a single collection</li>
<li>If the JSON document contains a <em>type field</em> then a collection will be created for each type and documents will be inserted/updated in these collections</li>
<li>MongoDB does not allow attributes key to have . and $ signs, so it is necessary to change the name with alternative characters. This is done automatically during the copy of the data.</li>
</ul>


<p>All this, and more is configurable in the tool.</p>

<p>As you can see in the screencast this is straightforward.<em>(note that I have only tested very simple use cases and deployment)</em></p>

<p>You can download the tool and the source code here:</p>

<ul>
<li><a href="https://github.com/tgrall/mongodb-cb-replicator">https://github.com/tgrall/mongodb-cb-replicator</a></li>
<li>Download the <a href="http://goo.gl/WkuHBk">MongoCBReplicator.jar</a> file.</li>
</ul>


<h2>Updating the application code</h2>

<p>The next step is to use these data in an application. For this I simply use the Beer Sample Java application available on <a href="https://github.com/couchbaselabs/beersample-java">Couchbase repository</a>.</p>

<p>I just recreated the project and modified few things, to get the application up and running:</p>

<ul>
<li>Change the connection string</li>
<li>Remove the code that generate views</li>
<li>Replace set/get by MongoDB operations</li>
<li>Replace call to the views by simple queries</li>
</ul>


<p>The code of the MongoDBeer application is available here:</p>

<ul>
<li>[<a href="https://github.com/tgrall/mongodbeer">https://github.com/tgrall/mongodbeer</a>]</li>
</ul>


<p>I did not change any business logic, or added features, or even replaced the way navigation and page rendition is made. I just focused on the database access, for example :</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Couchbase Query</span>
</span><span class='line'><span class="n">View</span> <span class="n">view</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="na">getView</span><span class="o">(</span><span class="s">&quot;beer&quot;</span><span class="o">,</span> <span class="s">&quot;by_name&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="n">Query</span> <span class="n">query</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Query</span><span class="o">();</span>
</span><span class='line'>    <span class="n">query</span><span class="o">.</span><span class="na">setIncludeDocs</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">setLimit</span><span class="o">(</span><span class="mi">20</span><span class="o">);</span>
</span><span class='line'>    <span class="n">ViewResponse</span> <span class="n">result</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="na">query</span><span class="o">(</span><span class="n">view</span><span class="o">,</span> <span class="n">query</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">ArrayList</span><span class="o">&lt;</span><span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">beers</span> <span class="o">=</span>
</span><span class='line'>      <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;</span><span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;();</span>
</span><span class='line'>    <span class="k">for</span><span class="o">(</span><span class="n">ViewRow</span> <span class="n">row</span> <span class="o">:</span> <span class="n">result</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">parsedDoc</span> <span class="o">=</span> <span class="n">gson</span><span class="o">.</span><span class="na">fromJson</span><span class="o">(</span>
</span><span class='line'>        <span class="o">(</span><span class="n">String</span><span class="o">)</span><span class="n">row</span><span class="o">.</span><span class="na">getDocument</span><span class="o">(),</span> <span class="n">HashMap</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">beer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
</span><span class='line'>      <span class="n">beer</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">row</span><span class="o">.</span><span class="na">getId</span><span class="o">());</span>
</span><span class='line'>      <span class="n">beer</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="n">parsedDoc</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">));</span>
</span><span class='line'>      <span class="n">beer</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;brewery&quot;</span><span class="o">,</span> <span class="n">parsedDoc</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;brewery_id&quot;</span><span class="o">));</span>
</span><span class='line'>      <span class="n">beers</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">beer</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="n">request</span><span class="o">.</span><span class="na">setAttribute</span><span class="o">(</span><span class="s">&quot;beers&quot;</span><span class="o">,</span> <span class="n">beers</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">// MongoDB Query</span>
</span><span class='line'><span class="n">DBCursor</span> <span class="n">cursor</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="na">getCollection</span><span class="o">(</span><span class="s">&quot;beer&quot;</span><span class="o">).</span><span class="na">find</span><span class="o">()</span>
</span><span class='line'>                                                   <span class="o">.</span><span class="na">sort</span><span class="o">(</span> <span class="n">BasicDBObjectBuilder</span><span class="o">.</span><span class="na">start</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span><span class="mi">1</span><span class="o">).</span><span class="na">get</span><span class="o">()</span> <span class="o">)</span>
</span><span class='line'>                                                   <span class="o">.</span><span class="na">limit</span><span class="o">(</span><span class="mi">20</span><span class="o">);</span>
</span><span class='line'>     <span class="n">ArrayList</span><span class="o">&lt;</span><span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">beers</span> <span class="o">=</span>
</span><span class='line'>             <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;</span><span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;();</span>
</span><span class='line'>     <span class="k">while</span> <span class="o">(</span><span class="n">cursor</span><span class="o">.</span><span class="na">hasNext</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>         <span class="n">DBObject</span> <span class="n">row</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="na">next</span><span class="o">();</span>
</span><span class='line'>         <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">beer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
</span><span class='line'>         <span class="n">beer</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="o">(</span><span class="n">String</span><span class="o">)</span><span class="n">row</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;_id&quot;</span><span class="o">));</span>
</span><span class='line'>         <span class="n">beer</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="o">(</span><span class="n">String</span><span class="o">)</span><span class="n">row</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">));</span>
</span><span class='line'>         <span class="n">beer</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;brewery&quot;</span><span class="o">,</span> <span class="o">(</span><span class="n">String</span><span class="o">)</span><span class="n">row</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;brewery_id&quot;</span><span class="o">));</span>
</span><span class='line'>         <span class="n">beers</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">beer</span><span class="o">);</span>
</span><span class='line'>     <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c1">// Couchbase update</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">beerId</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">gson</span><span class="o">.</span><span class="na">toJson</span><span class="o">(</span><span class="n">beer</span><span class="o">));</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// MongoDB update</span>
</span><span class='line'><span class="n">db</span><span class="o">.</span><span class="na">getCollection</span><span class="o">(</span><span class="s">&quot;beer&quot;</span><span class="o">).</span><span class="na">save</span><span class="o">(</span><span class="k">new</span> <span class="nf">BasicDBObject</span><span class="o">(</span><span class="n">beer</span><span class="o">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>I did not attend to optimize the MongoDB code,  but just to replace as few lines of code as possible.</p>

<p>Note: I have not created any index during the process. Obviously if your application have more and more data and you do intense work with it you must analyze your application/queries to see which indexes must be created.</p>

<h2>Adding new features</h2>

<p>Once you have the data into MongoDB you can do a lot more without anything more than MongoDB:</p>

<h4>Full Text Search</h4>

<p>You can create a Text index on various fields in the collection to provide advanced search capabilities to your users.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.brewery.ensureIndex(</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;description&quot;</span> <span class="p">:</span> <span class="s2">&quot;text&quot;</span>
</span><span class='line'>  <span class="p">}</span><span class="err">,</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;weights&quot;</span> <span class="p">:</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;description&quot;</span> <span class="p">:</span> <span class="mi">5</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;TextIndex&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then you can query the database using the <code>$text</code> operation, for example all breweries with <em>Belgium</em> and without <em>Ale</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.brewery.find(</span> <span class="p">{</span> <span class="nt">&quot;$text&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;$search&quot;</span> <span class="p">:</span> <span class="s2">&quot;belgium -ale&quot;</span> <span class="p">}</span>   <span class="p">}</span>  <span class="err">,</span> <span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="mi">1</span>  <span class="p">}</span> <span class="err">);</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;daas&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;Daas&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;chimay_abbaye_notre_dame_de_scourmont&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;Chimay (Abbaye Notre Dame de Scourmont)&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;brasserie_de_cazeau&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;Brasserie de Cazeau&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;inbev&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;InBev&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;new_belgium_brewing&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;New Belgium Brewing&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;palm_breweries&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;Palm Breweries&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Some analytics</h4>

<p>Not sure these queries really make sense, but it is just to show that now you can leverage your documents without the need of any 3rd party tool.</p>

<p>Number of beer by category, from the most common to the less one:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.beer.aggregate(</span><span class="p">[</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;$group&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;$category&quot;</span><span class="p">,</span><span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="nt">&quot;$sum&quot;</span> <span class="p">:</span> <span class="mi">1</span> <span class="p">}</span> <span class="p">}</span> <span class="p">},</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;$sort&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">-1</span> <span class="p">}</span> <span class="p">},</span>
</span><span class='line'>  <span class="p">{</span><span class="nt">&quot;$project&quot;</span> <span class="p">:</span> <span class="p">{</span>  <span class="nt">&quot;category&quot;</span> <span class="p">:</span> <span class="s2">&quot;$_id&quot;</span><span class="p">,</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="mi">0</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'><span class="p">]</span><span class="err">);</span>
</span><span class='line'>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">1996</span><span class="p">,</span> <span class="nt">&quot;category&quot;</span> <span class="p">:</span> <span class="s2">&quot;North American Ale&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">1468</span><span class="p">,</span> <span class="nt">&quot;category&quot;</span> <span class="p">:</span> <span class="kc">null</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">564</span><span class="p">,</span> <span class="nt">&quot;category&quot;</span> <span class="p">:</span> <span class="s2">&quot;North American Lager&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">441</span><span class="p">,</span> <span class="nt">&quot;category&quot;</span> <span class="p">:</span> <span class="s2">&quot;German Lager&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="err">...</span>
</span><span class='line'><span class="err">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>Number of beer of a specific ABV by brewery, for example: top 3 breweries with the most beer with an abv greather or equals to a value, let&rsquo;s say 5:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.beer.aggregate(</span><span class="p">[</span>
</span><span class='line'><span class="err">...</span> <span class="p">{</span> <span class="nt">&quot;$match&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;abv&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;$gte&quot;</span> <span class="p">:</span> <span class="mi">5</span> <span class="p">}</span>  <span class="p">}</span> <span class="p">},</span>
</span><span class='line'><span class="err">...</span> <span class="p">{</span> <span class="nt">&quot;$group&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;$brewery_id&quot;</span><span class="p">,</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;$sum&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">}</span> <span class="p">}},</span>
</span><span class='line'><span class="err">...</span> <span class="p">{</span> <span class="nt">&quot;$sort&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">-1</span> <span class="p">}</span> <span class="p">},</span>
</span><span class='line'><span class="err">...</span> <span class="p">{</span> <span class="nt">&quot;$limit&quot;</span> <span class="p">:</span> <span class="mi">3</span> <span class="p">}</span>
</span><span class='line'><span class="err">...</span> <span class="p">]</span><span class="err">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;midnight_sun_brewing_co&quot;</span><span class="p">,</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">53</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;troegs_brewing&quot;</span><span class="p">,</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">33</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;rogue_ales&quot;</span><span class="p">,</span> <span class="nt">&quot;count&quot;</span> <span class="p">:</span> <span class="mi">31</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Geospatial queries</h4>

<p>The first thing to do with the data is to change the data structure to save the various data into a GeoJSON format, for this we can simply use a script into the MongoDB Shell:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">&gt;mongo</span>
</span><span class='line'>
</span><span class='line'><span class="err">use</span> <span class="err">beers</span>
</span><span class='line'>
</span><span class='line'><span class="err">db.brewery.find().forEach(</span>
</span><span class='line'>  <span class="err">function(</span> <span class="err">doc</span> <span class="err">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="err">var</span> <span class="err">loc</span> <span class="err">=</span> <span class="err">{</span> <span class="err">type</span> <span class="err">:</span> <span class="nt">&quot;Point&quot;</span> <span class="p">}</span><span class="err">;</span>
</span><span class='line'>    <span class="err">if</span> <span class="err">(doc.geo</span> <span class="err">&amp;&amp;</span> <span class="err">doc.geo.lat</span> <span class="err">&amp;&amp;</span> <span class="err">doc.geo.lon)</span> <span class="p">{</span>
</span><span class='line'>      <span class="err">loc.coordinates</span> <span class="err">=</span> <span class="err">[</span> <span class="err">doc.geo.lon</span> <span class="err">,</span> <span class="err">doc.geo.lat</span>  <span class="err">];</span>
</span><span class='line'>      <span class="err">db.brewery.update(</span> <span class="err">{</span> <span class="err">_id</span> <span class="err">:</span> <span class="err">doc._id</span> <span class="p">}</span> <span class="err">,</span> <span class="p">{</span><span class="err">$set</span> <span class="err">:</span> <span class="err">{</span> <span class="err">loc</span> <span class="err">:</span> <span class="err">loc</span> <span class="p">}</span> <span class="err">}</span>  <span class="err">);</span>
</span><span class='line'>    <span class="err">}</span>
</span><span class='line'>  <span class="err">}</span>
</span><span class='line'><span class="err">);</span>
</span><span class='line'>
</span><span class='line'><span class="err">db.brewery.ensureIndex(</span> <span class="p">{</span> <span class="nt">&quot;loc&quot;</span> <span class="p">:</span> <span class="s2">&quot;2dsphere&quot;</span> <span class="p">}</span> <span class="err">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>This call take all the breweries and add a new attribute, name <code>loc</code> as a GeoJSON point. I could also chose to remove the old geo information using a &lsquo;$unset&rsquo;, but I did not; let&rsquo;s imagine that some API/applications are using it. This is a good example of flexible schema.</p>

<p>Now I can search for all the brewery that are at less than 30km from the Golden Gate in San Francisco: [-122.478255,37.819929]</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">db.brewery.find(</span>
</span><span class='line'>  <span class="p">{</span> <span class="nt">&quot;loc&quot;</span> <span class="p">:</span>
</span><span class='line'>    <span class="p">{</span> <span class="nt">&quot;$near&quot;</span> <span class="p">:</span>
</span><span class='line'>      <span class="p">{</span> <span class="nt">&quot;$geometry&quot;</span> <span class="p">:</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>          <span class="nt">&quot;type&quot;</span> <span class="p">:</span> <span class="s2">&quot;Point&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;coordinates&quot;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">-122.478255</span><span class="p">,</span><span class="mf">37.819929</span><span class="p">]</span>
</span><span class='line'>        <span class="p">},</span>
</span><span class='line'>        <span class="nt">&quot;$maxDistance&quot;</span> <span class="p">:</span> <span class="mi">20000</span>
</span><span class='line'>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="err">,</span> <span class="p">{</span> <span class="err">name</span> <span class="err">:</span> <span class="err">1</span> <span class="p">}</span>
</span><span class='line'><span class="err">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can also use Geospatial indexes and operators in the aggregation queries used above</p>

<h2>Conclusion</h2>

<p>As as said in the introduction, this week end project started as a joke on Twitter, and finished with a small blog post and Gitub repositories.</p>

<p>My goal here is not to compare the two solutions -I made my choice few months back-  but simply show how you can move from one to the other with almost no effort, not only the data but also the application code.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Everybody Says “Hackathon”!]]></title>
    <link href="http://tgrall.github.io/blog/2015/01/23/everybody-says-hackathon/"/>
    <updated>2015-01-23T10:54:20+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/01/23/everybody-says-hackathon</id>
    <content type="html"><![CDATA[<h4>TLTR:</h4>

<ul>
<li>MongoDB &amp; Sage organized an internal Hackathon</li>
<li>We use the new X3 Platform based on MongoDB, Node.js and HTML to add cool features  to the ERP</li>
<li>This shows that “any” enterprise can (should) do it to:

<ul>
<li>look differently at software development</li>
<li>build strong team spirit</li>
<li>have fun!</li>
</ul>
</li>
</ul>


<h3>Introduction</h3>

<p>I have like many of you participated to multiple Hackathons where developers, designer and entrepreneurs are working together to build applications in few hours/days. As you probably know more and more companies are running such events internally, it is the case for example at Facebook, Google, but also ING (bank), AXA (Insurance), and many more.</p>

<p>Last week, I have participated to the first Sage Hackathon!</p>

<p>In case you do not know Sage is a 30+ years old ERP vendor. I have to say that I could not imagine that coming from such company… Let me tell me more about it.</p>

<p><img class="center" src="http://tgrall.github.io/images/posts/everybody-says-hackathon/00-logo.png"></p>

<!-- more -->


<h3>Sage Hackathon</h3>

<h5>How did it start?</h5>

<p>I have met the development team few months back when I learned that Sage was using MongoDB. We discussed about use cases, architecture,&hellip; And this is when I was the most surprised! The new version of Sage ERP X3 is a mix of legacy components (RDBMS, C++ based proprietary middleware), and brand new layer based on Node.js, MongoDB and HTML/CSS/JS (AngularJS like). The Sage team has open sourced some of the JS libraries, see <a href="https://github.com/sage">https://github.com/sage</a> Pretty cool isn’t?</p>

<p>I was really excited to see how MongoDB and Node.js are used by Sage modernize the ERP. So I asked more and more questions about the product, looked at some demonstrations. This leads to a broader discussion to see how we can use this new architecture to develop more features using it.</p>

<p>This is how we started to talk about an internal hackathon. Everybody, developers, marketing and managers were very excited about the idea.</p>

<h5>Hackathon Preparation</h5>

<p>Sage and MongoDB teams worked together to organize the event, with the following constraints:</p>

<ul>
<li>The hackathon will be a 24h (noon to noon) event, to allow Sage management to have corporate meetings before and after the event,</li>
<li>40 persons limit - 6 teams max - with a mix of developers, designer, product owner, quality engineer, … (coming from various countries),</li>
<li>The event will occur offsite to <em>daily duty noise</em></li>
</ul>


<p>Also since the hackathon will be short, 24h!, we decided to propose in advance many subjects and teams. This to be able to focus on the implementation on D-Day and avoid &ldquo;team and project&rdquo; selection.</p>

<p>So we define a list of 6 ideas that would extend the ERP in a cool way, for example: notification platform, collaboration feature such as business discussion, caching layer with query capabilities, office tool integration, plug social network like LinkedIn and Twitter to ERP business objects,&hellip;</p>

<p>Once we had a good vision of the event, Sage marketing and product management organized an internal presentation to announce the event, and ask for more ideas. We were all surprised to see so many ideas coming out of this presentation!</p>

<h5>Let&rsquo;s code!</h5>

<p>So we all met at the location, a very nice conference center, <a href="http://www.les-fontaines.com/">Les Fontaines</a>, where fresh coffee was waiting for us!</p>

<p>The event started with a very short presentation of the teams, projects, and jury.</p>

<p><img class="center" src="http://tgrall.github.io/images/posts/everybody-says-hackathon/01-sage-hack-intro.png" title="Presentation" ></p>

<p>Quickly the teams started to draw things on whiteboard, discuss architecture, and design&hellip; The organizers, included myself, were
very happy to see that everybody was diving into it.</p>

<p><img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/02-team-work.png" title="Team Work" > <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/03-motto.png"></p>

<p>MongoDB (<a href="http://twitter.com/alainhelaili">Alain</a> and I), and Sage architects were here to help; so we did. I pushed hard to be sure all the teams start to develop, design
as early as possible. I also gave many advices around document design and other things around MongoDB and node.</p>

<p>In the evening we stopped for a nice dinner, this is the big difference between a startup event, and a corporate one, good wine, soup, duck confit, wine, and fantastic desserts. Yummy!</p>

<p>Let&rsquo;s go back to the code thing, so all the teams were working like crazy on their project. I had lot of interesting discussions with all of them.</p>

<p><img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/04-night-coding.png" title="Night Coding" > <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/05-night-coding.png" title="Night Coding" ></p>

<p>I went to bed at 11:30pm, <em>yeah, I am a loser!</em>, while everybody was still working.</p>

<p><img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/06-night-coding.png" title="Night Coding" ><img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/07-night-coding.png" title="Night Coding" ></p>

<p>I as back in the <em>war room</em> around 6:00am, and helped some team to finish their project.</p>

<p>All the teams used the morning to polish the feature and prepare the demonstration.</p>

<h5>Let&rsquo;s vote!</h5>

<p>At noon each team started to demonstrate their feature in 5mn. All the teams did a live demonstration, with the feature well integrated to the Sage X3 screens.
It was really cool. A team even created a small video clip to explain the feature and vision.</p>

<p><img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/08-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/10-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/11-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/12-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/13-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/14-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/15-demonstration.png"> <img src="http://tgrall.github.io/images/posts/everybody-says-hackathon/09-demonstration.png"></p>

<p>It was very hard to chose a winner, but we agreed on a very rich and promising notification platform.</p>

<h5>What&rsquo;s next?</h5>

<p>It was really nice for me to see the excitement of all the teams, and the pride of being able to develop something that fast!</p>

<p>I cannot talk for Sage, but I think they all realize something: they can do stuff a lot faster, and this should try to push this into the product now!
It is also a good opportunity to see how to developer and deliver new addons for X3.</p>

<p>On my side, I am very happy of the result, and see that MongoDB and new technologies can really change the way we work with our data. And I hope to be able to do that again
with other companies.</p>

<h3>What about you?</h3>

<p>I believe that any organization that has an IT/Development team should organize such event, for example every year.</p>

<p>Honestly, we can &ldquo;stop&rdquo; working on our daily duties for 1,2 or 3 days and do this. If you look at your agenda, I am sure that you have wasted
more time on none productive meetings; remember :</p>

<blockquote><p>If a picture is worth 1000 words</p>

<p>A prototype is worth 1000 meetings!</p></blockquote>

<p>by @ideo</p>

<p>You will be surprised to see what can be done when you let the passionate people do what they love, but also it will be a good opportunity to motivate your team.</p>

<p>I will be pleased to discuss that you will, so feel free to drop me a comment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nantes MUG : Event #2]]></title>
    <link href="http://tgrall.github.io/blog/2015/01/21/nantes-mug-event-number-2/"/>
    <updated>2015-01-21T07:18:06+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/01/21/nantes-mug-event-number-2</id>
    <content type="html"><![CDATA[<p><a href="http://www.meetup.com/Nantes-MongoDB-User-Group/events/218926859/">Last night</a> the Nantes MUG (<a href="http://www.mongodb.org/user-groups">MongoDB Users Group</a>) had its second event. More than 45 people signed up and joined us at the <a href="http://www.epitech.eu/nantes/ecole-informatique-nantes.aspx">Epitech schoo</a>l (thanks for this!). &nbsp;We were lucky to have 2 talks from local community members:</p>

<ul>
<li>How “MyScript Cloud” uses MongoDB by <a href="https://twitter.com/mathieuruellan">Mathieu Ruellan</a></li>
<li>Aggregation Framework by <a href="https://twitter.com/sebprunier">Sebastien Prunier</a></li>
</ul>


<!-- more -->


<h3>How “MyScript Cloud” uses MongoDB</h3>

<p>First of all, if you do not know <a href="http://myscript.com/">MyScript</a>&nbsp;I invite you to play with the <a href="http://webdemo.myscript.com/#/home">online demonstration</a>.&nbsp;I am pretty sure that you are already using this technology without noticing it, since it is embedded in many devices/applications including: your car look at the <a href="http://vimeo.com/49013364">Audi Touchpad</a>!</p>

<p>That said Mathieu was not here to talk about the cool features and applications of MyScript but to explain how MongoDB is used to run their cloud product.&nbsp;
Mathieu explained how you can use <a href="https://dev.myscript.com/dev-kits/cloud-development-kit/">MyScript SDK</a> online. You just need to call a REST API to add Handwriting Recognition to your application. Let&rsquo;s make the long story short, and see how MongoDB was chosen and how it is used today:</p>

<ul>
<li>The prototype was done with a single RDBMS instance</li>
<li>With the success of the project MyScript Cloud the team had to move to a more flexible solution:

<ul>
<li>Flexible schema to support heterogeneous structures,</li>
<li>Highly available solution with automatic failover,</li>
<li>Multi datacenter supports with localized read,</li>
</ul>
</li>
<li>This is when Mathieu looked at different solution and selected MongoDB and deployed it on AWS.</li>
</ul>


<p>Mathieu highlighted the following points:</p>

<ul>
<li>Deploy and Manage a Replica Set is really easy, and it is done on multiple AWS data centers,</li>
<li>Use the proper <a href="http://docs.mongodb.org/manual/core/read-preference/">read preference</a>&nbsp; (nearest in this case) to deliver the data as fast as possible,</li>
<li>Develop with JSON Documents provides lot of flexibility to the developers, that can add new features faster.</li>
</ul>


<p><img class="center" src="http://4.bp.blogspot.com/-AWHn75hAyBY/VL9EMpRrFVI/AAAAAAAAAwA/CrDMkKL5A1Y/s1600/IMG_3743.jpg"></p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/43741214 " width="595" height="446" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen></iframe>


<p></p>

<h3>Aggregation Framework</h3>

<p>Sebastien &ldquo;Seb&rdquo; is software engineering at SERLI and working with MongoDB for more than 2 years now. Seb introduced the reasons why aggregations are needed in applications and the various ways of doing it with <a href="http://docs.mongodb.org/manual/aggregation/">MongoDB</a>: simple queries, map reduce, and aggregation pipeline; with a focus on a Aggregation Pipeline.</p>

<p>Using cool demonstrations, Seb explained in a step by step approach the key features and capabilities of MongoDB <a href="http://docs.mongodb.org/manual/core/aggregation-pipeline/">Aggregation Pipeline</a>:</p>

<ul>
<li>$match, $group, &hellip;</li>
<li>$unwind arrays</li>
<li>$sort and $limit</li>
<li>$geonear</li>
</ul>


<p>To close his presentation, Seb talked about aggregation best practices, and behavior&nbsp;<a href="http://docs.mongodb.org/manual/core/aggregation-pipeline-sharded-collections/#aggregation-pipeline-sharded-collection">in a sharded cluster</a>.</p>

<p><img class="center" src="http://4.bp.blogspot.com/-1fK-Q5SmL4s/VL9EQiaUIvI/AAAAAAAAAwI/AMVYrmQDPVg/s1600/IMG_3745.jpg"></p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/43730356 " width="595" height="446" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen></iframe>


<p></p>

<h3>And&hellip;</h3>

<p>As usual the event ended with some drinks and a late dinner!</p>

<p>This event was really great and I am very happy to see what people are doing with MongoDB, including storing <em>ink</em> like MyScript, thanks again to the speakers!</p>

<p>This brings me to the last point : MUGs are driven by the community. You are using MongoDB and want to talk about what you, do not hesitate to reach out the organizers they will be more than happy to have you.</p>

<p>You can find a MUG near you, <a href="http://www.mongodb.org/user-groups">look here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Create a Pub/sub Application With MongoDB ? Introduction]]></title>
    <link href="http://tgrall.github.io/blog/2015/01/12/how-to-create-a-pub-slash-sub-application-with-mongodb-introduction/"/>
    <updated>2015-01-12T09:21:03+01:00</updated>
    <id>http://tgrall.github.io/blog/2015/01/12/how-to-create-a-pub-slash-sub-application-with-mongodb-introduction</id>
    <content type="html"><![CDATA[<p>In this article we will see how to create a pub/sub application (messaging, chat, notification), and this fully based on MongoDB (without any message broker like RabbitMQ, JMS, &hellip; ).</p>

<p>So, what needs to be done to achieve such thing:</p>

<ul>
<li>an application &ldquo;publish&rdquo; a message. In our case, we simply save a document into MongoDB</li>
<li>another application, or thread, subscribe to these events and will received message automatically. In our case this means that the application should automatically receive newly created document out of MongoDB</li>
</ul>


<p>All this is possible with some very cool MongoDB features: <a href="http://docs.mongodb.org/manual/core/capped-collections/">capped collections</a> and <a href="http://docs.mongodb.org/manual/tutorial/create-tailable-cursor/">tailable cursors</a>,</p>

<!-- more -->


<h2>Collections and Tailable Cursors</h2>

<p>As you can see in the documentation, Capped Collections are fixed sized collections, that work in a way similar to circular buffers: once a collection fills its allocated space, it makes room for new documents by overwriting the oldest documents.</p>

<p>MongoDB Capped Collections can be queried using Tailable Cursors, that are similar to the unix <code>tail -f</code> command. Your application continue to retrieve documents as they are inserted into the collection. I also like to call this a &ldquo;continuous query&rdquo;.</p>

<p>Now that we have seen the basics, let&rsquo;s implement it.</p>

<h2>Building a very basic application</h2>

<h4>Create the collection</h4>

<p>The first thing to do is to create a new capped collection:</p>

<div><script src='https://gist.github.com/f16b1d3b5bcc12a4270a.js?file=capped-collection'></script>
<noscript><pre><code>$&gt; mongo

use chat

db.messages.drop()

db.createCollection(&#39;messages&#39;, { capped: true, size: 10000 })

db.messages.insert({&quot;type&quot;:&quot;init&quot;});

</code></pre></noscript></div>


<p>For simplicity, I am using the MongoDB Shell to create the <code>messages</code> collection in the <code>chat</code> database.</p>

<p>You can see on line #7 how to create a capped collection, with 2 options:</p>

<ul>
<li><code>capped : true</code> : this one is obvious</li>
<li><code>size : 10000</code> : this is a mandatory option when you create a capped collection. This is the maximum size in bytes. (will be raised to a multiple of 256)</li>
</ul>


<p>Finally, on line #9, I insert a dummy document, this is also mandatory to be able to get the tailable cursor to work.</p>

<h4>Write an application</h4>

<p>Now that we have the collection, let&rsquo;s write some code. First in <em>node.js</em>:</p>

<div><script src='https://gist.github.com/f16b1d3b5bcc12a4270a.js?file=app.js'></script>
<noscript><pre><code>var mongo = require(&quot;mongodb&quot;);

var mongodbUri = &quot;mongodb://127.0.0.1/chat&quot;;

mongo.MongoClient.connect (mongodbUri, function (err, db) {

  db.collection(&#39;messages&#39;, function(err, collection) {
    // open a tailable cursor
    console.log(&quot;== open tailable cursor&quot;);
    collection.find({}, {tailable:true, awaitdata:true, numberOfRetries:-1})
                      .sort({ $natural: 1 })
                      .each(function(err, doc) {
      console.log(doc);
    })
  });

});</code></pre></noscript></div>


<p>From lines #1 to 5 I just connect to my local mongoDB instance.</p>

<p>Then on line #7, I get the <code>messages</code> collection.</p>

<p>And on line #10, I execute a find, using a tailable cursor, using specific options:</p>

<ul>
<li><code>{}</code> : no filter, so all documents will be returned</span></li></li>
<li><code>tailable : true</code> : this one is clear, to say that we want to create a tailable cursor</li>
<li><code>awaitdata : true</code> : to say that we wait for data before returning no data to the client</li>
<li><code>numberOfRetries : -1</code> : The number of times to retry on time out, -1 is infinite, so the application will keep trying</li>
</ul>


<p>Line #11 just force the sort to the natural order.</p>

<p>Then on line #12, the cursor returns the data, and the document is printed in the console each time it is inserted.</p>

<h4>Test the Application</h4>

<p>Start the application</p>

<p><code>node app.js</code></p>

<p>Insert documents in the messages collection, from the shell or any other tool.</p>

<p>You can find below a screencast showing this very basic application working:</p>

<iframe width="560" height="420" src="http://www.youtube.com/embed/uSuiYvssKuo?color=white&theme=light"></iframe>


<p>The source code of this sample application in this Github repository, take the step-01 branch; clone this branch using:</p>

<p><code>git clone -b step-01 https://github.com/tgrall/mongodb-realtime-pubsub.git</code></p>

<p>I have also created a gist showing the same behavior in <em>Java</em>:</p>

<div><script src='https://gist.github.com/f16b1d3b5bcc12a4270a.js?file=MyApp.java'></script>
<noscript><pre><code>package org.mongodb.demos.tailable;

import com.mongodb.*;

public class MyApp {

    public static void main(String[] args) throws Exception {

        MongoClient mongoClient = new MongoClient();
        DBCollection coll = mongoClient.getDB(&quot;chat&quot;).getCollection(&quot;messages&quot;);

        DBCursor cur = coll.find().sort(BasicDBObjectBuilder.start(&quot;$natural&quot;, 1).get())
                .addOption(Bytes.QUERYOPTION_TAILABLE | Bytes.QUERYOPTION_AWAITDATA);

        System.out.println(&quot;== open cursor ==&quot;);

        Runnable task = () -&gt; {
            System.out.println(&quot;\tWaiting for events&quot;);
            while (cur.hasNext()) {
                DBObject obj = cur.next();
                System.out.println( obj );

            }
        };
        new Thread(task).start();
        
    }
    
}</code></pre></noscript></div>


<p>Mathieu Ancelin has written it in <em>Scala</em>:</p>

<div><script src='https://gist.github.com/f16b1d3b5bcc12a4270a.js?file=App.scala'></script>
<noscript><pre><code>package org.mongodb.demos.tailable

import reactivemongo.api._
import reactivemongo.bson._
import play.api.libs.iteratee.Iteratee
import scala.concurrent.ExecutionContext.Implicits.global
import reactivemongo.api.collections.default.BSONCollection

object Capped extends App {

  val driver = new MongoDriver
  val connection = driver.connection(List(&quot;localhost&quot;))
  val db = connection(&quot;chat&quot;)
  val collection = db.collection[BSONCollection](&quot;messages&quot;)

  val cursor = collection
        .find(BSONDocument())
          .options(QueryOpts().tailable.awaitData)
            .cursor[BSONDocument]

  println(&quot;== open tailable cursor&quot;)
  
  cursor.enumerate().apply(Iteratee.foreach { doc =&gt;
    println(s&quot;Document inserted: ${BSONDocument.pretty(doc)}&quot;)
  })
}</code></pre></noscript></div>


<h3>Add some user interface</h3>

<p>We have the basics of a publish subscribe based application:</p>

<ul>
<li>publish by inserting document into MongoDB</li>
<li>subscribe by reading document using a tailable cursor</li>
</ul>


<p>Let&rsquo;s now push the messages to a user using for example socket.io. For this we need to:</p>

<ul>
<li>add socket.io dependency to our node project</li>
<li>add HTML page to show messages</li>
</ul>


<p>The following gists shows the updated version of the app.js and index.html, let&rsquo;s take a look:</p>

<div><script src='https://gist.github.com/d8c2acfdc416abcc5d18.js?file=app.js'></script>
<noscript><pre><code>&quot;use strict&quot;;

var mongo = require(&quot;mongodb&quot;),
    fs = require(&quot;fs&quot;),         // to read static files
    io = require(&quot;socket.io&quot;),  // socket io server
    http = require(&quot;http&quot;);

var mongodbUri = &quot;mongodb://127.0.0.1/chat&quot;;

var app = http.createServer(handler);
io = io.listen(app);
app.listen(3000);
console.log(&quot;http server on port 3000&quot;);

function handler(req, res){
  fs.readFile(__dirname + &quot;/index.html&quot;,
  function (err, data) {
    res.writeHead(200);
    res.end(data);
  });
}

mongo.MongoClient.connect (mongodbUri, function (err, db) {

  db.collection(&#39;messages&#39;, function(err, collection) {

    // open socket
    io.sockets.on(&quot;connection&quot;, function (socket) {
      // open a tailable cursor
      console.log(&quot;== open tailable cursor&quot;);
      collection.find({}, {tailable:true, awaitdata:true, numberOfRetries:-1}).sort({ $natural: 1 }).each(function(err, doc) {
        console.log(doc);
        // send message to client
        if (doc.type == &quot;message&quot;) {
          socket.emit(&quot;message&quot;,doc);
        }
      })

    });

  });

});
</code></pre></noscript></div>


<p>The node application has been updated with the following features:</p>

<ul>
<li>lines #4-7: import of http, file system and socket.io</li>
<li>lines #10-21: configure and start the http server. You can see that I have created a simple handler to serve static html file</li>
<li>lines #28-39: I have added support to Web socket using socket.io where I open the tailable cursor, and push/emit the messages on the socket.</li>
</ul>


<p>As you can see, the code that I have added is simple. I do not use any advanced framework, nor manage exceptions, this for simplicity and readability.</p>

<p>Let&rsquo;s now look at the client (html page).</p>

<div><script src='https://gist.github.com/d8c2acfdc416abcc5d18.js?file=index.html'></script>
<noscript><pre><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;title&gt;MongoDB pub/sub&lt;/title&gt;
  &lt;style&gt;
  * { margin: 0; padding: 10px; box-sizing: border-box; }
  body { font: 13px Helvetica, Arial; }
  #messages { list-style-type: none; margin: 0; padding: 0; }
  #messages li { padding: 5px 10px; }
  #messages li:nth-child(odd) { background: #eee; }
  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;h2&gt;MongoDB/Socket.io demonstration&lt;/h2&gt;

  &lt;ul id=&quot;messages&quot;&gt;&lt;/ul&gt;

  &lt;script src=&quot;https://cdn.socket.io/socket.io-1.2.0.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://code.jquery.com/jquery-2.1.3.min.js&quot;&gt;&lt;/script&gt;
  &lt;script&gt;
  var socket = io();
  socket.on(&#39;message&#39;, function(doc){
    $(&#39;#messages&#39;).append($(&#39;&lt;li&gt;&#39;).text(doc.text));
  });
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre></noscript></div>


<p>Same as the server, it is really simple and does not use any advanced libraries except socket.io client (line #18) and JQuery (line #19), and used:</p>

<ul>
<li>on line #22 to received messages ans print them in the page using JQuery on line #23</li>
</ul>


<p>I have created a screencast of this version of the application:</p>

<iframe width="560" height="420" src="http://www.youtube.com/embed/N9fDxuohdy8?color=white&theme=light"></iframe>


<p>You can find the source code in this Github repository, take the step-02 branch; clone this branch using:</div></p>

<p><code>git clone -b step-02 https://github.com/tgrall/mongodb-realtime-pubsub.git</code></p>

<h3>Conclusion</h3>

<p>In this first post, we have:</p>

<ul>
<li>learned about tailable cursor and capped collection</li>
<li>see how it can be used to develop a pub/sub application</li>
<li>expose this into a basic web socket based application</li>
</ul>


<p>In the next article we will continue to develop a bigger application using these features.</p>
]]></content>
  </entry>
  
</feed>
